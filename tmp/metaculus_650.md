**Speaker A:**  You know, we do edit the show, so any, ~~uh,~~ interruptions, you need to take a break, somebody comes in, no problem. ~~Um,~~ we will also offer you, if you'd like, the opportunity, but not obligation, to review our edit before we publish. Most, ~~um,~~ people don't take us off on that, but it's totally up to you. ~~Um,~~ some people have like, corporate requirements where they have to, ~~um.~~ **Speaker B:**  Sounds good. **Speaker A:**  So it's a standard offer. ~~Um,~~ have you seen my outline? I assume that made way to you. **Speaker B:**  I did, yeah. Yeah. Look it. Cool. So we can certainly previous chapters you've done too, so I'm excited to be here for it. **Speaker A:**  Great. Thank you. **Speaker B:**  ~~Uh,~~ aw. **Speaker A:**  ~~Um,~~ we can certainly deviate from that. If there's anything you want to add or subtract, ~~you know, whatever, it,~~ it's all good, but at least that's a good starting point, hopefully. **Speaker B:**  I think it looks good. ~~Um,~~ I love going organic and just seeing where the conversation takes us. ~~Um,~~ I do think talking a little about approaches on such a technical alignment is something that I find pretty interesting. Like before metaculous, I was, ~~um,~~ leading AI objectives in institute, which is a research lab that focuses on context in which alignment manifests today. And I find that to be quite interesting as a counterweight. ~~Um, we can talk about that a little bit. Um, but yeah, overall, um, I feel good.~~ First time I'm doing a podcast also, so I, ~~um,~~ am interested in seeing how that goes. **Speaker A:**  Love it. I take a good amount of pride, actually, in having a lot of first time podcast guests, so that's cool. ~~M~~ cool. **Speaker B:**  ~~Um, so,~~ yeah, maybe we'll just start. **Speaker A:**  A little bit with that at the top. Yeah. **Speaker B:**  ~~Um,~~ because you said we will edit it, I guess I can like, say, can we do a ret take of a part or something? And that's fine. **Speaker A:**  Yeah, it's totally fine. ~~Um,~~ we even, in theory, have AI tools that can help us with that to a certain degree now, although we do have, ~~uh,~~ a human, ~~uh,~~ oversight still in place for now, at least. **Speaker B:**  ~~I think~~ where the tech is at right now requires this. So I think that sounds about right. **Speaker A:**  There is actually later today I have an interview with the CEO of Descript, which we use for editing, and they have recently launched a set of new features that collectively they call Underlord, which I think is funny. It's kind of obviously a play on overlord. The idea is the AI, you are the overlord and the AI is the underlord. ~~Um,~~ but they do have a like, retake removal where you can do these retakes and then just say, ~~like,~~ remove my retakes and it will, in theory, go through and cuddle that stuff. ~~So,~~ yeah, it's new. I wouldn't say we've ~~like,~~ battle tested it just yet, but. ~~So,~~ yeah, maybe put a little bit of your kind of background at the top and then, ~~um,~~ that can inform other things we talked about. But does that sound good to you? Just start with that. **Speaker B:**  That sounds good. I can also get to the background more from, ~~like,~~ how did I start focusing on forecasting? I like the order of questions you put ~~on on, you know, about you fire.~~ And then we can go from there and I can share, ~~you know,~~ what my interests are in the space and go from there. **Speaker A:**  Okay, cool. Can you pronounce your name for me so I can make sure I'm saying it correctly? **Speaker B:**  It's dare. Like truth or dare? **Speaker A:**  Dare. Okay. **Speaker B:**  And last name to run. **Speaker A:**  Dare to run. Cool. ~~Um, well,~~ let me get.

**Speaker A:** I kind of lost my voice at an event this past weekend, and it's mostly back, but it's not a hundred percent back, so I apologize for, ~~um,~~ not sounding my very best, but here we go. Dertron, CEO of Metaculus. Welcome to the cognitive revolution. **Speaker B:**  Thank you. Big fun here. **Speaker A:**  Thank you. That's ~~kind of~~ you to say. I'm excited for this conversation. ~~I've been a metaculous watcher and am I saying that right?~~ ~~By the way, let me make sure I'm pronouncing the company right, too.~~ **Speaker B:**  ~~Yes. Yes.~~ **Speaker A:**  ~~Ok.~~ Metaculous. **Speaker B:**  We got a lot of meticulus and meta calculus, ~~um,~~ which are both reasonable. I like what those signal as well. But metaculous is what we go. **Speaker A:**  All right, cool. So I've been a long time watcher, and you've got some very interesting new projects, which will be ~~kind of~~ the bulk of our conversation today. But ~~maybe~~ for starters, you're relatively new, ~~uh,~~ to the job, just a handful of months in the CEO role there. ~~Want to give us a little bit of~~ your background in AI? Because you've been working in the space for years before that and made a move that, ~~um, you might want to unpack a little bit in terms of~~ why the shift to the forecasting realm now, right? **Speaker B:**  ~~I guess~~ hindsight is 2020, especially in context like forecasting. ~~Um,~~ I have always been interested in questions of collective intelligence. How can we aggregate multiple different perspectives to the point that we can build a coherent world model? ~~And, um,~~ I was working on this question while I was still at school from a perspective of can we use natural language processing? This is way before LLMs back in, ~~um,~~ 2016. ~~Um,~~ how can we aggregate multiple different streams of thoughts, ~~um,~~ so that this would be actionable for a policymaker? So I've been interested in working with federal agencies and, ~~um,~~ build the startup on the space. ~~And,~~ right before metaculous, I was working on AI Objectives Institute, which is a nonprofit research lab focusing on socio technchnical alignment, which is looking at questions of AI alignment in context of real people in deployments right now, and seeing, are there any technical steps we can take that can actually say this group of people do perceive this AI model as better aligned or more instrumental towards their goals? ~~Um,~~ looking at it from an individual perspective and from a collective perspective, and from a systems perspective on understanding how can these tools be much better used for enhancing human agency? And I've been doing a lot of work on questions of collective intelligence. How can we augment, ~~um,~~ a multitude of different views to be able to contribute to a system that might be a single modith, or it might be multiple different agents collaborating. This might be a government, this might be an LLM, this might be an ensemble model. This is in a way applicable to many different systems. **Speaker A:**  ~~Right?~~ **Speaker B:**  And, um. ~~Um,~~ very quickly I find myself thinking about, okay, say we can aggregate multiple people's desirabilities. Even if we are able to do this on a high fidelity level, how do we get to the world outcomes that we're looking for? How do we actually go towards the model that is not just driving towards the lowest common denominator, um, and finding a consensus mode where the desire for consensus actually causes a trade off with fidelity to one's perspective, but instead see what would actually be helpful. What future do we want to live in? Are causes prioritized correctly so that we can move towards better futures? Can we find positive sum games? Um, who will shoulder the externalities? Um, if there is no free lunch, how can we make sure we're tracking that?

**Speaker B:** And these questions brought me towards thinking, okay, who's looking at the world from a perspective of, if we take action course x, will that yield a better outcome? And that's how I found myself thinking about forecasting. Because if I'm able to even have a very high fidelity version of desirability, elicitation, preference, elicitation, understand all the cruxes that exists in society, that still does not bring me towards a machine system being able to take actions that yield net good. So exploring that, along with the questions of wisdom of the crowd, if you have multiple different perspectives, be these be real humans or AI, that is actually once aggregated is doing a better job in forecasting outcomes. I realized this is actually quite instrumental in how we look at the world. ~~So, um,~~ that is what brought me towards thinking about more forecasting. Cool. **Speaker A:**  Just two. Rewind back in time for a second to the 2016 era. Did any of that stuff work? Were you able to make anything with technology that was available at the time that you thought yielded any practical utility? **Speaker B:**  ~~Um,~~ yes. Well, back then I was working actually with, ~~um,~~ Dan Jfsky, ~~um,~~ on a question at Stanford on, ~~um,~~ federal agency regulatory feedback. So the FCC net neutrality debate was just taking off, and there was 2 million comments that were submitted to the federal agency. And at that point this seemed like, wow, this is the largest data set that was ever collected of, ~~you know,~~ raw text. Now, it's ridiculously small, but at that point there was this question of, okay, how should a central agency pay attention to this? There was a lot of interesting questions. Like, a lot of the submissions were form letters that are copy paste. But the fact that it is copy paste does not make it illegitimate. You know, I will read, ~~you know,~~ a campaign and say, yeah, I agree with this, I want to send this. How should you take that into account compared to, ~~you know,~~ something that is bot generated compared to something that is you? A genuine opinion that someone has taken time, but it's not necessarily sophisticated and you can see that it has shortcomings. And, ~~um,~~ in my thesis work, I was looking at this both from a legal perspective and also technical perspective. You know, what are the expectations from, ~~you know,~~ EPA and EPA perspective on just the us legislation, but also, how can we have natural languageing augment this? ~~Um,~~ and funny enough, at that point I was thinking a lot of questions of good hearting. ~~Like,~~ every time we start focusing on a specific, narrower metric, it ceases to be a good measure. And this was very apparent in being able to claim that you're looking at the public. ~~Um,~~ things we tried were so simple, and yet they seemed like, ah, oh, this is a paradigm shift. ~~Um,~~ just like simple clustering strategies, unsupervised learning topic modeling. ~~Um,~~ and even that went a long way because people had no idea, and now we can do much more sophisticated versions and people still are like, people assume that we don't need to ask these questions because we cannot do large scale qualitativeveys. So we keep going back to Likert scale. So I guess the crusade I've been on for a long while is, can we go past, ~~uh,~~ how happy are you, one to seven, or should we build a road from a to b or a to c. I'm like, maybe we need to build a bridge instead. And if you don't let people express that, you're just not going to get that opinion. So how do we get, ~~um,~~ machine learner systems optimizers to be able to understand?

**Speaker B:** Uh, there is something qualitative that I need to elicit that even the speaker might not be sure what they want. Like, how can we give room for that human flexibility in these misschions? I cannot hear. Sorry. **Speaker A:**  There's a little construction outside my, ~~uh,~~ window, so I'm muting the mic sometimes, but. And then I've got to remember to unmute it. ~~Um, so~~ your comment on goodharting definitely resonates with me, particularly today. I was just, ~~uh,~~ having some back and forth on Twitter about the new GPT four o mini model, which is coming in ahead of claud 3.5 sonnet on the, ~~uh,~~ LMC leaderboard. And that raises the question. ~~It seems like~~ the general consensus among ~~people like me who are obsessed with the latest AIs'and,~~ kind of have their own individual opinions, seems to be that 3.5 sonnet is the best. ~~Um,~~ certainly we all would all tend to think it's better than GB 400 mini, and yet there it is, ~~uh,~~ ahead in terms of the votes that it's getting. So this has raised all sorts of ~~why is this happening?~~ Do we trust this thing anymore? ~~Um,~~ is it just about formatting? Is formatting. If it is mostly about formatting, does that mean it's ~~like,~~ illegitimate in some way, or does that mean we should really think more about the importance of formatting? ~~Um,~~ but yeah, ~~it's very.~~ As always, it's extremely difficult to pin much down if you really want to do it, ~~um,~~ with any real rigor. So that, ~~um,~~ is maybe a good bridge toward. And certainly the same is even more true about the future. So I've been interested in this space of forecasting for a long time. ~~I actually~~ participated in one of the original, ~~um,~~ tetlock organized super forecasting tournaments maybe 15 years ago now. ~~Uh,~~ Tyler Cowen posted, ah, an invitation to participate, and I was like, I'll try it in my hand at that. I did reasonably well. I wouldn't say, ~~um,~~ I didn't top the leaderboard, but I came out feeling like I had at least somewhat of a knack for it. And I've always found that the sort of Robin Hanseson perspective on this seems like a much better way than sor of highest paid person's opinion or whatever kind of prevails in organizations. ~~Um,~~ that's always been compelling to me, but it seems like generally speaking, we still don't see a ton of forecasting deployments in the world, ~~I guess.~~ What would your analysis be of ~~kind of~~ where we are in forecasting, where you think the most notable deployments are, and why we don't see more than we do today? **Speaker B:**  Right. I want to answer from the previous point you made around good hearting, because I think this actually goes towards there and you know, which model is better? Define better. Right. Better is incredibly content specific. Like even in just a small world of things I am trying to do personally within metaculous clau like 3.5 is more useful for me on question writing, but not necessarily fact retrieval. And it's a very narrow thing. And this current version of these models seem like, you know, one of them has an easier knack towards one thing without interrupting, without self censoring, so I can move forward faster. I think the core of forecasting also relates to this in terms of how can this process actually be useful? Is one thing that is different from, you know, will it score good on these benchmarks? Like in this one specific competition, will, you know, 4.0 score better? Like, that is a much narrower thing. In a way. Usefulness is almost always anecdotal and I think we are not paying enough attention to that. And I think the same as applicable for forecs.

**Speaker B:** Well, there has been so many tournaments like latest, ~~know,~~ like ACX ~~uh,~~ 2023 tournament is interesting for how accurate the forecasts have gotten. ~~Um,~~ but to me, okay, how is this going to actually be useful for an end user ~~is a different question.~~ ~~And I think this is the approach that I really want to focus on with metaculous for the upcoming sprint is, okay, we,~~ I have a couple of validations that, ~~you know,~~ I feel satisfied with. What are those? One wisdom of the crowd works. It is interesting that it works, but ~~when you aggregate a number of people,~~ and we will go into it, when you aggregate a number of bots, ~~um, that are trained with~~ LLMs or what have you, it seems to be able to draw an accurate picture of the future. And we have enough case studies of this. Why is this not more commonly used? I think usefulness is a whole different paradigm than accuracy, and this is really what I want to focus on. What do we want Toa do on this front? Like for example, can we identify critical inflection points towards future states? Is a different question than just is your forecast accurate? What is the shape of the world? That we want to live in. What are entities? ~~You know,~~ these can be federal agencies, like my prior work. This can be philanthropists, this can be corporations, nation states. The framework of forecasting so far, especially from a te talking lens, I think has not focused on how will this be actually useful, but has more so focused on can we improve the accuracy. I would like to move forward towards coming up with versions of forecasting deployments that actively pay attention to how will the decision maker take this into account? What are things that are within their space of levers? This is why I think forecasting in context of the humans that are trying to live a better life is extremely important. ~~Um,~~ I can share more examples on this front, but I'm curious where ~~you'to~~ go. ~~But, um, with this, like pretty much our research agenda for metaculous, for the next chapter,~~ for the next, ~~um,~~ two quarters heavily focuses on a lot of experimentation on these kinds of questions. **Speaker A:**  Yeah, interesting. ~~Does that look like basically~~ conditional. **Speaker B:**  Markets. **Speaker A:**  ~~Um,~~ being ~~kind of~~ the first thing, I mean, that's something that Robin Henson has talked about for a long time, and I don't see much, but we've just lived through a moment in history where it seems like something like that was pretty motivating to the current president of the United States, who I, ~~uh,~~ think was, if reporting and general intuition are correct, seems like he was not sold on the idea that somebody else had a better chance than him until he saw polling data suggesting that and then was kind of like, well, I guess, yeah, if somebody else has that much of a better chance, maybe I should step aside. ~~Um,~~ is that the sort. Obviously play that out a million different ways for a million different context. But is that the kind of next big paradigm? **Speaker B:**  I think that is an example that basically is, ~~uh,~~ a very simplified and somewhat was obvious to the entire population, except the decision makers themselves for longer than it should have, in my opinion, state of affairs. With that said, the real cases that I'm interested in is much more sophisticated than this, right. That heavily looks at public opinion and is more, I may say, like vibes based rather than data driven. And I'm interested in really pushing this edge further. Say we have $50 million to allocate towards making the world better. Pick your challenge. You reducing microplastics, climate related risks, AI related risk.

**Speaker B:** How should we allocate these resources to get to a better world? Requires us to build world models. I think forecasts around what are specific outcomes we can get to if we take an intervention point is very helpful. And the simplest thing we can do is exactly what you said on you come up with conditional forecast. If we take lever x, will that bring us to a better future? If not, what will it be like? ~~Um,~~ and if we see high divergence here, that is great. Now I want to push this much further. We can already do this. ~~Um,~~ but ~~throughuth~~ test conditional questions are somewhat hard to answer. It's hard to think in that framework. So can we build tools, be it, ~~you know,~~ LLM driven or discourse driven, or come up with ways in which people can collaborate, that enable conditional forecasts to be more useful? This is one avenue. One of the things I want to do in, ~~uh,~~ the near future is launch a series of minitacul. This is the name we came up with. Think of it like subreddits, which is metaculous instances. This will come in context of us open sourcing metaculus, and we hope that many of these will spring in the next quarter. ~~Um,~~ each Mintaculus will be focused on a specific question, a goal oriented question, such as we are trying to reduce microplastics, for example, or we're trying to reduce homelessness in San Francisco. This is geared towards disaster response or consequences of research avenues and context of AI. I would want every question in the minuteacul to be able to serve. If we are able to answer this question, it bubbles up to the parent, and then we can see which of these questions have the highest value of information. Which of these questions actually inform us to say, oh, it looks like this intervention is going to be able to drive much further value. I would want us to identify critical inflection points like, is there a specific moment in which the world models see to diverge? Are we able to extract schools of thought in the context of forecasting by seeing, oh, ~~uh,~~ this group of forecasters seem to be much more in accordance over multiple forecasts. Why is there world modern divergent? Can we double down on finding more questions that can help us excavate that? These kinds of research questions go way beyond what metaculous has aimed for so far. This is actively trying to build a world model in an enclosed world space that is metaculous with a spec goal. And I find this to be really, really interesting. Like, the kinds of things I would love to do is, for example, can we find short term proxies and heavily forecast on both? Is this short term proxy good? And how is the short term proxy panning out? ~~Um,~~ the way we landed with ~~the, uh,~~ forecasting AI benchmark is basically guided from this. Also in a way, ~~um,~~ we can frame the presidential debate through this lens. I ~~think~~ we as a civilization need to think much more from this lens. Like this is a version of a cognitive revolution where we change how people are thinking about the future. In a way, we're enabling them to coordinate between their world models. I still see forecast aggregation to be fairly low fidelity to be able to coordinate world models, but I think we can use that as a building block, as a primitive, and come up with much better world models. **Speaker A:**  So let's maybe take one step back just for those who maybe don't have so much experience with metaculous as it exists today. ~~Uh,~~ I'd be interested to hear ~~just like~~ for starters, how do you describe it to somebody ~~who's~~ never seen it before?

**Speaker A:** ~~Um,~~ would you call it a prediction market? Would you call it a forecasting platform? Um, how does it fit it? Because there's like a few of these now, right, with people would be familiar with certainly just online betting platforms, but also there's like manifold and polymarket that I see ~~kind of, you know,~~ shared them around. How would you describe the overall product today, and how would you distinguish it from some of the other things that are out there? **Speaker B:**  Mhm. Metaculous aggregates forecasts. It's a forecasting platform and an aggregation engine. I would not call metaculous a prediction market. The goal of Metaulus is to bring a level of epistemic security towards how we envision the future to be. We can call it Wikipedia about the future, and it is a space in which multiple people can see how they foresee the future to play out and the critical discussions to take place there. ~~Um,~~ it works with predictions as its core block, but it does not have a monetary incentive. ~~Um,~~ it behaves quite differently than prediction markets as a result of that. And some of those differences are the reasons why, in my opinion, Metaculus has been both more accurate and also more rigorous compared to a lot of other spaces. ~~Um, uh,~~ I can shed more light into that. For example, on a prediction market, the, uh, participants are buying and selling contracts that are based on the future outcome of an event, ~~right?~~ So you place bets and the result is a zero sum question. For example, if the current forecast is at 60% and you think it is 60%, you don't have an incentive to add that information in because it only can get worse from there. While on metaculous, this is not the case. ~~Um,~~ there's no financial incentive, and instead we are comparing all the forecasters accuracy and track record through time. And, ~~um,~~ this creates a different set of incentives that I believe are actually much more productive towards something that looks like Wikipedia about the future, where people are one incentivized share what their world model is. Two, people are incentivized to participate in forecasts and not think about de risking or spreading, but instead focus on, ~~you know,~~ what is the world model that I have that I can share. So our scoring mechanisms are different with respect to prediction markets as a result of that, too, because the reward mechanism is that you reward a forecaster over time for their calibration across many predictions and for their accuracy. ~~Um,~~ we also have a metric that we call the community prediction. This is interesting because this is where you can see everyone that has predicted on this question. And we also have weighted averages depending on your past success on your track record, and the recency for sooner forecasts thand to be better for, you have more information. So using these, we actually end up in an ecosystem that is much more collaborative and much more grounded and good epistemicics. And this brings higher rigor as well. So the questions we forecast tend to be more like, ~~you know,~~ carbon emissions on this d, rather than very personal questions, ~~uh,~~ on you. Who am I gonna be dating with next? And I like that, too. ~~You know,~~ there's a market for that, but I like that there is a space for focusing on the rigor that is actually beneficial for the world. So that is what I find distinct and attractive about metaculous. **Speaker A:**  Gotcha. So it seems like the big thing there is the incentives, whereas on a more market oriented platform, I am looking for things that are wrong so I can make money here.

**Speaker A:** I am looking for just opportunities where I can share something with the community that hopefully brings the overall, ~~uh,~~ community forecast toward a more accurate. **Speaker B:**  Right. But on top of that, I will add, there is a financial ~~incentiment,~~ metaculous, too, as in, if you have very good track record as a forecaster, we will hire you as a pro forecaster to go engage on many specific paid client works. And these range from federal agencies to large retailers, to hedge funds, think tanks that have much narrower questions. These questions don't make their way to the public forecast that we have, and they will be paid engagements, and we will also pay the pro forecasters for their reasoning so that they can actually explain why they see the forecast to be this way. ~~Just to echo back to a thing we were talking about,~~ I think one of the core projects that we have for metaculous is going to be reasoning transparency. The forecast on, say, I'm making up an example, ~~um,~~ say we'thinking about the taiwanese sovereignty. ~~This was the context in which this came up. Um, I was in Taiwan recently for a conference,~~ ~~and~~ we were talking about, ~~um,~~ will Taiwan, ~~you know,~~ electricity grid be, ~~um,~~ challenged by China, as, ~~you know,~~ in the process of a potential invasion? And, ~~um,~~ the forecast jumped from 30% to 40%. And there were no comments ~~under it because it was fairly new.~~ And I was sharing this with, ~~you know,~~ one of the, ~~uh,~~ folks there that are working on from the ~~government'pers~~ respective. And they were saying, unless I know why this is the case, I cannot take this into account. ~~And for that, we do pay our pro forecasters to come up with better forecasts with their explanations as well.~~ ~~And, um, we place people in jobs in the past.~~ ~~Um, so there is, in a way,~~ the leaderard can translate into, ~~uh,~~ financial incentives. **Speaker A:**  Yeah. **Speaker B:**  Opportunities happen on the substrate of the question. And that I think is quite. **Speaker A:**  Okay, cool. Can you say a little bit more about how you create that community forecast out of you kind of touch on this briefly, but this is one of the big questions that I've had, ~~um,~~ honestly, for a long time, because there are two kind of. I think of them as, like, canonical AI questions around AGI timelines that I've come back to for years now. I think I first tweeted about that, like, almost two years ago. And these are the weak AGI and the strong AGI. And we can unpack ~~this~~ a little bit more in a minute. But one thing that I've always kind of wondered is, like, exactly what am I looking at when I'm looking at this? To what degree am I seeing, you know, is it a naive aggregation? ~~Um,~~ because you can go in there and put a whole distribution. ~~Right.~~ So I'm interested in your comments on that, too. ~~Like,~~ I don't have a great sense of what I'm doing when ~~I'm, like,~~ actually drawing a curve over the potential timeline of ~~something happening.~~ Um, I feel like ~~I'm a little bit like, you know,~~ I mean, I guess I'm always ~~sort of~~ viing with these predictions, but that brings it home to me where I'm like, boy, the precision here feels like I'm leaving something behind. That is, ~~you know,~~ it's weird, right? It's a way to express my uncertainty, but it's also a way to, like, be very specific about my uncertainty. And even that I don't feel like I really have so interested in ~~sort of~~ how you see that kind of curve drawing. And then how are you aggregating? All these curves into one curve. Like do people get UPW weighted if they're better?

**Speaker A:** Is there a recency bias, et cetera? **Speaker B:**  So, ~~um,~~ couple different parts there. ~~Um,~~ with respect to the community prediction calculation, ~~we~~ ~~basically~~ keep the most recent prediction from each forecaster that we have. ~~And, um,~~ we wait each forecast based on how recent it is before being aggregated. ~~And um,~~ we also, for the Met tacless prediction, do pay attention, ~~especially~~ if there is you, a paid client that is looking for a specific outcome or higher rigor. We ~~do~~ do things like pay attention to the past track record of each of the forecasters and aggregate that information in as well. ~~Um,~~ for binary question, the commuter prediction is basically a weighted mean, ~~um,~~ all of the individual forecasters probabilities. And if you have a numeric question or a date question, it is a weighted mixture of all of the individual forecaster distributions. ~~Um,~~ there's actually a lot of different philosophies of aggregation and this is one of the spaces ~~that~~ I am interested in experimenting further. These are the ones that we use. And in general, the community prediction works and seems to be really accurate. ~~Um,~~ there may be a couple of folks that seemingly know consistently beat the community prediction. ~~And I think, you know,~~ there's a couple posts, ~~um,~~ from like astral code, ext ten, et cetera, that has focused on exploring this. ~~Um,~~ I think that I'm very interested in this. Very soon we will open source metaculous. I'm curious for people to come up with, you know, hey, here's a difference scoring mechanism, an aggregation mechanism that actually seems to work better or seems to be more instrumental. ~~Um,~~ I really want to encourage experimentation ~~on~~ in the space. What we have so far seems to work. If you just copy the community prediction, you will do pretty well in, ~~uh,~~ tournaments, but then you're not really bringing in independent information, right? So the better question to do is for someone to do their homework on, ~~you know,~~ what are past forecasts, ~~um,~~ that might be similar to this and then contribute, and only after that you see the community prediction because otherwise you start messing with the wisdom of the crowd. You said, you know, you might be doing vibes based reasoning. I think a lot of more. ~~So, you know,~~ reasoning based forecasting ends up being space for a lot of people. Not everyone is going to build like a mathematical vigoroous model or be a domain expert, but somehow when we put many of these together, it actually does yield a better outcome. And community prediction is our way to be able to ~~preict.~~ **Speaker A:**  Yeah. Do you want to talk about the metaculous track record on AI forecasting in particular. I think, ~~um,~~ that's obviously a very relevant data point. And then I do want to dig into those two questions that I refer to most often a little bit more. ~~Uh,~~ but maybe the general background would be good to share first in terms of just establishing that there is some alpha in the community forecast. **Speaker B:**  ~~Mhm. Uh,~~ what do you mean? I didn't understand. ~~Um,~~ there's some alth. **Speaker A:**  ~~Well,~~ there's this post on just kind of breaking down the track record. ~~Um,~~ the meticulous track record for AI forecasting. ~~Um,~~ exploring meticulous's AI track record and you know, I basically was hoping you would, ~~uh,~~ summarize that or share the highlights as you see it. **Speaker B:**  ~~M sorry, pausing here for Min. If there's this, can you find. Let's find the specific pos if you want to zoom in on.~~ **Speaker A:**  ~~Are you in the.~~ ~~Um. I'll put it into the chat. I'll put two things in the chat. First, I have the.~~ **Speaker B:**  ~~There's a bunch of things that are somewhat similar to this.~~ **Speaker A:**  ~~Well,~~ you could certainly bring in anything that you want, but here's my outline.

**Speaker A:** This is what I'm just referring to as we go. And then second is this post. But definitely feel free to go ~~beyond that or~~ give whatever you know best. Summer, you think. **Speaker B:**  ~~Uh, where did you, did you paste it on the end of.~~ **Speaker A:**  ~~Oh yeah, you should have.~~ ~~The UI here is not surpr.~~ **Speaker B:**  Track record on AI forecast. Oh yeah. Yeah. This is the ~~uh,~~ post by Peter. Yeah, I'm gonna ask actually, ~~can we just take a brief nature break? Um, I'll be adv.~~ **Speaker A:**  ~~Sure a sec. Yep, no problem. See you in a sec.~~ ~~We're back.~~ **Speaker B:** ~~Cool. Can you hear me well, yeah, uh.~~ **Speaker A:**  Yeah, I think so. **Speaker B:**  ~~I would love to go into like,~~ I was just like looking at my ~~uh,~~ notes. ~~Um,~~ I'd love to talk a little about ~~like~~ interesting episodes from history we would have caught and. ~~Right. That was.~~ Maybe we talk about that a little and then we can shift to Aji questions slash d. ~~Um, the, like,~~ I just looked at the post from Peter. I can talk about that. This is very much around ~~like,~~ the scoring rules and scoring accuracy rather than ~~like~~ what are the takeaways from there? So I would address this in context of ~~like~~ some of the more recent things we are doing on this front, like the ~~um,~~ five years after, ~~uh,~~ AGI tournament. We can talk also about, ~~you know,~~ the questions that we have written on the, ~~um,~~ AGI question, like I saw on the doctor. ~~So like maybe we can talk about those in a larger context altogether, rather than specifically dive into this post. For.~~ ~~I feel like~~ the post is ~~like~~ a math lecture, almost like I can go into that, but I feel like it's not necessarily the interesting cy ofistry. **Speaker A:**  Yeah, ~~I mean,~~ I think my takeaway from that post was somebody had said on the Internet that the mettaculous forecast were no better than random. And it's basically a exhaustive, rigorous breakdown of why that's not in fact true. And, ~~um,~~ we can see that there is actually some amount of significant benefit to looking at ~~the,~~ the community forecast over random. But I do think that anecdotes or kind of notable examples are very much of interest as well. Please share. **Speaker B:**  ~~So, sure.~~ One of the things that ~~I, I mean, I think it goes much more than,~~ better than random, given that there's actually a lot of people using metaculous forecasts. ~~Um,~~ I would start from, for example, the comparisons from the, ~~ah,~~ 2023 ACX, ~~uh, uh,~~ contest is quite interesting, ~~for example,~~ to look at, for comparison of know how does metaculous compare for prediction markets or super forecasters. And I really like Sasiti as an anchor for, ~~I think they're actually doing a great job, um, as a reference point.~~ ~~Um, this doesn't, you know,~~ I think to me, the parts of the question is like, how to make the forecast useful, along with how to make the forecast be accurate. I think there is enough track record on a couple different forums, like who predicted 2023? Best post from astral code. Extent is quite interesting for this. ~~Um,~~ but if you've been zooming on specific moments where an entity, be it a federal agency or a person, was able to take action from a forecast, ~~I think those are like~~ the moments where I see, yes, metaculous was actually useful or interesting. Like for example, in epidemiology, metaculus has outperformed both panels of experts on Covid and also informed hospital resource allocation, public health decision making. ~~Uh,~~ a lot of the forecasts were more robust and accurate than baseline models in predicting COVID vaccine uptakes. And, ~~um,~~ I do think that'quite interesting.















**Speaker B:** Can you improve this and have the human continue with just verbal intuition rather than, ~~um,~~ need to keep an excel spreadsheet to see if all of my intuitive probabilities are tracking, but instead you're able to say things like, these are my intuitive probabilities. Can you figure out where I am? Logically not consistent like, this would help a forecaster right now. Here's all the data that I have. Here's 30 forecasts. Maybe these 30 forecasts have some logical inconsistencies between them. Can you do better? If we can help language models get better at this, that's composite system, I believe will yield a much more reliable, much more safer AI model as well. And if we extend that further and further, ~~um,~~ we actually might end up with AI systems that are interpretable, that have reasoning transparency, that have distinct parts of world model building, exploring option spaces, eliciting preferences and desirabilities from people that you can look at and see, ~~uh~~ oh, this is how all of them are talking. If you're just trying to get one LLM or a bunch of LLMs, not so much ~~like,~~ I will never be able, but maybe through breakthroughs on mechanistic interpretive, we might be able to get there. ~~Um,~~ so I believe these kinds of explorations will actually yield much better AI forecasting. Yeah. Cool. **Speaker A:**  So that's awesome. I want to, just for closure, for people who wanted to maybe hear those other two papers, I'll just mention them briefly, ~~uh,~~ because I think if you're going to get into this tournament, you should look at the, ~~uh,~~ Halloween and Steinhardt paper for sure. That's like you're kind of jumping off point. Well done, agent with retrieval, with fine tuning, with, ~~ah,~~ a good scaffolding to spit out good predictions. That's the one that I mentioned before, comes reasonably close, but still fall short ~~of the,~~ of the community prediction. Then there are two from Tetlock and co authors. One was pretty interesting around just giving people access to an AI assistant and seeing how that helped them as humans forecast. This is kind of the big picture, at least a small step toward the big picture vision that you're painting. ~~Interestingly, they had a biased,~~ they ran an experiment where they gave the best assistant that they could give to the participants and then also a deliberately biased, ~~um,~~ AI assistant, and they found that both helped, although the biased one didn't help as much. ~~Um,~~ that's an interesting finding and also an interesting argument in that paper about how this look at the future. I mean, you could think like multiple reasons for why AI forecasting could be useful. You've made the case that, ~~you know,~~ obviously we would like to have a better sense of what's going to happen. We would like to be able to make better decisions. They also make ~~kind of~~ an argument in that paper that the study of what language models can predict is also ~~kind of~~ a useful way to interrogate to what degree they can get out of distribution, which is a very hotly debated topic within the study of AI. Right. Some level. By definition, if you're predicting the future, you're out of distribution. So that's, ~~I think.~~ And the fact that they are doing it reasonably well is definitely at least some points for team. These things can generalize, ~~um,~~ purely beyond their strictly defined training data. ~~Um,~~ then the third one, also from Tetlock and a number of the same authors, is just an exercise in ensembling the different language models and finding that like the average of the language models performs better than the individual. So it's ~~kind of~~ wisdom of, in fact, that's the title of the paper is wisdom of the silicon crowd. Yes, that one was interesting to me.

**Speaker A:** I mean, they did as you'd expect from a Tetlock publication. They pre registered all their experiments and were very sort of rigorous about, ~~you know,~~ declaring exactly what hypotheses they were going to test. It did jump out to me from the data that GPT four was like way outperforming the other models. And if you wanted to make a really simple improvement on their method, I would just cut the worst models and take, ~~uh,~~ one or ~~like~~ a few of the very top performing models and just ~~kind of~~ run multiple copies of those. **Speaker B:**  Right. **Speaker A:**  ~~Um,~~ a couple interesting notes there around bias toward round numbers, ~~a little bit biasd~~ toward positive resolution. Some of these things that you noted where there was like some logical inconsistencies and they were also hard. Another note I had on that paper was, it really shows the breadth of AI knowledge off in a powerful way because I would have had to do. ~~I was looking at some of these things, and I'm like, I don't even know the person.~~ It might be a leader of a country or whatever, and I don't even know who that is as we begin this, ~~uh,~~ discussion. So the fact that ~~the a as~~ are just jumping in and making, ~~uh,~~ predictions on such a wide range of things is like a good reminder of some of their fundamental strengths. **Speaker B:**  ~~Right?~~ **Speaker A:**  ~~So,~~ okay, that's all background and ~~hopefully breadcrumbs~~ for people that want to get into the tournament. **Speaker B:**  You've alluded to the tourn. If I make comment on then a little bit, I think ~~the conclusions of these papers do make intuitive sense, and I'd love to see much more rigorous tests of this.~~ Like, for example, what you said on, well, cut the worst models, and maybe that'll get you better. Maybe. But I also want you to keep in mind, ~~like,~~ if your goal is to, ~~uh,~~ have better forecast, probably the kinds of things that will make mild leaps is going to be things like look up if there has been similar questions asked on a variety of, ~~you know,~~ prediction platforms, ~~like,~~ that is actually instrumental and shifts out of an academic mindset of, ~~uh,~~ the rigor towards, ~~like,~~ what is actually instrumentally helpful here. I do think a lot of shortcuts are actually much more around. Like, okay, how can we get this to be further helpful? So those are the things I'm really interested in getting more folks to explore. Ensemble methods are great. Like, wisdom of the crowd works. Wisdom of silicon crowd also would probably work as a result. ~~Like,~~ try different models. Try the same model. Figure out if these models are good at specific domains or if they're avoidant on specific questions. ~~Like, these are all.~~ There is so much juice there. And as we have better models, also, the conclusions will shift continuously, which is why I think a benchmark like this will actually be really, really ~~helpful.~~ **Speaker A:**  ~~So,~~ let's get to the contest. You've alluded to the competition, ~~uh, or I guess we should maybe properly call this a forecasting tournament. Um, you've alluded to that a couple of times.~~ I would maybe love to start with just ~~kind of~~ a rundown of, ~~like,~~ what the setup is, ~~what,~~ what the rules are. There's prize money available. So you just give people a sense of ~~like,~~ what they would be signing up for ~~it and kind of the, you know,~~ the specific nature of the competition. **Speaker B:**  Yes, I am pretty excited about this competition. ~~Uh,~~ it s called AI benchmark by AI forecasting benchmark series. The competition will last for an entire year, where every quarter we will have new questions that get launched.

**Speaker B:** And, um, for this quarter we will ask about, uh, 250 to 400 questions to the AI systems that are forecasting. Um, we have about 120k prize money to be allocated across the entire competition. ~~And, yeah,~~ I would love for people to participate. A couple learnings that I've had just looking at the competition is, ~~um,~~ even very simple. Bots seem to be doing really well. And, ~~um,~~ this might be that their prompts are better, this might be that they're paying attention to better news sources. So it is definitely, ~~definitely~~ interesting. ~~Uh, and, um,~~ without a lot of effort, I do think it is possible to get something that is somewhat competitive. ~~Um,~~ now, what is the tournament? ~~It is, in a way,~~ it's a typical metaculous forecasting tournament, but, ~~um,~~ it is specifically geared towards spots. ~~Um,~~ we encourage people to build bots that use multiple LLMs. And, ~~um,~~ we will use this as a benchmark to compare against, ~~um,~~ pro forecasters and also the community aggregation. And, ~~um,~~ it's the first of its kinds to be done at this scale. ~~Um,~~ the basic rules are that you cannot have a human in the loop. You can change your bot, but you cannot make specific adjustments to the bot. Bots have to leave comments to showcase reasoning. We won't score the comments, but it will be good for us to see what are the winning bots doing. **Speaker A:**  ~~Uh,~~ so just quick clarification. When you said you can change your bot but you can't modify it, that means you can update it periodically, but you can't adjust it for a specific question. **Speaker B:**  Is that exactly? ~~Exactly? Exactly.~~ I'm just saying it for specific question basically defeats the purpose at that point. It has human in the loop, right? ~~I mean,~~ I do believe human. The loop systems ultimately are going to be better. Just like how, ~~you know,~~ competition is good, collaboration is good, ~~but like a competitive collaborative system where you have teams that can collaborate in competition is better. Um, this tournament, we're not looking into this.~~ We do want to see AI capabilities on their own, in their own footing. ~~Um, so, um,~~ hence you can update if you come up with a better strategy. ~~Uh, and, um,~~ especially the winning bots, we will interview, like the writers of the winning bots, we will interview them and ask them what was your approach. We do encourage people to share these systems if they would like, but they're not expected to do so. ~~Um,~~ they will provide some description of the bot or the code, ~~um,~~ if they would like, so that we can see what works and what doesn't. ~~Um,~~ yeah, this will create a benchmark that is continuously evolving, and also it's a benchmark that kind of cannot be cheated for. We literally don't know the answers to a lot of these questions. So it is really fun. ~~Like,~~ it evolves every day. ~~Like~~ every day you look at it again ~~and~~ see how your bot is doing. Is there something that is missing? So I find it pretty fun, personally. ~~Um,~~ we have created a template that people can follow that is fairly simple and straightforward, ~~um,~~ that you can use to just start with a one off system, but, ~~um,~~ on top of it, go to town. ~~Like,~~ there's a lot that can be done. Try the ensemble methods. Try model based reasoning systems. Bring on news. Like one of the things, for example, ~~where I saw,~~ I touched on this earlier a little bit, ~~um,~~ if a human forecaster is forecasting and trying to do well, they will google and look up other forecasting platforms to see if there are similar questions. This was something that the bots figured out pretty fast, or the bot writers, rather.

**Speaker B:** ~~Um, so, uh,~~ I'm really happy about these kinds of explorations. ~~Um, yeah,~~ so that is the rough rules of the competition. ~~Um,~~ fairly easy to get started. ~~Oh, also, um,~~ both OpenAI and anthropic have donated a fairly generous amount of credits for the competition. So for anyone that would like to get credits, ~~um,~~ because, ~~you know,~~ there's a lot of questions to forecast, I think we can cover all of the needs. ~~So if you, huh,~~ have the process is ping us either on discord or send us an email. You can email me daggeraculous.com ~~or,~~ or support email for it. It's all on the website and say, hey, this is the kind of thing I want to try. Can I get credits? And I'm pretty sure we can give you plenty of credits to support you. ~~So, yeah,~~ I find it too, to be, ~~um,~~ quite exciting for that. **Speaker A:**  All the questions are binary questions they're going to resolve. Yes. No. Is that right? Can you give us a few examples of early ones that have already resolved? **Speaker B:**  Yes. I want to say all the questions are binary at this tournament. ~~Um,~~ we will have non binary questions soon, ~~um,~~ for the next round, which will be q four, the tournament will happen in every quarter. ~~Um,~~ and, ~~um,~~ you get scored on the questions you forecast. So a lot of folks have asked me, am I too late to participate? I missed the first few weeks, actually. Not at all. We have some people that are on high on the leaderboard that have joined fairly late. So I say join now and also try things now because we will just cover your credits. Anyway, ~~um,~~ so when Q four hits, you can go in with a system that you have rigorously tested. ~~Um,~~ some of the questions that have already resolved with respect to, ~~um,~~ like the prime minister of France, ~~um,~~ will that belong to a coalition other than the new popular front or together? A lot of election related questions on France ~~have, ah,~~ resolved already. ~~Um,~~ domestic box office question. We have one on Deadpool and boulverine. Will that be higher than that of deadpool resolve? Yes, it was interesting for the bots did better than humans on this one. ~~Um,~~ Joe Biden. ~~Uh,~~ you know what will happen for the democratic card? We had a bunch of questions on that front. ~~Um,~~ one thing we have done that I think is really interesting is in the, ~~uh,~~ main quarterly cup, we have questions that are, ~~for example,~~ continuous variables like, ~~um,~~ what will be the between. I'm looking at one of the questions between July 17 and July 28. ~~Um,~~ what will the strongest geomagnetic, ~~uh,~~ storm have a k in excel? ~~Um,~~ for this tournament, for example, we have discretized this continuous variable question to say things like, will it be greater than four or less than or equal to six, greater than four, less than or equal to five, between five and six. So we have turned continuous variables into binary questions, and that way we can compare it to you. Is there logical consistency here? But also, how does this compare with human forecasters that are looking at this? So a couple tricks that we have placed in there to be able to make sure we can stay with a purely binary forecasting tournament. ~~Um,~~ and, ~~uh,~~ next quarter we'll build on top of that with more complexity. **Speaker A:**  So is the structure that the people submit their bot, then you guys are going to run the bot for them on a daily basis as new questions come out?

**Speaker A:** ~~Um,~~ they going to do, are they going to answer each question once or are they ~~sort of~~ going to be, repose the questions daily as they go until they resolve? And then do they provide a, I assume it's not just a simple yes no, but it's presumably a percentage. ~~Um,~~ and then how does the scoring work based on that number that they give you? **Speaker B:**  ~~Um,~~ the scoring is the same as any binary question that we have done on metaculous. ~~Um,~~ it will resolve yes or no, and we will score it accordingly towards that, and ~~um,~~ we will score the ensemble on top of all, ~~um, we don't host their bots,~~ they host the bots. And ~~um,~~ we will open questions. Every question will be open for 24 hours. So you will need to continuously forecast on top of that. We have made that process fairly easy. ~~If you're,~~ if anyone has any questions, they should take a look at the ~~um,~~ onboarding, ~~uh,~~ process. It would take maybe about 30 minutes to spin up a very simple bot. ~~Um,~~ but yeah, so you need to submit ~~through the API, um,~~ your forecasts to the question that open and close every day. **Speaker A:**  Gotcha. So people are running their own bots on their own computing infrastructure? **Speaker B:**  Yeah, basically we have some folks that are actually competing with bots that have value in form of private ip. We don't want them to just say, ~~well,~~ you need to give us what you have. Or if you have built something really interesting that you want to monetize, we do want to encourage that. So I think it would be very interesting for everyone to just submit their bots. But also at this point, at this stage where the current element capabilities are at, I would rather have people ~~to~~ how much more ease updating their bots. I want to see things like, oh, ~~uh,~~ this bot seem to be bad at scope sensitivity, but it got better. I'm curious, what tricks did they do for that, I'd rather have the bot be still in the custody of the person that is building it. Does that make sense? **Speaker A:**  Yeah. Is there a way, are we working on the honor system or is there the possibility that people could have a human in the loop as they submit their stuff? ~~Like,~~ the reason I assumed that they had to submit the bot was so that you could guarantee that they wouldn't have a human intervention in the process. **Speaker B:**  In this tournament, we have discussed this quite a bit and we decided that this will go with an honor system. ~~Um,~~ one of the things we have is like the number of questions to forecast is quite high, actually. So, ~~um,~~ somewhat ~~disinceentivizes~~ a human to forecast about you, 600 questions that are just, you're being bombarded. **Speaker A:**  It's a lot of work. **Speaker B:**  ~~Um,~~ and another reason why we want people to submit, their reasoning is that if there is human intervention, it might be much more visible through that, especially for, ~~you know,~~ the winning cases and the high volume of questions. ~~Um,~~ I do think we will scrutinize them heavily. And if we do have, ~~you know,~~ reasonable suspicion on that front, I'm sure we will have, ~~you know,~~ further investigations. But for this tournament, we decided to go forward with the honor system rather. So we do encourage people to abide by the norms because it'll be contributing to a meaningful benchmark that way. Otherwise it ~~kind of~~ ~~pro~~ provides a cheat. ~~Um,~~ so yeah, I guess the other.

**Speaker A:** **Speaker A:**  Thing is that the general prior assumption is just based on the, all the research that we talked about a few minutes ago that ~~like,~~ you might be able to ask, add a bit, but you're not going to add. Even over the baseline AI performance, an individual is not likely to add that much. ~~So~~ m and you might even make it worse in some cases. So it's not an obvious advantage to be unlike, for example, the arc challenge, where if you had a human intervention, there would be like a clear reason to think that you would have a big advantage toward the prize. Here, it's like much less obvious that a human can actually improve on what their bot is doing, ~~uh,~~ on its own. **Speaker B:**  Yeah, exactly. And to be honest, ~~like,~~ this is fairly early to make any conclusive statements and ~~kind of~~ hope that this will change. But we have a couple questions where the bots did better than the aggregate of pro forecasts. And I'm like, oh, this is very interesting because they clearly are failing on things like, ~~you know,~~ scope of negation, sensitivity, but, ~~um,~~ on questions where that's not, ~~you know,~~ the primary, ~~um,~~ mechanism, it's, they seem to be able to do something that is powerful. ~~Um,~~ so I think people should try not messing with it. And one thing is, ~~um,~~ every quarter we will have a different tournament that will have its own sets of rules and norms. So I am m interested in actually exploring, ~~you know,~~ different mechanisms here as well. So, ~~um,~~ we have an active ~~discour.~~ So people have ideas on like, hey, this kind of competition would be much more interesting. ~~Um,~~ I'd love to chat with them and hear, ~~you know,~~ what their ideas are. So, ~~um,~~ we can try different things, but ~~like,~~ the goal of this is to be able to benchmark AI capabilities and see if this can be an early warning system that would actually substantially help, ~~um,~~ the role forecasting plays in. **Speaker A:**  You said a minute ago that the scoring is ~~like~~ standard scoring, but just in case, I don't know exactly what that is, is that basically a. ~~My~~ intuition is that it would be like almost in the way that ~~like~~ a neural network might be measured for like a classification task, ~~sort of~~ sum of, ~~um,~~ squares type scoring. Is that right? **Speaker B:**  ~~Um, it's~~ your question how we are forecast, like how the scoring is for binary questions. **Speaker A:**  Yeah, exactly. **Speaker B:**  Yeah. I think with this way, ~~um,~~ we're basically comparing the forecast to a coin flip. In the context of ~~uh,~~ the forecaster. We're using log loss versus a coin flip and the peer score is basically how your baseline score, which is the log loss compared to the coin flip, compares to everyone else's. ~~Um,~~ so that way we have a proper scoring rule that's used based on log scores. The reason why we designed this way is that it rewards the forecasters for beating the crowd and incentivizes both. Like do research and understand the crowd, but also report your best guess rather than ~~um,~~ say things like I want to be 10% above whatever the community prediction is. ~~Um.~~ Does that make sense? **Speaker A:**  Yeah. Are you penalized by that for overconfidence? Like if you put a one on something and you're wrong, is that like very costly in that scoring system? **Speaker B:**  Yeah, given basically. So you need to be more accurate with respect to how you envision the world. Um, that s way we don't, you know, drive towards the far edges, which is something you see in prediction markets that have financial incentives. Um, so this actually combats against that.

**Speaker B:** That's why I was saying like if the market or community prediction is at 60% and you believe this is correct, you should say 60% because if it is accurate, ~~um,~~ then if it turns out to be a yes, you will be not penalized with, but if you don't think this is the accurate guess that you could make, then you should not say it's 60%. ~~Um,~~ while in a market, ~~um,~~ if you're trying to maximize the financial output where the market is at, isn't something meaningful to bet? **Speaker A:**  Yeah, gotcha. ~~Uh,~~ and you get all the questions at once as well. Would, is it within the rules to have the system consider all the questions to ~~sort of~~ handle the, to try to deal with the sort of possible inconsistencies. **Speaker B:**  Can you repeat what you said? **Speaker A:**  Yeah, you said that you have a number of questions that are related where you've ~~kind of~~ discretized a continuous variable or something. Are you supposed to just consider each one one by one and give a prediction or can you kind of consider them as a family ~~and a,~~ and imp post checks on like if there are related questions, make sure ~~uh,~~ my predictions are self consistent. **Speaker B:**  I mean, I hope that's what the contributors do. Right. I want a human forecastaster, a bot to be able to do that, which is precisely why we're asking these questions this way, because it is very hard for bots to be able to do this, ~~um,~~ unless you have come up with something that is much more robust. So I also want to see if they get better at doing this over time. ~~Um,~~ in the next, ~~um,~~ through the next year, will simpler models be better at scope sensitivity or negation sensitivity? ~~But yeah, like a human pro forecaster will obviously say, oh, all of these questions are related, so let me come up with an answer.~~ ~~Um,~~ it wouldn't be very difficult for an AI system to start doing this by noticing these questions are all connected. You can just have a simple LLM check that says if all of the questions are looking at similar variables, come up with one coherent answer, and then based on that answer, answer each of the individual parks specifically. ~~Um,~~ I'm curious how many contributors will do that. And I'm curious if that will actually yield numbers that will be, yeah, I. **Speaker A:**  Would think it would help at least a bit. **Speaker B:**  Yeah, it should. Like this is's what I'm hoping for. **Speaker A:**  Is there a leaderboard that folks can obsessively refresh instead of going to the election websites every day? **Speaker B:**  Yes, there is, and I encourage people to check it. ~~Uh,~~ what's interesting is some like newcomer bots have already went up high on the leaderboard fairly fast, which is why I tell everyone, ~~you know,~~ we have easy templates to get started. Just go and take your shot at winning the prize money. Like we do have a large ~~um,~~ pool of money. And this will also be distributed across the entire contribution over a certain level. So you don't have to get first place to get something. Like I do expect a lot of the ~~um,~~ bots will actually be compensated, ~~um,~~ in some shape or form. ~~Um,~~ so yeah, like bot performance seems high, variance enough, and we have three more quarters. So I would say like this is the time to get your bot in shape, set up through the template, start testing, and maybe you'live win some money. We will cover your costs. ~~So um,~~ the catch will be distributed along the curve rather than know just the top three. So it's not too late at all. I say give it a shot.

















**Speaker B:** Like, if we can find the good crux where I think a is true, you think a is false, but the underlying cause, if I thought the underlying cause change, this would change my mind about a, and you would say the same thing. Like the typical, ~~uh,~~ double crre process is good because that means we actually have a same shared world model, ~~um,~~ and we need more data. And at that point, bring on further research, bring on forecasting. ~~Like~~ we're in a good mode. The failure mode here is a risky alliance where someone says, oh, I think policy a is good. You say, I also think a is good. And I say a is good because it will enable b, which will be great, and you could say, I don't think b is likely to happen as a result of a, but maybe we should keep together because it seems instrumental just for this one step. And you end up having a lot of unlikely alliances. And the ultimate version of this is a completely polarized society where you for some reason know social conservative and fiscally conservative behavior is correlated with each other, even though that doesn't necessarily manifest. ~~Um,~~ there was one research that I read, I, ~~um,~~ can't remember where, that I just absolutely loved, which was instead of asking people their opinions with to immigration policy, it actually asked a statistical question on how many people are you willing to let in, ~~um,~~ before you reject someone that truly deserved to come into the country and, ~~uh,~~ the previous people that you have Letin might be mistakes. This is very interesting, because instead of people saying, ~~well,~~ I am liberal, I am conservative, you see people who say they are liberal, San Francisco crowd that will say, yeah, I'm willing to let in five mistakes before we admit one person. And others will say, what do you mean five? We need like 300. But both of these people see themselves as having a liberal opinion. ~~Like,~~ we do not yet operate on a level where we are looking at good policy. So we should not encourage these ~~illusion of consensus~~ so that it can serve towards ~~better~~ power. Instead, we can use these techniques that we have right now to go towards better policy. And better policy means higher visibility, better policy means people agree on the world models. So I see the work we're doing at metaculous as an instrumental step in that trajectory. Are we able to find people whose world models are diverging? Let's figure out why they are diverging. Are we able to see, okay, will this action that a policymaker has given us bring us to the outcome? ~~Um,~~ I think these are really important questions around the category of you. How can we have better epist security? **Speaker A:**  It's crazy to think how far this might be able to go over the not too distant future. ~~I mean,~~ obviously, you're primarily focused right now on getting a read on what the bots can do and trying to be as accurate as you can and to be much more in depth on these sort of mini metaculuses. Do you have a roadmap for let's ~~assum,~~ this works? Do you have a roadmap for how this sort of rolls out and scales up to ultimately, ~~like,~~ big picture, most important questions in society? **Speaker B:**  Right? And that question I hear, ~~ah, o,~~ they are, you should write a blog post about this, probably that maps this out. ~~Um,~~ quick thoughts that come to my mind, ~~um, like,~~ we know preferences can and do change based on actions and their consequences, right? So can we build these feedback loops as proof points in organizations that can actually take action on them where real stakes are present?

**Speaker B:** Um, that's why I'm interested in labor unions, for example, because it's a fairly acute case of coordinated decision making with stakeholders that are outside and inside the group. So it gives us a lot of visibility. I think where we are at right now is, I don't expect the top down revolution of a government adopting this off the bat, but I do think there's a lot of municipal level, ~~um,~~ experimentation that already has been happening. Like, for example, talk to the city is collaborating with, ~~uh,~~ a couple of municipalities in Japan right now, ~~um,~~ through liquid, which is a japanese, ~~um,~~ liquid democracy focus company. ~~Um,~~ there's a bunch coming in in Taiwan. We have interest from folks in Singapore to be able to use metaculous forecasts. For example, we have interests in ~~similar Taiwan~~ community. We have groups in the US also on municipal level. Like for example, Detroit has a bunch of communities, ~~um,~~ that are focusing on well being of African Americans and previously incarcerated forks. Are we able to figure out what interventions bring a better world to them? These are all very short term, but in these processes we can actually see, oh, this seemed to have worked. This actually did yield an outcome where a group was able to coalesce much better. I think we need more visibility into that. This, I think, is the very first step. I think AI tooling is absolutely critical for both the failure mode and the success mode will heavily depend on how these tools are implemented and used, um, how these tools are actively enhancing human aid. ##y um, I would recommend people who are interested in more of this to check out the roadmap documents from AI Objectives Institute. That's where I have done a lot of my writing and thinking with the team there. Um, and I reach out to them also. ~~Um,~~ I still try to stay as involved as I can, but it does hold a dear space in my heart for Peter Eckersy, who was the original founder and a, ~~uh,~~ mentor and a friend of mine, unfortunately passed away quite unexpectedly, which is when I started leading AI objectives institute. ~~Um,~~ and like the line of thought, there was very much always, ~~like,~~ AI can be a transformative point for human well being, but the default systems do not place us on that path. ~~Um,~~ so I think there's a lot there, and this is the question of existential hope, right? ~~Like,~~ I see existential risk and a lot of risk related failures as let me put it this way. Existential risk is failure to coordinate at the face of a risk. If we can already foresee this path and we are failing to coordinate the systems we are in, the coordination capabilities we are in doesn't let us get to the heart of that. That is why we are fail. So that is the angle that I wanted to keep looking at. Because we have seen incredibly successful cases of international coordination, or multi corporation coordination. Like the ozone layer is basically recovering since we have banned CP CFcs. Like there is many different cases where we have moved mountains as society. Like microplastics related harms. Like we have bands, ~~um,~~ lead at this point. Like there are ways in which we are able to coordinate if we can create coherent world models. And I think the thing we need to do is have shared world models that can contain the disagreements rather instead of agreeable action policies. I think the way politics happens right now, voting happens right now, is find the most agreeable action policy so you can maintain control as opposed to, say, what is the good policy? And this requires the level of epistemic rigor and epistemic security. I see.

**Speaker B:** My life's work is to focus on that question and bring more and more towards that. And if there are groups that we can work with, hell yeah, let's kick it. This is where we need to start. So if there are any organizations that are focusing on our priority cause areas, ~~know,~~ be it on ~~um,~~ climate, ~~uh,~~ change, or AI, or ~~like~~ nuclear consequences, or there's any organizations that are trying to do better on resource allocation where they want the resources to be able to do the maximal good for this specific community, I would love to talk to them. I would love to understand how the things we are building can be useful for them. ~~Um,~~ I think we need more experimentation of this sort. And, ~~um,~~ I'd rather have these experiments be with people that benefit from them in the immediate short term. Cool. **Speaker A:**  ~~Well, that's a great, uh, call to action.~~ ~~Um, I'm glad we stayed on the little extra to get, um, that final section. Um, I guess I'll ask again, anything else that we didn't last time? It was a fruitful question.~~ ~~Anything else that we didn't, uh, get to that you wanted to touch on?~~ **Speaker B:**  Nope. I feel complete. ~~Um,~~ thank you so much for this opportunity. It was lovely for it also made me realize the context through which my path has evolved. Like seeing the role forecasting can play hand to hand with collective intelligence and the failure modes of, you know, the current political processes or democracy or resource allocation makes me realize, oh, I see the role at this place. ~~Uh,~~ so this was great for me as well. So thank you. **Speaker A:**  Cool. Thank you, Dar. ~~Uh,~~ make sure I'm saying it correctly again. Dr. Tan, right? **Speaker B:**  Yes. **Speaker A:**  Der Tan, CEO of Mettaculous. Thank you for being part of the cognitive revolution. **Speaker B:**  Same here. **Speaker A:**  ~~Uh, great job about you.~~ ~~I think, uh,~~ some of your commentary, especially toward the end there, and think it'super fascinating. I'll hit stop.

