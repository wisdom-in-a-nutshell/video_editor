**Speaker A:**  Hi, Sam Oa, founder of Bismarck Analysis. Welcome to the cognitive revolution. **Speaker B:**  ~~Uh,~~ great to be here. **Speaker A:**  So you are known for your strategic analysis and for your super crystal clear monologues. I'm an active listener to your show that you do with Eric live players and definitely recommend folks check that out for in depth analysis of many of the nation state level live players. Obviously one of the hottest topics in the world today, and one that is gradually infusing all of geopolitics is AI. ~~That's, um, many dimensional topic.~~ But I wanted to start off before we ~~kind of~~ go deeper into different live players and what their interest and positions and strategies are likely to be. ~~Um,~~ just with a little bit of context on ~~kind of~~ your AI worldview. I find that many conversations fork early on, ~~um,~~ questions of just like, what do you actually expect to happen? Do you think that AI is going to get super powerful or not so much, ~~um,~~ and we'll leave any debate of that topic for another time. But I just wanted to at least give people a sense for kind of what your outlook is so that they can, ~~you know,~~ better contextualize the rest of your analysis. **Speaker B:**  I think that artificial intelligence is a fascinating test for people. It really, whenever you talk about artificial intelligence, ~~uh,~~ you end up having to look at basically all of the world models that one has. You have to employ them, you have to reconsider them, you have to check which assumptions hold in which assumptions should be dropped. I think it's, ~~uh,~~ fascinating how much people's expectations of the future of AI reflect their general thinking on technology, or even their general thinking on what is a mind and ultimately what human beings are and what is special about human beings. You might have people who greatly focus, say, on the lack of agency that the current AI models display. ~~Right?~~ You might say that actually that rather than intelligence is the most valuable thing, and then others would, ~~you know,~~ brush that aside and say, ~~you know,~~ all you really need is a for loop on, ~~you know,~~ already thenerative intelligence. First off, that's shown to be not quite true, but it is a fundamental question of whether something much, a very different process would be needed to produce age genic AI, or whether it's just a small tweak that we're going to get through, ~~uh,~~ through the normal application of gener AI. So first, to get it out of the way, I think there's been real scientific progress in the early two thousands on, ~~um,~~ just the computer science of artificial intelligence. The term AI scientist did actually make sense then. It still ~~sort of~~ makes sense, I think since the last four, five years, there have been new breakthroughs as the larger and larger models have been trained. However, to a great extent, we're merely applying, ~~uh,~~ these theoretical insights from the early two thousands. That's why there is a lot of disputation as to who ultimately should properly be credited for the so called transformer architecture that is now used to, ~~you know, basically~~ generate most of the tax that's behind LLMs. ~~Um, you know,~~ LLM is, in a way, a much less descriptive, ~~uh,~~ a m marker, right. It's a marker for an application rather than the technology itself. It's like talking about a car when, of course, there could be an internal combustion engine inside the car, or there could be an electric motor. I'm certain that, ~~you know,~~ now that there is demand, ~~uh,~~ for basically generation of text with, comes with, ~~you know,~~ generation of knowledge, that there will be architectural revolutions that will optimize for it even further than what transformers have done. So I do expect some continued progress in sort of the science of artificial intelligence.

**Speaker B:** That is, ~~uh,~~ the theoretical side, the architecture side, and the discovery of what do larger and larger in different kinds of data sets do. ~~Uh,~~ we are, in a way, discovering it. We don't have strong theory behind what's happening. That's an important thing that has to be stated. This is not similar to, ~~uh,~~ the development process of, say, supersonic flight, where, ~~let's say,~~ 80% to 90% of the science is just resolved. We have our models of physics. It's not pushing physics that much forward, except maybe some details of fluid dynamics, which are chaotic. We're just doing engineering on the basis of a theory here. The engineering has outpaced theory long ago, and we're continually surprised by what are essentially not just business ventures. They're not just launching an app. A ~~ah,~~ training run is actually an experiment. I think we should ~~think~~ of it as if we've built dozens of large hadron colliders around the world. ~~You know,~~ the scientific experiment on the border between Switzerland and France ~~at,~~ at CERN, ~~uh,~~ where they accelerate particles at great cost. Now we're ~~kind of~~ living in this world where, ~~you know,~~ 100 billion dollar valuations have become boring for some of these new software companies. It's no longer, ~~no one's~~ that excited. They're interested when yet another AI scientist goes off to fund their own lab. ~~Uh,~~ but that seems like table stakes now. So these ~~very,~~ very large training runs are legitimate, in my opinion, scientific experiments, they're not just normal technological development. Now, why did I talk so much about ~~sort of~~ the epistemology of this? Well, I think we have to be extremely cautious when making predictions. ~~I don't think~~ this is actually like Moore's law at all. I think that we are continually surprised by what these systems do and do not do. There've been already so many deviations from the so called scaling laws that I think we have to admit ~~that~~ that was perhaps not quite the correct hypothesis. ~~Right?~~ To give an example, ~~we're already,~~ we're not seeing huge improvements in output for improvements in compute, but we're suddenly finding ways to reduce the amount of compute to get the outputs that we already had. So in a way, AI is becoming more compute efficient. ~~Uh,~~ that's not what people were ~~predicting~~ six months ago. That's not what people were predicting. Experts, by the way, or at least entrepreneurs, let's say, if we make a distinction between expert and entrepreneur. 18 months ago. So truly, I think we do not understand the fundamental science of any of this. And I've tried, ~~you know,~~ in my own thinking, my research, both for personal interest, in a professional sense, deeply interviewing, ~~uh,~~ the best AI scientists I could find, and they have no consensus. They have no consensus with each other. So I think the enthusiasm over scaling laws was trying to invoke something like, oh, we ~~kind of~~ understand the physics of semiconductors. So it's only a matter of. Moore's law is ~~kind of~~ like intel's business plan, right? And it's an economic and social and, ~~uh,~~ technological law. But here we could encounter scientific barriers at any point. ~~So, you know,~~ there is no guarantee that simply throwing more compute will continue to work. We can expect more and more compute to be available, but perhaps as soon as there's enough data on what these training runs are doing, there will be a, ~~uh, there will be~~ some sort of scientific understanding of what this is. And I think that, ~~you know,~~ in computer science, there's always been this interesting question of how much useful computer science is there, actually, and how much is it just engineering and just application of the computer science to new and new problems? Here we have an open wide field of computer science. So this leads me ~~sort of~~ to the second point. Why is it important to carefully think about the theoretical underpinning, not just the empirical outcome of AI? Well, ~~uh,~~ this is my theory of progress. I would literally not even track who has the most compute.

**Speaker B:** I think that's important to know. You should have a little chart, a little table with the best information you can find. You need to update it, not quite quarterly, but you need to update it every six months because it changes pretty fundamentally. And, ~~uh,~~ people are going in depth, ~~uh,~~ trying to find ~~all of the,~~ all of the compute they can, all of the GPU's that they can. They're trying to strike deals, favoritism, all this corporate stuff, politics stuff. Super interesting. At the end of the day, I'm not going to bet on the company that has raised most money to have the most compute. I'm going to bet on the company that has the best AI scientists, right? So Demis Hasssab is, for example, at the end of the day, when you read what he writes, when you look at what he says, ~~um,~~ he ultimately wants to show and answer, he wants to answer questions about the nature of intelligence. Ilya Sukovar, he almost has like, almost this like religious air about him when he talks about the models, because to him, this is about the beauty of the universe, this is about the beauty of intelligence, right? This is about the discovery of it. ~~Um,~~ and I think when you hear scientists talk this way about their craft, about their field, ~~uh,~~ you realize that they have a very deep motivation. Now, this motivation might be assisted by a financial motive, a profit making motive. But let's put it this way. If I see an AI company where everyone is just trying to make money and, you know, it is possible to make money with AI, ~~uh,~~ it's harder than people might think. By the way, most of the, ~~uh,~~ air companies are clearly losing a lot of money very quickly, right? So I expect most of these to fold within the next few years with the giants remaining, because the giants just have way more capital to throw around, like whoever's working with Amazon, whoever's working with Microsoft, and of course, Google itself, ~~uh,~~ they're not going toa run out of money, right? They're basically like Saudi Arabia. They can build as many, ~~you know,~~ Saudi Arabia can build a line in the desert, right? That giant skyscraper that just goes to the desert, this pharonic gesture. Well, Google can build, like, pyramids of compute, and it would still be among the most profitable companies in the world. Microsoft can build great cigarettes of compute. ~~Um,~~ and they would still be a very successful company. So that's important to keep in mind who has money to burn. But merely having money to burn does not produce the breakthroughs. The breakthroughs will be actually from the who has the best AI scientists? And I do mean scientists, I do not mean software engineers. I don't mean data scientists. I mean people who you can, ~~uh,~~ people who you can figure out have both an intellectual excellence, an in depth passion, and are not easily confused by marketing or social pressure. There has been, in western civilization, a fundamental tension between science, engineering and commerce. The commercial mindset always involves talking up the current business plan, talking up the current, ~~uh,~~ approach to things. Science involves undermining it. ~~Right.~~ Science involves questioning the current approach. Science, ~~uh,~~ involves disproving the current approach. So you can see how in a corporate culture, these two can be intention. And most people, also very intelligent people, if they go to elite universities, by default, they're trained in agreeability. The purpose of the educational system is to train you up in agreeability. We basically destroyed the prussian science university. It took a century for the destruction to happen. But when we made the prussian research university model, when it was adapted, adopted in the United States and adapted to scale to most of the population, ~~uh,~~ it obviously can scale.

**Speaker B:** So something that was designed to sort of protect your PhD autists ended up being a degree mill and ended up being a necessary career step, not just here, but back in Germany and in the United Kingdom and in France, and actually now more and more so in China. If the talent distribution mechanism of your society is, is the same thing as the scientific mechanism of your society, that is also a contradiction, and that is a fundamental problem of western civilization. We do not know what to replace universities with. So why am I talking about universities in the context of AI? Like I said, AI, uh, is a good test. You have to go deep. So many of these top AI scientists were poached from universities that had good computer science departments, but these weren't even first year universities. Can you name a brilliant AI scientist from Harvard, has background, did a PhD there or something? It's kind of interesting. You see that canadian universities punch above their weight. MIT. Well, that's pretty predictable. British universities, french universities, for some reason. French mathematicians seem to have a knack for it. Anyone, uh, who was trained in the former Soviet Union for some reason, uh, you know, and by the way, that's not surprising. A lot of the mathematics underpinning modern models was actually developed in a compute starved environment as academic hobbies for mathematicians who are kind of trying to cope with the lack of good computers and, you know, trying to figure out new and more efficient ways to do things and working things out on paper rather than on huge training runs. Now, that tradition has developed immensely in the 1990s and the two thousands after the fall of the Soviet Union, but it's notable that a lot of these like academic lineages go back there. So after the launch of chaptt, I think we have stripped mind academia for all the good AI scientists. I don't think you have any truly knowledgeable questioners of the nature of the universe of the Iliautka left. I think they've all been struck minded. There was just too much money. There are mathematicians who for ideological reasons were not inherently interested in AI, but were scared of AI by basically Aler Yudkowski and basically things around that arguably turned how is in that category to some extent. And those mathematicians, I think will make modest or decent progress because ultimately if you have a holy terror of AI which causes you to change your mathematics, what you apply your mathematical expertise to, I think it can make you a very good engineer, but it makes you like kind of a m m mid m scientist. I think the curiosity, not the terror, is the actual underlying deep motivation which causes these like very uh, flawed human brains prone to various interesting cognitive flaws like wishful thinking and so on, to actually end up locking on to truth. This means that if someone wanted to, they could compile a list of all the AI scientists that are likely to be paradigm breakers. You wouldn't get 100% of them, you could probably get 90% of them. And you can chart which company has the most. And at the end of the day you can chart which company is likely to not be constrained by needing to develop a product. Let's remember that this, uh, breakthrough of application of chatptt came out of a company that people used to make fun of for releasing white papers instead of products. Like this is important to remember before its memory. Hold that OpenAI. You know, it wasn't just a, uh, corporate drama that came out of structuring it as a nonprofit. They basically gave the best AI researchers they could find. Tenure. Like, they basically were just publishing white papers and they were working very hard. And they were motivated by this vision that AI will transform the world. They were recruited by literally Sam Altman and literally Elon Musk.

**Speaker B:** Working together like that's in the prehistory, including things like giving Tesla gifts to ~~uh, uh, to uh,~~ the early employees to encourage them. ~~Right. Um,~~ to go do that. And I think that cannot be recreated in the current environment. So it's ~~sort of~~ decaying. ~~Right.~~ And if you look at the key people like Dario Mae and like Ilya Suutar and ~~you know,~~ maybe others in the future, ~~uh,~~ this dream team has ~~sort of~~ split, ~~um,~~ apart. Now. I think they have likely trained up a large number. ~~Uh, uh. I mean,~~ not large. I think they have trained up significant human capital. So anyone who was working with them in that initial period before the entire planet decided OpenAI was a huge success. Those people, if they were AI scientists, not software engineers, I think they're underrated, and I think people should be trying to poach those because, ~~you know,~~ like I said, academia is strip mind, which places we're still producing and training people in the scientific mindset, rather than an entrepreneurial mindset, a hype mindset. Let's be real. ~~Like,~~ I feel like generative AI is now as much of a buzzword as web three ever was. It's web four, basically, right? It's ~~like,~~ what is supposed to save the balance sheets of all the investors and all the major corporations and actually Blackrock. And when you add it all together, ~~you know,~~ really, the US has no plan for solvency except for an AI, ~~uh,~~ revolution, right? ~~Like,~~ that's the only way in which the western world can achieve collectively four or 5% economic growth per year. Now, of course, ~~f~~ I worked in this promised way, we wouldn't have four or 5% a year. We might have like 10% growth a year, or 20% growth a year. Truly singularitarian numbers. ~~Um,~~ but, ~~you know,~~ if it works only the way it's working right now, I don't think there's any chance that this results in a five or 6% rate, ~~uh,~~ of GDP growth. There's no chance it automates labor fast enough to counteract the global labor crunch. And I don't think we are focusing enough on the science of artificial intelligence and asking the deepest questions and, ~~um,~~ investing in the most esoteric mathematics. One way to put it is that imagine a world where it was easy to raise money to build particle accelerators, but it was extremely hard to raise money to let, ~~uh, AI, uh, theoreticist~~ theoretical. Sorry to use the analogy, imagine a world where it is easy to raise money to build particle accelerators and employ experimental physicists, but it is difficult to employ and protect for longer periods of intellectual development theoretical physicists. That is a world where we would hit a wall in physics very quickly. And I think artificial intelligence, it's much closer to physics than it is to, I don't know, fintech or, ~~uh,~~ Moore's law or something like this. So that's my ~~sort of~~ contrarian thesis. We've undervalued AI science. We've overvalued AI compute. We overvalue, ~~uh,~~ raising huge amounts of money to, ~~like,~~ quickly enter the AI race and undervalued longer, ~~uh,~~ term plays to cultivate top AI talent that is intrinsically motivated by their curiosity to push forward this frontier of understanding. And I think it's just because a single AI product went viral. And here's the spiciest take I have my spiciest take. Had OpenAI not gotten chat ~~CPTT,~~ had chatpt not been viral for whatever reason, probably two or three UX decisions could have killed it, to be honest. It would have enthused experts and some top programmers, but the general public would ignore it. I think we'd actually be making more theoretical progress because the dream team would still be together and the intent would still be on the white papers, ironically. **Speaker A:**  Should, uh. **Speaker B:**  Like, you should. ~~You should. You should.~~ You should interrogate these five or six heresies, because I don't think anyone talks about it this way. ~~I've been, like,~~ surveying the entire discourse landscape, and I see very few people arguing these points, so I'm happy to be challenged on them. **Speaker A:**  ~~Yeah, I think there's.~~

**Speaker A:** You've touched on, like, ten different things that could be full discussions unto themselves. Some of the ones that I think I agree with, assuming I'm interpreting you correctly. ~~Um,~~ I always say the transformer is not the end of historyes, and it's important to remember that, ~~you know,~~ we've had, ~~uh,~~ for much of our lives, the sort of, ~~you know,~~ end of history vibe, and obviously we're now shaken out of that. I think the AI community, maybe not the top thinkers, ~~you know,~~ not the top scientists that you're talking about, but the community at large has experienced a somewhat similar thing where there's been this sort of, well, we just scale up the transformer, and we'll keep doing that forever, and that will deliver, ~~you know,~~ the sort of transformative outcome. And I personally don't rule that out, but I expect that there will be more theoretical and, like, we'll probably never find out, because I think we will see more theoretical advances. That will mean we're never going to run the trillion dollar transformer, ~~uh,~~ experiment, because there will just be other things that will be sort of better. **Speaker B:**  It's good to remember that diffusion models are what's generating all the images. It's not transformers. So what is it? If transformers are fully general intelligence in the bedrock of it, why are they so much worse to generating images than diffusion? I think that we are seeing the cambrian explosion of the different definitions of intelligence, right? The cambrian explosion with this event on prehistoric earth hundreds of millions of years ago, where suddenly there was a vast diversity of multicellular cellular life that came to be. It's, like, visible on the fossil record. I think for most of our history, we have had only human and animal intelligence, and we added a tiny bit of computer intelligence, which I think is different and kind than human and animal intelligence. And now we have added even more forms of human. Sorry. We've added even more forms of computer intelligence. Right. So I think that already the Turing machine was already a form of artificial intelligence. I think we're eventually going to have a periodic table of elements of different things that can be called intelligence that are fundamentally different processes. So I think we'll have qualitatively different processes that can produce outputs that we would call intelligence, but they will be fundamentally different processes with different properties, different strengths, different weaknesses. And, ~~uh,~~ I think that will be surprising to us because we're used to thinking of intelligence is a single thing. ~~Uh,~~ because the evidence is pretty strong in human beings when you do psychometrics and cognitive science, that humans are just kind of doing one thing super special. ~~Uh,~~ but, you know, maybe the universe doesn't work that way, right? Maybe human intelligence was like the hydrogen atom, the first atom that happened, that comes into existence in the universe. But then very quickly, the stars start making helium and iron, and then the supernova start making, ~~you know,~~ uranium and all these heavier elements that, ~~uh,~~ near star fusion can t produce. So I really do think that, ~~uh,~~ we are going to be continuously surprised at the strength on reasonable effectiveness of various forms of intelligence as we discover them, but also surprised and shocked by their weakness. Right. Why do AI agents, when you put generative AI, when you put transformers on a loop, why do they melt down into incoherence and don't pursue goals and cannot actuate and cannot act on the world? ~~Like,~~ that's a surprising thing. I don't think people expected that if you. If you told someone 20 or 30 years, the kind of verbal behavior these. This intelligence is capable of, ~~uh,~~ they would assume it's trivial to use the words to command a robot and have the robot do things, right? I think they would assume it's trivial, but it turns out it's not. Or they would assume it's trivial to have a representative.

**Speaker B:** Wasn't that the thesis of, like, a hundred startups five minutes after Chatptt came out, the personal assistant, and they're just not. You know, you can use them, but you can use them the way you can use a calendly link. You can't use them the way you can work with an executive assistant. A human executive assistant. **Speaker A:**  So there's a lot there that I really agree with. And ~~I think you're, uh, sharp to emphasize.~~ I use the term Cambridge explosion sometimes as well. I also have started to use the term mixture of architecture'era to signal ~~sort of~~ the end of the transformers era and the beginning. And I think we're just very much still in the beginning. Butes, ~~uh,~~ folks who listen to my feed know that I have an obsession with state based models. And the big reason for that is that I see it as one of the first new core mechanisms that performs basically on par with the attention mechanism. ~~But~~ notably, as you said, does have different strengths and weaknesses, which you ~~sort of~~ have to drill down to a very small level to really distinguish. It's quite interesting that at the high level, when they train like a state based model versus a transformer model, at scale, they look pretty similar. They qualitatively, you can chat with them. They seem to have, ~~like,~~ reasonable memory. When you drill down into the micro skills, you find that there are like, kind of two sides of, ~~uh,~~ a coin, sort of different strengths and weaknesses. And not surprisingly, based on that, some of the most exciting new things coming out these days are hybrid structures where you have, ~~uh,~~ an integration of these things. When I just think about, and, ~~um,~~ I'm no expert in neuroscience, but when I just look at sort of a picture of, ~~you know,~~ a brain, an anatomy textbook, I sure think, ~~you know,~~ yes, there's, like, some parts of this that are kind of highly repeated. You'get your kind of cortical column that's like, definitely a main piece, ~~you know, that is~~ repeated a lot and doing a lot of work. We also see just a lot of other parts. And so it does seem like we're headed for, ~~I think~~ a periodic table, ~~uh,~~ is a pretty good mental model for it. We'll have a lot of these different, specialized, not even full architectures, but components that you can kind of snap together in all sorts of different ways. Going back to just the ~~sort of how, let's say, uh,~~ Eric always asks questions in this way, so I'll do the same. If you're advising a national government, President Harris, ~~uh,~~ comes to you and says, ~~um,~~ okay, ~~you know,~~ a lot of hype out there, obviously, though, a lot of undeniable progress, too. How should I think about how extreme things could be? ~~Like,~~ I hear you, that the agents aren't quite ready and that, like, GPT four, ~~you know,~~ is still ~~kind of~~ a slog to implement. ~~Um,~~ and, ~~you know,~~ probably is not going to be transformative. But, ~~you know,~~ there's a lot of buzz about a possible GP five and the GPT six behind that. ~~Um,~~ how would you ~~kind of~~ characterize, ~~you know,~~ for somebody that doesn't have time to get into the science, like, what the sort of range of plausible outcomes might be or ~~like,~~ what they need to be prepared for? **Speaker B:**  Well, I think the possibility of a compute race should be kept in mind. But a compute race is not a software company race. It is a hardware race. So if you want to preserve the us capacity to engage in a hardware race, I would advise the president, and especially, you know, in an ironic twist, ~~maybe~~ President Trump has already received, ~~you know, former~~ President Trump has already received this advice because recently he went on air saying, oh, we're going to need to double the energy supply for compute. I'm like, wait, where did you get that talking point? ~~I don't think.~~ I don't think he read about it.

**Speaker B:** I don't think he asked Chati, someone who kind of knows what they're talking about must have spoken to him. So I would say to President Harris, if Kamala becomes President Harris, ~~um,~~ I would say that you will have to pursue an industrial policy on semiconductors and an industrial policy on energy. And the thing that I, ~~you know,~~ my libertarian friends will most disagree with me. ~~Um,~~ I'll just say it will require government action, not just the government getting out of the way, but the government buying compute in America. Even TSMC cannot run a chip fab in America and have it be as profitable. No matter what they do, the unit costs are 50% higher. ~~Like,~~ Morris is on record for having said that. So if TSMC can't do that, how could intel? And if we're doing free trade, even with our allies, this means the second largest chip fab, ~~uh,~~ might be in America, but not the largest the free market will not provide. So I think the answer has to be something extremely politically difficult. I think we need to create a new Silicon Valley. Let's remember, Silicon Valley originally meant silicon. ~~Right?~~ It meant hardware. ~~Right.~~ When I saw, ~~uh, you know,~~ there's a wired article a few years ago, it was titled Shenzhen is the Silicon valley of hardware. I was like, I felt my, ~~like,~~ heart drop. I was like, ~~oh, no.~~ Oh, no. The valley has no idea how much trouble they're in. And my friends at the time made fun of me because I was saying, ~~no,~~ no, you don't understand. If they dominate hardware so thoroughly, they will easily reverse engineer software, too. And they're going to have their own unicorns. And they're going to have their own software giants. ~~Well, you know,~~ my friends don't find it so strange. My clients don't find it so strange either. Now that we are discussing whether to ban TikTok, ~~right? Like, um,~~ obviously China can build software startups now. No one's wondering that. ~~Uh,~~ obviously, Baidu is. Honestly, it is about as good as Google, actually. They're, ~~like,~~ keeping pace, not just with the stuff we did three or four years ago. They're keeping pace with things like self driving cars and driving their own progress just as fast. ~~So really,~~ the hardware thing is going to be difficult. It's going to be difficult because you won't be able to do it like NASA. The political economy of NASA is that NASA has to do something in all 50 states, because otherwise it can't protect its budget. It has to give something to every single state, or states will go against it. However, that's not a good way to build rockets, right? SpaceX doesn't have to have a facility in all 50 states. Right? SpaceX's biggest client, of course. ~~You know,~~ I think it remains the government, though. Starlink is genuinely going to be a very different model. ~~Um,~~ but I think there has to be a move to do the politically difficult thing of designating a zone, ~~uh,~~ probably a port city. And it doesn't have to be, by the way, the Bay Area, maybe California is actually difficult to deal with, and you want to do it in a different state. It has to be a federal designation, get every single regulation out of the way. ~~You know, the.~~ The Arizona plant and the delays there. You've heard of that? **Speaker A:**  I've heard a bit about it, for sure. I know the. **Speaker B:**  Yeah. **Speaker A:**  Daycare requirements and so on. **Speaker B:**  Yeah. So much of it is stuff that has nothing to do with manufacturing the chips. It's literally like, how do we comply with the building codes? I'm like, well, what if we didn't worry about the building codes and just build the chip fab as soon as possible, right? It would take that kind of mentality where you create an american special economic zone and you demand, you buy a lot of compute there. Honestly, you know, given the density of data centers in Virginia. Heck, maybe you do it in Virginia, right?

**Speaker B:** Maybe you go retro, you put it on the east coast. I'm not sure if Virginia would play nice with that, but maybe it would, right? Maybe the federal government partners up with that one individual state, and then we build a full stack, somewhat subsidized, somewhat expensive chip, ~~uh,~~ fab. ~~Uh,~~ set up there, and then we have the capacity to win a hardware race. Let's be real. We shouldn't be seeking a hardware race with China because we'll lose it if it was actually an existential military exercise. China can destroy Taiwan. It doesn't need to take Taiwan. It can destroy Taiwan and can make it hell to get ships out of there with chips. And, ~~you know,~~ what are you going toa do then? Are you going to invade the chinese mainland? ~~Like,~~ what the hell? ~~Like,~~ are you going to nuke China? If you do that, China's going to nuke you right back. The people who are calling, ~~you know,~~ shout out to Leopold, right? Like, the people who are calling for this, ~~like,~~ massive build up, I'm like, no, nobody. We have to be much slower with this. If America wants to win an industrial race, it just needs some industry first. And America's industry is ~~like,~~ it's pretty good. But the fact that, ~~you know, let's put~~ this way, America is the industrial peer of China. Sorry. America is not the industrial peer of China. It is the industrial peer of Germany. So every single thing you can say about the german economy and how it sucks and how they've been deind industrializing, well, guess what? We can say that about american industry. It's just that America is not just a Germany. It also has, ~~like,~~ a giant software sector. It has finance, it has service sector. All of this other stuff that Germany has less of. ~~Uh,~~ so we sometimes forget that, ~~you know,~~ when we look at these GDP numbers, it's not really american manufacturing driving those. And american manufacturing does not outperform dutch or german or south korean or japanese manufacturing. That's why ASMl is in the Netherlands. Okay? ~~Uh,~~ that's why Samsung is, ~~like,~~ a korean company, not an american company. So that's. That's what has to be dealt with. Right? So because of that, I actually think it's a hopeful message geopolitically that this might be yet a scientific ra. However, I'm sure, ~~uh,~~ that if the intelligence explosion theories are correct, that there's, ~~like,~~ a key event after which there's a beautiful feedback loop that then results in kind, ~~uh,~~ of a single singleton style future, ~~uh,~~ where, ~~you know,~~ whoever starts this will just be so far ahead exponentially every few years, they'll be hopeless to catch up. We have to preserve industrial capacity for that era because at the end of the day, ~~it's.~~ It's not like it's easy to coordinate allies. So even Fren shoring does not fully work. And, ~~uh, you know,~~ I'm not sure which president has the capital, the political capital, to push for a functional industrial policy rather than like a pretend industrial policy, ~~uh,~~ where we have to do something in all 50 states. **Speaker A:**  Yeah, I want to get into the chip ban in a second. And I definitely, ~~you know,~~ by the. **Speaker B:**  Way, the Chipan is, of course, a subsidy for american companies too. When I say subsidy, I don't just mean literally giving them a trillion dollars, though. Hey, maybe we should try that, right? Do you remember that infrastructure bill? Can anyone point to a single bridge built from the trillion dollars of the infrastructure bill? A single bridge, right. We could have a trillion dollar chip bill, and maybe even some chips would get built. Who knows? **Speaker A:**  Yeah. I mean, so I'm, I'm very allergic to, ~~I guess,~~ the whole US China conflict. I mean, we could do hours probably, ~~on,~~ on this from kind of beginning to end. **Speaker B:**  ~~Um,~~ but in brief, viewbr economic competition with China. And stop emphasizing the geopolitical angle, because that's really how China thinks of it. They think that they will win the geopolitics through winning the economics.

**Speaker B:** Like, every single chinese party document that comes out, you know, they talk a little bit about belt and road, but they sort of know it doesn't work. What they really want is to be the economic hegemon. And because they're orthodox Marxists, if you, ~~you know,~~ here's a funny one. They were such orthodox Marxists that they decided to, ~~uh,~~ own the means of production. And they thought that results in global dominance by literally owning the factories that build all the stuff. Right? ~~Uh,~~ and they weren't averse to using free market capitalism to get to the point where China owned the means of production. So I think that's their theory of geopolitics. And they think of it, they don't think about it as it, ~~like,~~ imperial way that we in the west think of it. The chinese approach to dominance. It's more like, it's not that you go out to the periphery and you conquer all the periphery, which we could say is the roman way of building an empire. It's more the, you consolidate and unify China, and then you outshine and extract tribute from all of the periphery. That's the chinese model of empire historically. And I think these different set of assumptions are there, right? Like, ~~you know,~~ for everything we can say about China is ~~like,~~ can we name a single country that China has invaded since their last war with Vietnam? Like, that's been over half a century ago, right? ~~Like, it's,~~ it's been a long time. The last place they annexed. You could argue maybe it's Hong Kong, but really it was Tibet. And from their perspective, Tibet, Hong Kong, Taiwan is just unifying all the chinese lands. ~~Uh,~~ so I think the economic competition and having a smarter trade policy, ~~uh,~~ I think that is the right approach to think about China and like militarizing it, or like having a rhetorical point where you emphasize the national security angle. I think that is likelier to cause them to also build up military capacity. ~~Right.~~ I think ~~that's,~~ that's likelier. And I think the US in the 21st century should strap in for the long game of beating China economically over the next 50 years. And it will take 50 years. China will not implode in five years. It will not implode in 15 years. It'll take 50 years to beat China economically and once more manufacture, ~~uh,~~ high technology here in the United States rather than in East Asia. **Speaker A:**  So before going a little bit deeper on China, I just wanted to zoom out for a second and ask if you see any other live players on the global stage that you think we should factor into this analysis. I look around at the US. I agree with your general sense that like most of the second tier of AI companies, even those that have raised in the low billions days seem to be numbered. That used to be ~~sort of~~ somewhat spicy take, ~~uh,~~ to ro your term, but, ~~uh,~~ increasingly, as these sort of aqua, higher type deals are happening, it's actually now becoming, ~~I think, sort of~~ consensus that leaves us with maybe like five companies at the top, depending on exactly how you'd want to count. I would certainly still put OpenAI, anthropics and Google in the top three just by the kind of sheer excellence of the science, ~~you know,~~ and obviously they've scaled, but they seem to have a know how that is ~~kind of~~ still cut above. Meta has definitely crashed that party in a meaningful way, although I wouldn't put them quite at the top tier. And then I would never count out, ~~uh,~~ an Elon company. So I definitely would put an x AI slash Tesla, whatever, ~~you know,~~ kind of in that same, ~~uh,~~ category. Yeah, same, ~~you know,~~ let's call that the top five. When I look around the rest of the world, ~~you know,~~ then I ~~sort of~~ have China as like a buc, ~~um,~~ and then I'm like, maybe we could see a european champion.

**Speaker A:** There's mistral, ~~you know,~~ Europe maybe wants a european champion, but obviously they're, ~~you know, a bit of~~ a harder environment to do business in. And it's unclear, ~~you know,~~ exactly how that's gonna play out. Maybe somebody from India, maybe somebody else. I'm not thinking about, ~~um,~~ any other. Before we zoom back in on China, which I think is inevitably where we're going, is there anybody else that you would say really has to be watched on the global game board? **Speaker B:**  I ~~think~~ not quite yet, but ~~I think~~ ten to 15 years from now, ~~not ten, maybe five years from now,~~ ten years from now, ~~uh,~~ there will be a formidable indian, ~~uh,~~ giant. I think that India is very likely to develop its own software ecosystem. And if they decide to eventually go the route of favoring indian companies over western companies, ~~you know,~~ that's a, ~~uh,~~ one and a half billion users right there. That's large enough. That's the same sort of initial captive audience that, ~~uh,~~ chinese companies enjoy and that actually even a russian company Yandex enjoys, right. Yandex ~~kind of~~ is the russian software conglomerate. They basically do almost everything that, ~~uh,~~ western software companies do, including having a self driving, ~~uh,~~ program of their own. ~~Uh,~~ they're not leaders in any sense, but they demonstrate that even if you have ~~like,~~ a very small market of users, which honestly, like 100 million users is really not that much, but if it's, ~~you know,~~ behind a digital wall or a regulatory wall, well, then you can do, ~~uh,~~ a very similar things to Silicon Valley. Even if you have much less money than Silicon Valley companies, you can do for a few billion what in Silicon Valley is done for tens of billions or hundreds of billions. And I think the indian situation will be very similar. Something will happen there, I think, for Europe. I'm more bearish on Europe after, ~~uh,~~ Macron stepped down, because I think Emmanuel Macron was personally convinced of the importance of artificial intelligence, had personal contacts with silicon valley, championed and push and, ~~uh,~~ pushed against german regulators, ironically, using french pull and weight to have french diplomats argue against regulation. ~~You know,~~ think how dire it is if french diplomats are going around Europe arguing against AI regulation while the Belgians and the Germans are going wild and having fun, ~~uh, you know,~~ restraining them. And, ~~uh,~~ it went as far as, ~~uh,~~ the french state was, ~~uh,~~ trying to do the best it could to recruit people into Paris. This was a smart strategy. With the exit of London from the European Union, Paris could have become the startup capital of Europe. Now, if a future french government picks this up, and let me explain a little bit, ~~uh,~~ France still has excellent mathematics education. They still have lots of field medalists and so on. ~~Um,~~ you have the raw talent there, ~~right?~~ So they don't need to poach from MIT. They have their own mini mit, ~~right?~~ So they have a university there. It's a big city, so you don't feel like you're in a backwater. ~~Um,~~ and if the french government gets off your back, you're not even getting in trouble regulatory wise. Like, in theory, you could actually do a startup if the french government went, get, got out of your way and gave you some tax breaks and all of that stuff, and also actively invested into seeding an ecosystem there. So I think it remains an option for the next four to five years for a french government to continue this strategy. I'm just not sure if they will. ~~Right, like, that brings us back. Yeah, yeah.~~ **Speaker A:**  ~~So I guess quick time check, because I'm happy to go past the hour again if you can. Um.~~ **Speaker B:**  Mhm. Yeah, let's continue. **Speaker A:**  Okay. So then that brings us back to us and China. I would love to get a maybe the brief version of how you understand why the US and China are at such odds in the first place. I don't have a great account of it.

**Speaker A:** I start like you, with a sort of naive, ~~uh,~~ observation that, ~~like, you know,~~ neither one is, as you said, like, we're not gonna invade the chinese mainland and they're not gonna invade, ~~you know,~~ North America. So we should seemingly be able to coexist, ~~you know,~~ each comfortable in the fact that we've got these huge ocean buffers. And yet all I hear, I feel these days is out of, ~~like,~~ the DC establishment in general, China this, China that, ~~China, China,~~ China. And it's also now moving into the AI discourse in a way that I think is quite unhealthy, where it's like, ~~well,~~ if we don't race to develop the most powerful technology that we can as fast as we can, then, ~~you know,~~ we're just seeding the future to China and we're ~~going to~~ have to live under chinese values. And I swear to God, people who say that, I always want to know, ~~like,~~ what is your definition of chinese values that you are expecting us to be living under? Because ~~I'm. I,~~ uh, think that's just, ~~you know,~~ often such a Raapid comment. But anyway, why do we have this? ~~Um.~~ And, ~~you know,~~ I guess the next question that you can maybe carry on into is, is there any way for us to avoid the AI arms race or AI cold war with China? The chip ban, to put my cards on the table seems like a step in the wrong direction in that it can only be interpreted from their side as at best, an attempt to keep them down and at worst, an attempt to create decisive strategic dominance over them. And obviously neither one, ~~you know,~~ sounds very good from their perspective. So I. Yeah, why do we have this? Is there any way we can avoid an arms race? And you know, what would you to maybe go back to the advising, strategic advising frame? What would you advise the next president to do about the shipb ban? **Speaker B:**  ~~You know,~~ I think the chip ban is too little, too late. I think that had it been something that was pursued in like 2010, ~~uh,~~ China could have been taken off the track of developing cutting edge chips. What the Chipan has done now, it's not sanctioned to China, really. It's given a subsidy to chinese chip manufacturers. ~~Right?~~ So if you can't buy the best Nvidia chip, or if you can only buy a nerfed version of it, ~~well~~ guess what? A chinese chip designer or manufacturer only has to compete with the nerfed version, not your cutting edge version. ~~He just.~~ They just need to do the nerfed version better. Slightly better. And ~~uh,~~ a ~~uh,~~ chinese giant or company becomes viable because there is enough chinese commercial demand for GPU's, right? They have a huge tech ecosystem, like dozens of companies. Dozens of huge companies. They're equivalent of Google, their equivalent of Amazon, they're equivalent of ~~uh,~~ OpenAI, right? They're equivalent of Waymo, ~~uh,~~ they have their equivalent of meta, they have their own ~~uh,~~ demand for this. And ~~you know,~~ the government in China hasn't really even started buying GPU's at all. If they wanted to, they could make it a national priority. And we've basically announced, hey, it's a national priority for you to develop your own high end chips because we're not going to sell them to you, not now and not in the future. And the chinese government is rich enough to afford that. I think people really don't understand that America is not the only country in the world it can drop a trillion dollars in a serious problem anymore. China could drop a trillion dollars on this problem if they choose to, or a hundred billion or 50 billion. ~~Right?~~ In the us context, the US has not dropped a trillion dollars on this. It's only dropped 100 billion. ~~You know,~~ we dropped a hundred billion on it ~~and,~~ and we get an Arizona chip. **Speaker A:**  Fab.

**Speaker B:** **Speaker B:**  Um, meanwhile we drop a trillion dollars on building bridges and it's not clear we built any bridges, so I find that super funny. Anyway, ~~uh,~~ the future here will rely on, ~~uh,~~ a general industrial revival in the US where I do think the energy angle is the right one. I think we should seek to radically increase energy production, electricity production in the US, because then it makes sense to run data centers in the US. And energy is one of the few things where, ~~you know,~~ labor costs are not a big cost in producing electricity. ~~Right.~~ So I think that would be a good, ~~uh,~~ medium term advantage. ~~Um,~~ and I think that also the scientific question is an interesting one as well. I do think we have a scientific advantage over China, but not a technological advantage. So I think something very good can be done in terms of smarter scientific grants, even if the Chinese is inevitably copy whatever the science, ~~uh,~~ discovers or produces a few years later. I think that, ~~you know,~~ one of the us advantages has been DARPA. ~~Uh,~~ and having a good understanding of how DARPA works. ~~Well, maybe~~ you should have a DARPA focused exclusively on artificial intelligence and you have to staff it with ideologically diverse people. So don't just hire all the easas, ~~you know,~~ even if, ~~you know,~~ Jason Maen is listening to this podcast, ~~you, you know,~~ the current CEO of Rand, ~~uh,~~ and ~~you know,~~ Holden Karnowsky and all of the EA royalty, ~~uh, you know,~~ they can certainly have a few program directors at the AI DARPA. They just should not be allowed to appoint all of them. So that ~~would be, you know, uh,~~ my other advice to the president ~~would be, you know,~~ uh, Madame president or mister president, whatever it might be. ~~Uh, you know,~~ we have to have ideological diversity because this is no longer just a technology. People are pursuing their end of the world cosmologies here. It's ~~like, you know,~~ sure the Manhattan project can be 50% marxist, but maybe keep it just 50% marxist. So similarly, the AI DARPA, ~~uh,~~ maybe it can be 50% effective altruist, but keep it at 50%. ~~Okay, so,~~ so sorry not to pick on EA, but they're like a big, ~~you~~ also wouldn't want it to be more than 50% EAC, whatever EAC even is ideologically. ~~Right.~~ It's just the case that a lot of people will, ~~you know,~~ they will pay lip service to the United States. But ultimately, if you look at their ideology, ~~look,~~ if you have a utilitarian ideology, you are not always a friend of the US, you are mostly a friend of the US, but you're supposed to be thinking globally in the future, light cone and all of that stuff. You are incidentally not fundamentally patriotic. And I don't want to overburden the patriotism because patriots can be dumb. Patriots often do very noble and excellent things, but it's very easy to weaponize patriots against free speech. ~~Like,~~ that's happened many times in the history of many countries where countries embark on a stupid course of action because proposing the smart one sounds like a little bit less nationalist than the alternative. ~~He.~~ That's why the empire of Japan failed. It was too unpatriotic to suggest that maybe Japan cannot beat the United States and maybe Japan should not bomb or destroy us ships, ~~right?~~ That was just end patriotic. And, ~~you know,~~ the outcome was not one that I think chinese nationalists appreciated when the full course of history Iran. So let's put this way, I think currently the United States is. It has to play a very careful game, ~~uh,~~ because it is not the world's industrial giant, as it was. So the game has to be, ~~uh,~~ scientific, low energy costs, very smart government spending. We'll have to have much smarter government spending on strategically relevant science, not more of it, smarter. Because the way we're currently spending, ~~uh,~~ scientific money is that, ~~you know,~~ we're literally giving the Wuhan Institute of Virology money to produce new plagues for the world.

**Speaker B:** That's kind of insane, right? That was partially us funded. That, mind you, is now well documented. It's long ago lefty Alex Jones or even Joe Rogan world. It's now just congressional testimony world. **Speaker A:**  So a lot of ~~tradeeads~~ there that I want to pull on. **Speaker B:**  ~~No, we can,~~ we can go a few more minutes. And again, I invite push back. I put, put provocative things there because we need to have real and honest conversations we can't be following. **Speaker A:**  ~~Corporate sounded perfect, whole.~~ ~~Now you're breaking up on me. Oh, sorry, I don't know if you.~~ ~~Can still hear me.~~ ~~I can hear you.~~ ~~Can you hear me? Ye, you'back. It was. Yeah, yeah, you're back. Um, connection has been flawless until just the last 30 seconds.~~ So I just, ~~um. So~~ I'm broadly very much with you when it comes to. Okay, let's get our own house in order. Let's like, throw up some nuclear plants, you get the energy, ~~uh,~~ you know, flowing more freely. ~~Uh,~~ all that stuff sounds great when it comes to the. I do understand that Chipan, in a similar way, that, like, we're inviting them to develop a strong industry, and I don't doubt their ability to do it, to do so, ~~um,~~ it may take some time. I don't know how long it's going to take, but you. I always say I watched them throw up a hospital in a handful of days, ~~you know,~~ at one point. ~~So, um,~~ I don't want to be caught, ~~know,~~ underestimating their ability to create a chip industry. I also think there's just, ~~uh,~~ an interesting ~~um,~~ question of ~~sort of~~ do we want to be developing this technology in tandem, or do we want to be running on ~~sort of~~ parallel tracks and having, like, secrets from each other and all of the things ~~that~~ that implies? ~~I don't necessarily know that you meant to imply this with DARPA, but when I think DARPA,~~ I ~~sort of~~ think, like, secret technology development. Some of that stuff obviously finds its way into the, ~~you know, the~~ broader world, but some of it is secret. ~~Um, do you that~~ we should. **Speaker B:**  I think the US government kind of sucks at developing secret technology. I think the US has great strength in its commercial sector, which is, by its nature, public, even if you have trade secrets. Right. You know, Nvidia has trade secrets. TSMC has tradequens. Secrecy, in that sense, makes sense. Secrecy in a, uh, top classified, you know, top secret classified something. Well, let's say, I think the world war two era us government could do that. Well, we are not dealing with the world war two era government. If you declare something classified and top secret, the result will not be a technological breakthrough. It will just beized, uh, it will be waste shielded from oversight. So I think that, you know, there can be clandestine projects. It's sort of like, well, how exactly? We apply artificial intelligence to the NSA's work. Okay, that can be secret, but commercialization. And by the way, the intelligence world has done this through institutions like Inql. Right. Uh, any technology you can declassify and hand over to Silicon Valley or America's commercial sector, you should. Right. You should just do as much of that as possible, even if it means that China catches up to Silicon Valley three or four years from now, uh, because of what you declassify to Silicon Valley. Because the true advantage of the United States is its vast wealth and the speed of its scientific progress. And when you make something secret, you stall scientific progress, you don't accelerate it. **Speaker A:**  I also worry that this combination of trying to deny chip access, which is not going to work entirely, but, you know, may make for at least some asymmetry. ~~You know,~~ China might be looking at a situation where they're saying, geez, we can only get to 20% the compute capacity that the United States can get to. And also they've got, you know, some secret military science programs that we don't have much.

**Speaker A:** Of course, they might hack into those, um, you know, perfectly capably, who knows? But let's say they, ~~you know'~~also, like, genuinely worried that there are secrets that they are not able to learn. It worries me ~~that~~ that might send them down a totally different branch of the technology tree. And when I think about, ~~like,~~ how do we get into an arms race? That would be a really, ~~you know,~~ bad situation versus how do we avoid it? One key factor there seems to be are we ~~kind of~~ on the same general technology path, ~~you know,~~ such that there is ~~kind of~~ a, ~~ah,~~ shared understanding of what everybody's working with versus to what degree do we look at the other side as ~~kind of, you know,~~ the great unknown that we can project our fears onto and then motivate ourselves to, ~~you know, take higher risks, um, you know,~~ be more militaristic in our technology. **Speaker B:**  Historically. Historically, that's always been the case. Right? It's even when, ~~you know,~~ the US and the USSR signed a treaty banning biological weapons development in the late cold war, both side scientists were, of course, told that now you should get to work, because, of course, the other side is ignoring this treaty, and we don't know what they're doing. So you best develop, ~~you know,~~ the worst plagues you can think about. ~~Uh,~~ the worst plagues you can think of. And even during World War Two, the fact that Los Alamos scientists greatly overestimated the state of german nuclear research is what allowed the project to be completed before the end of the war and be used in Japan. I think the weaponization of AI is, ~~like,~~ troubling. And I think part of it is that, ~~you know,~~ scientists are like everyone else on some level. They think weapons are cool and they want to develop cool weapons. So if they find a way to make physics a weapon, people get very excited. And I think this is one of the problems where, you know, we crave peace as a species, but we also crave violence. And I think a lot of the time, we should actually be very mindful of our motivations for developing breakthroughs. I think that it is best if artificial intelligence is a peaceful technology for two reasons. First, we do invite existential risk, like, and human extinction into the equation if we're trying to develop literally weaponized or malevolent AI. Dude, Skynet is not just a movie. It's a Pentagon pitch deck at this point, right? ~~Like. Like,~~ if you could deliver half of what, ~~uh,~~ Terminator films depict, if you could deliver half of that, the Pentagon would just give you a trillion dollars, ~~like,~~ right away. Right, ~~uh,~~ Skynet. But a pitch deck would be, ~~you know,~~ that would probably work, but that's like, ~~kind of.~~ We're developing the worst technology first. When we think of it in a weapons'context, we will not be prioritizing safety, and we will be teaching an artificial intelligence to win at zero sum and adversarial games and to win at logistical and military games. And I think, ~~you know,~~ it's completely predictable that if you could have an ageentic artificial intelligence that decides humanity as its enemy, ~~like,~~ that's literally the plot of Terminator and all of the AI safety people made fun of it for decades. But if you just look at how the military world is ~~perceeding~~ AI, you realize ~~that~~ that's like, actually extremely bad. And if you make it a geopolitical conflict, that the generals will ask you to just build Skynet, please. ~~Right?~~ They will just ask you to do that. ~~Um, don't.~~ Don't build Skynet, bro. Just don't. I know you think it's cool. I know it feels really good, but you're gonna regret it, right? Just as Oppenheimer regret it now after he got the high of the detonation, then he regretted it. And that's the hypocrisy of human nature. But, ~~you know,~~ hopefully we can grow from that. So let's not make it cool that way. Let's not fetishize the Manhattan project. Let's not do all of that.

**Speaker B:** And instead, let us be curious explorers of the universe and figure out what is the nature of these new forms of intelligence we're discovering, and let's apply them to our economy to compete with the chinese economy in who can get richer faster. **Speaker A:** ~~Yeah,~~ I love that vision. ~~Um, just to put one little bit, we're going toa have a full episode on this coming soon, but a little bit of meat on the bone on,~~ because I think some people might be thinking, okay, sure. ~~But~~ what does that actually ~~m~~ mean to have weaponized AI versus non weaponized AI? One proposal for AI safety that I just, ~~um,~~ have been reading through is to train AI's so that in general, you have these loss functions. **Speaker B:**  Right. **Speaker A:**  In the training process where there's some objective that you're being optimized, you, the AI are being optimized toward. And a huge trend in general in the literature is to have a supplemental element to that loss function that in addition to. So you have the one component of loss function ~~that's~~ can you do the task? And then there's some other thing ~~that's~~ ~~like, uh,~~ but we also want to emphasize this. And that could be like sparsity for efficiency or for interpretability or what have you. So this really interesting one that I just came across, ~~um,~~ was about minimizing self other distinction and m trying to create an AI that had the same internal state, regardless of whether it was, ~~uh,~~ referring to itself or referring to someone else. And they've ~~kind of.~~ This is like very early proposal, but they've come up with all these different scenarios in which they think there's really no need for the AI to have a different representation ~~of this, um,~~ of these concepts just because it's referring to itself versus someone else. So let's try to minimize those differences. And they've been able to show in ~~like,~~ very simple, ~~um,~~ reinforcement learning scenarios that applying this technique can be the difference between agents emerging, that deceive other agents, or that don't deceive other agents. And I think this is ~~like,~~ one of the best ideas that I've heard in a while for how to create AI's that are ~~sort of~~ the, like Kumbaya, ~~uh,~~ all, always one. We're all sharing prosperity sort of mindset that. That we might hope to have. But obviously, that's going to be like a real problem if the goal of the AI is to, ~~like,~~ distinguish between friend and foe on the battlefield. ~~So.~~ Or at least it seems like you, those things might be quite incompatible. So I do think that there is, like, real. We're so early in it. ~~Uh,~~ we've ~~kind of~~ just got these things to work right. We've just ended the transformer for everything, ~~uh,~~ era. And we're just barely getting into the lots of different components to make tons of different architectures era. And we don't know that much about this stuff yet, but it sure seems like we could optimize for telling friend from foe and you killing foes. ~~Um,~~ or we. ~~Could you~~ take some more time and be more creative and come up with some of these ideas, like minimizing self other distinction. And that just seems like such a much better idea to me that I would really love to see us go down that path. So the Leopold plan. I want to ~~kind of~~ give you a chance to maybe articulate, ~~uh,~~ the samo plan. The Leopold plan, in brief, as I understand it, is we should, ~~um.~~ You do everything we can to keep China down for the time being. ~~Um, so~~ we have a couple years lead. We should harden our defenses. We should get the national security establishment and the AI labs into some sort of public private fusion partnership. ~~Um,~~ we'll keep all the secrets from trying to. That way, they'll be denied the chips then, because we are the good guys, ~~of course,~~ we will use this lead that we have to solve. Alignment. Obviously, details will be filled in later. ~~Uh,~~ I don't.

**Speaker A:** Too unkind to this plan, but I honestly don't really like it. ~~Um,~~ and then once we've done that, once we can then approach China from a position of decisive strategic advantage, then, because again, we are the good guys, we can approach China with, ~~uh,~~ the offer of benefit sharing and then we can ~~sort of~~ maintain american hegemony and american, ~~you know,~~ western civilizational values will prevail. ~~Um,~~ and China will ~~kind of~~ recognize that. Better to take the deal at that point than to what alternative will they have? Will have super intelligence. How would you, what's your alternative? ~~Uh,~~ vision for how, ~~uh,~~ leadership can conceive of a plan for the next, however many years in AI that would. **Speaker B:**  Contrast against that geopolitical leadership of this. Let me start at the end of the plan and work backwards. The US cannot credibly offer benefit sharing of this kind. The US allowed Germany and Japan to rebuild their economies after world War Two because it was interested in the containment of the Soviet Union ~~and the Soviet Union was a threat.~~ Had that not been the case, perhaps Germany would have been deind industrialized in 1946 rather than 2024, which, ~~you know,~~ mind you, is partially the US is doing through the destruction of nord stream. I'm just happy to say it's overwhelmingly clear the US did that. ~~Um,~~ the second step. So the offer cannot be credibly made, therefore the Chinese will not accept it. A step before then we solve alignment. Because who is we? Who is we? ~~Who is we?~~ What set of institutional or political forces in the us government would result in an accurate scientific understanding of alignment, assuming that is a coherent problem and make rational bureaucratic, committee driven decisions in line with that. ~~I mean,~~ sure, if we appoint a benevolent dictator of AI, which of course, if we take the premise as a benevolent dictator of the United States and of the planet. ~~So, you know,~~ so much for american freedom loving values. Perhaps that is the true convergence all along. And then we go a step earlier where it's ~~sort of, you know, this,~~ this kind of hardening. The only way you can truly make the american technology stack u ~~um,~~ um, secure against China is to make it secure against us citizens. So the idea of an open digital society, a creative digital society, I know open source, ~~you know,~~ people talk about open sourcing the weights, but I feel the vision of the social revolution that was supposed to happen because of the digital revolution is so lost at this point. I think we all want to have a closed Internet, we want to have a monitored Internet, we want to have a censored Internet. Right? Like that's what it would require. Do you scrub AI, ~~uh,~~ leaks, ~~leaks~~ would happen. There would be an Edward snowden of AI. Would you scrub that from the western Internet? Perhaps using AI to hunt down all instances and mentions of it. Like our problem is without an open source, open access, citizen participation vision of our Internet, if as soon as we abandon that, we actually go on the treadmill first towards being like the EU and then even worse, being like China. I've written an article on this. Unfortunately, this article has aged well. It is ~~uh,~~ called the centralized Internet is inevitable. And for example, the only break in social. In the escalating trend towards social media censorship that is suggested. And by the way, this is documented by things like, ~~uh,~~ you know, WikiLeaks and so on, ~~uh,~~ the US, various parts of the us government, just to suggest, oh man, sure is a nice software monopoly you got here. It would be a shame if someone antirusted it. ~~Uh,~~ can you remove the social media post or can you unbank this person, this Alex Jones person? He's a problem. Do you remember that happened in one day, all the major social media networks decided to deplatform him.



**Speaker B:** We should be thinking of it in terms of developing ~~uh,~~ the us sector ~~and~~ us economy, ~~and~~ we should justify it in that language. ~~And~~ it should ~~be~~ a set of give and take negotiations with China over splitting the global economic high. It should not be a set of give and take negotiations over splitting the light cone. ~~Right? It shouldn't.~~ That invites the wrong kind of logic and invites the wrong kind of bureaucratic incentives. ~~Like,~~ it's almost ~~like~~ these people never seen how bureaucracies work either. ~~Uh,~~ the large corporate environment, let alone a government environment. You have to be extremely careful. The first misaligned artificial intelligence was arguably bureaucracy. Let's prompt engineer it really, really carefully. **Speaker A:**  It's poetic. ~~Um, I like it.~~ ~~What do you think is the,~~ I have maybe three and a half more questions ~~if you have that much time.~~ **Speaker B:**  ~~Um,~~ I think I have to go, unfortunately, but perhaps I can come to your show again. **Speaker A:**  Okay, cool. ~~Um,~~ sounds great. ~~The three just to put ain, uh, for later question. Okay, I'll give you all three, and you pick one.~~ ~~Um, is going to be,~~ how do you understand the role of open source in this situation? That is at least at the moment, ~~uh, know,~~ a sort of irrevocable benefit sharing proposal, among other things. ~~Um, then,~~ though I also wonder, let's say we do continue to see more and more powerful AI and we start to get to a point where it's like actually this is starting to look dangerous. Is there any sort of, ~~you know,~~ precedent that we should look back to or any framework that you would look, ~~um,~~ to for how do we set up global coordination and containment of the technology development? ~~Um,~~ another one was going to be on sovereign ~~a~~ AI. This would probably save for the future. But if you're like any of the other 100 plus countries in the world beyond the two that we've ~~spend~~ most of our time talking about, there's this notion that like we should have our own models, or we should take a base model maybe from meta and train it on our bureaucratic information or whatever. I wonder if you think there's any value in that. ~~Um,~~ and the final one, personal angle, is to what degree do you use generative, ~~uh,~~ AI in your personal work today and what sort of value, if any, are you getting from it? So you can, ~~uh,~~ tack. Answer away for that? Pick one ~~or you just come back next time.~~ **Speaker B:**  Answer. I'll answer. ~~Um,~~ I check in every now and then and use generative AI to see where it is. ~~Uh,~~ it's not really a big part of my workflow because it usually provides me the consensus or the general thinking in a field. And almost all of my work is trying to find spots where the economic or political consensus or industry consensus is flawed or overlooking things. So in a way, ~~high schooler~~ interns, not yet useful. Maybe I'll check in when it can give me a Harvard intern who honestly, between you and me, are, ~~uh,~~ not that useful either. You ~~kind of~~ have to be even pickier than that if you're doing research. So I don't think it is useful for novel social science research yet. And because of that, I don't use it. And stylistically, sometimes it writes, puts things into words about as well as I do. The problem is it does it in a recognizable way. So I can't even use it in my personal writing because it can't really do my voice. And you know, I can always tell, ~~uh,~~ since one of my part time, ~~uh,~~ one of the hats I wear as say occasionally, I am m an editor for other people's writing, ~~right,~~ for ~~um,~~ Palladium magazine. I sit on the editorial board. I can always tell when they use AI.

**Speaker B:** And almost always it makes the writing worse, because just as people have become sensitized to so called AI slop in a visual sense, people have become sensitized to reading stuff that sounds like AI. I've actually had to change my own style to be a little bit different so that people aren't confused about how this text is generated. So yeah, I think it's not even useful for all white collar work. Not at all. I'm sure it could schedule, ~~uh,~~ it can write probably a good rescheduling email. I think that's about the level where if Google makes a feature where they ~~like,~~ tweak or improve the UI with, ~~you know,~~ my inbox, like get the suggested text a little bit better, maybe I'll integrate in my workflow there. But ~~uh,~~ yeah, I'm not yet making use of the available intelligence. ~~It seems to low great,~~ ~~well, we.~~ **Speaker A:**  Will continue to watch that closely. And ~~um,~~ I may have a couple, ~~uh,~~ I'll share a couple ideas with you, perhaps offline. I'm ~~m~~ working right now on fine, ~~um,~~ tuning some of the latest models to write as me and I' completed this project yet, so I don't know how well it's going to work. In all previous generations that I've tried to fine tune, it did not work. ~~Um,~~ but there have been some notable improvements in the capability, actually, most importantly, probably the context window, ~~um,~~ because I found in the fine tuning it could pick up my style okay, but it couldn't learn the facts and it still. **Speaker B:**  ~~It'~~Learn unique ideas or theories and so on. ~~And perhaps~~ with the larger context window, ~~it'~~be ~~cap of it.~~ Yeah. **Speaker A:**  Yah. The hope is I can stuff all my stuff in there and, ~~uh,~~ it might not have to hallucinate anymore. For starters, I think I will still have to give it ~~like~~ the kernel of the original idea that I have in the moment. I don't think ~~it'snna~~ at the current generation substitute for me there, although we'll find out. I'll definitely let you know if it does. ~~Um,~~ but my hope is I can give it the kernel and then I can give it like a lot of background and then train it on my style and get kind of interesting outputs. But I'll let you know if that, ~~uh,~~ starts to materialize. That's my current, ~~um,~~ AI obsession. ~~Uh,~~ I know you gotta go. This has been fantastic. A, ~~uh,~~ lot of really interesting things to think about, and I will look forward to, ~~um,~~ maybe getting into sovereign AI. And I'm sure we'll have plenty more developments on the, ~~uh,~~ us, china. ~~Uh,~~ I don't want to say conflict because I want to frame it. Let's frame it as friendly rivalry, ~~uh,~~ hopefully competition, constructive. ~~Yeah. Um,~~ but yes, this will be certainly a very active, ~~uh,~~ area for continued strategic analysis. For now. Sam Bura, founder, ~~uh,~~ of Bismarck analysis. Thank you for being part of the cognitive revolution. **Speaker B:**  T until next time. **Speaker A:**  Thank you. Thank you. Thank you. Great job, ~~uh,~~ as always. **Speaker B:**  Hopefully this was interesting. Hopefully machine m audience will like it. **Speaker A:**  ~~Yeah, I think so.~~ I think.

