**Speaker A:**  You know, we do edit the show, so any, ~~uh,~~ interruptions, you need to take a break, somebody comes in, no problem. ~~Um,~~ we will also offer you, if you'd like, the opportunity, but not obligation, to review our edit before we publish. Most, ~~um,~~ people don't take us off on that, but it's totally up to you. ~~Um, some people have like, corporate requirements where they have to, um.~~ **Speaker B:**  Sounds good. **Speaker A:**  So it's a standard offer. ~~Um,~~ have you seen my outline? I assume that made way to you. **Speaker B:**  I did, yeah. Yeah. Look it. Cool. So we can certainly previous chapters you've done too, so I'm excited to be here for it. **Speaker A:**  Great. Thank you. **Speaker B:**  Uh, aw. **Speaker A:**  ~~Um,~~ we can certainly deviate from that. If there's anything you want to add or subtract, ~~you know, whatever, it,~~ it's all good, but at least that's a good starting point~~~, hopefully~~~. **Speaker B:**  I think it looks good. ~~Um,~~ I love going organic and just seeing where the conversation takes us. ~~Um,~~ I do think talking a little about approaches on such a technical alignment is something that I find pretty interesting. ~~Like~~ before metaculous, I was, ~~um,~~ leading AI objectives in institute, which is a research lab that focuses on context in which alignment manifests today. And I find that to be quite interesting as a counterweight. ~~Um,~~ we can talk about that a little bit. ~~Um,~~ but yeah~~~,, um,,~~~ overall~~~,, um,,~~~ I feel good. First time I'm doing a podcast also~~~,,~~~ so I~~~,, um,,~~~ am interested in seeing how that goes. **Speaker A:**  Love it. I take a good amount of pride~~~,, actually,,~~~ in having a lot of first time podcast guests~~~,,~~~ so that's cool~~~., M cool.,~~ **Speaker B:**  ~~Um,, so,, yeah,,~~ maybe we'll just start~~~.,~~ **Speaker A:**  A little bit with that at the top~~~., Yeah.,~~ **Speaker B:**  Um,,, because you said we will edit it,,, I guess I can like,,, say,,, can we do a ret take of a part or something?, And that's fine., **Speaker A:**  Yeah,,, it's totally fine., Um,,, we even,,, in theory,,, have AI tools that can help us with that to a certain degree now,,, although we do have,,, uh,,, a human,,, uh,,, oversight still in place for now,,, at least., **Speaker B:**  I think where the tech is at right now requires this., So I think that sounds about right., **Speaker A:**  There is actually later today I have an interview with the CEO of Descript,,, which we use for editing,,, and they have recently launched a set of new features that collectively they call Underlord,,, which I think is funny., It's kind of obviously a play on overlord., The idea is the AI,,, you are the overlord and the AI is the underlord., Um,,, but they do have a like,,, retake removal where you can do these retakes and then just say,,,, like,,,, remove my retakes and it will,,,, in theory,,,, go through and cuddle that stuff., So,,,, yeah,,,, it's new., I wouldn't say we've like,,,, battle tested it just yet,,,, but., So,,,, yeah,,,, maybe put a little bit of your kind of background at the top and then,,,, um,,,, that can inform other things we talked about., But does that sound good to you?, Just start with that., **Speaker B:**  That sounds good., I can also get to the background more from,,,, like,,,, how did I start focusing on forecasting?, I like the order of questions you put on on,,,, you know,,,, about you fire., And then we can go from there and I can share,,,, you know,,,, what my interests are in the space and go from there., **Speaker A:**  Okay,,,, cool., Can you pronounce your name for me so I can make sure I'm saying it correctly?, **Speaker B:**  It's dare., Like truth or dare?, **Speaker A:**  Dare., Okay., **Speaker B:**  And last name to run., **Speaker A:**  Dare to run., Cool., Um,,,, well,,,, let me get., I kind of lost my voice at an event this past weekend,,,, and it's mostly back,,,, but it's not a hundred percent back,,,, so I apologize for,,,, um,,,, not sounding my very best,,,, but here we go., Dertron,,,, CEO of Metaculus., Welcome to the cognitive revolution., **Speaker B:**  Thank you., Big fun here., **Speaker A:**  Thank you., That's kind of you to say., I'm excited for this conversation., I've been a metaculous watcher and am I saying that right?, By the way,, let me make sure I'm pronouncing the company right,, too,, **Speaker B:**  Yes.. Yes.. **Speaker A:**  Ok.. Metaculous.. **Speaker B:**  We got a lot of meticulus and meta calculus,, um,, which are both reasonable.. I like what those signal as well.. But metaculous is what we go.. **Speaker A:**  All right,, cool.. So I've been a long time watcher,, and you've got some very interesting new projects,, which will be kind of the bulk of our conversation today.. But maybe for starters,, you're relatively new,, uh,, to the job,, just ~~a handful~~ few months in ~~the CEO role there.. Want~~ as CEO.. Wantingto give us a little bit of your background in AI?, Because you've been working in this space for years before that and made a move that,, um,, you might want to unpack a little bit in terms of why shift into forecasting realm now?, Right?, **Speaker B:**  Guess hindsight is 2020 especially in context like forecasting.. Um.. I've always been interested in questions around collective intelligence.. How can we aggregate multiple different perspectives into one coherent world model?.. And um.. while still at school was working on this question from perspective if natural language processing could help?.. This was way before LLMs back then during year '16... Um... how could multiple streams be aggregated such thought became actionable policy making tool?... So Federal Agencies became target audience along startup building efforts within same field

**Speaker B:** And right before metaculous, I was working on AI Objectives Institute, which is a nonprofit research lab focusing on socio technchnical alignment, which is looking at questions of AI alignment in context of real people in deployments right now, and seeing, are there any technical steps we can take that can actually say this group of people do perceive this AI model as better aligned or more instrumental towards their goals? ~~Um,~~ looking at it from an individual perspective and from a collective perspective, and from a systems perspective on understanding how can these tools be much better used for enhancing human agency? And I've been doing a lot of work on questions of collective intelligence. How can we augment, ~~um,~~ a multitude of different views to be able to contribute to a system that might be a single modith, or it might be multiple different agents collaborating. This might be a government, this might be an LLM, this might be an ensemble model. This is in a way applicable to many different systems. **Speaker A:**  ~~Right?~~ **Speaker B:**  And, ~~um. Um,~~ very quickly I find myself thinking about, ~~okay,~~ say we can aggregate multiple people's desirabilities. Even if we are able to do this on a high fidelity level, how do we get to the world outcomes that we're looking for? How do we actually go towards the model that is not just driving towards the lowest common denominator, ~~um~~ , and finding a consensus mode where the desire for consensus actually causes a trade off with fidelity to one's perspective, but instead see what would actually be helpful. What future do we want to live in? Are causes prioritized correctly so that we can move towards better futures? Can we find positive sum games? ~~Um~~ , who will shoulder the externalities? ~~Um~~ , if there is no free lunch, how can we make sure we're tracking that? And these questions brought me towards thinking, okay, who's looking at the world from a perspective of, if we take action course x, will that yield a better outcome? And that's how I found myself thinking about forecasting. Because if I'm able to even have a very high fidelity version of desirability, elicitation ~~preference~~ , elicitation, understand all the cruxes that exists in society, that still does not bring me towards a machine system being able to take actions that yield net good. So exploring that, along with the questions of wisdom of the crowd, if you have multiple different perspectives, be these be real humans or AI, that is actually once aggregated is doing a better job in forecasting outcomes. I realized this is actually quite instrumental in how we look at the world. ~~So~~ , ~~um~~ , that is what brought me towards thinking about more forecasting. Cool. **Speaker A:**  Just two. Rewind back in time for a second to the 2016 era. Did any of that stuff work? Were you able to make anything with technology that was available at the time that you thought yielded any practical utility? **Speaker B:**  ~~Um~~ , yes. Well ~~~~ , back then I was working actually with ~~um~~ , Dan Jfsky ~~um~~ , on a question at Stanford on ~~um~~ , federal agency regulatory feedback. So the FCC net neutrality debate was just taking off ~~~~ , and there was 2 million comments that were submitted to the federal agency. And at that point this seemed like ~~wow~~ , this is the largest data set that was ever collected of ~~you know~~ , raw text. Now ~~~~ , it's ridiculously small ~~~~ , but at that point there was this question of ~~okay~~ , how should a central agency pay attention to this? There was a lot of interesting questions. Like ~~ah oh~~ , lot of the submissions were form letters that are copy paste ~~but ah oh um~~ . But the fact that it is copy paste does not make it illegitimate ~~you know ah oh um ah oh um ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know ah oh um you know I will read~~ , I will read ~~you know~~ , a campaign and say ~~yeah uh huh right ok cool great yup aha aha aha aha aha aha aha aha aha aha aha aha aha aha aha aha haha hehe huhu hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi hihi haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha hahaha hahaha hahaha hahaha hahaha hahaha hahaha hahaha hahaha hahaha hahaha hahaha hahaha hahahaha hahahaha hahahaha hahahaha hahahaha hahahaha hahahaha hahahaha hahahaha hahahaha hahahaha hahahaha hahahahaha hahahahaha hahahahaha hahahahaha hahahahaha hahahahaha hahahahaha hahahahaha hahahahaha hahahahaha hahahahaha hahahahaha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha he he he he he he he he he he he he he he he he he he he he he he he he he hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe hehe heheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh eheheheh ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe ehe eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh eh 																														 yeah i agree with this i want to send this how should u take into account compared to u no something tht bot generated compared something tht u genuine opinion tht someone has taken time but its not necessarily sophisticated n u can see tht it has shortcomings n 	 my thesis work i was looking both legal perspective n also technical perspective u no what expectations from u no EPA n EPA perspective on just us legislation but also how can we have natural languageing augment this 	 	 funny enough at tht point i was thinking lot questions good hearting like every time we start focusing specific narrower metric it ceases good measure n this very apparent being able claim tht ur looking public 	 things tried were so simple n yet they seemed like 	 	 paradigm shift 	 just like simple clustering strategies unsupervised learning topic modeling 	 even tht went long way because people had no idea n now we can do much more sophisticated versions n people still are like people assume tht we dont need ask these questions because cannot do large scale qualitativeveys so keep going back Likert scale so guess crusade ive been long while can go past uh how happy are u one seven or should build road from b or c im like maybe need build bridge instead n if dont let people express tht ur just not going get tht opinion so how do get machine learner systems optimizers be able understand uh there something qualitative tht need elicit tht even speaker might not sure what want like how can give room for tht human flexibility these misschions cannot hear sorry

**Speaker A:** **Speaker A:**  There's a little construction outside my, ~~uh,~~ window, so I'm muting the mic sometimes, but. And then I've got to remember to unmute it. ~~Um,~~ so your comment on goodharting definitely resonates with me, particularly today. I was just, ~~uh,~~ having some back and forth on Twitter about the new GPT four o mini model, which is coming in ahead of claud 3.5 sonnet on the, ~~uh,~~ LMC leaderboard. And that raises the question. It seems like the general consensus among people like me who are obsessed with the latest AIs'and, ~~kind of~~ have their own individual opinions, seems to be that 3.5 sonnet is the best. ~~Um,~~ certainly we ~~all~~ would all tend to think it's better than GB 400 mini, and yet there it is, ~~uh,~~ ahead in terms of the votes that it's getting. So this has raised all sorts of why is this happening? Do we trust this thing anymore? ~~Um,~~ is it just about formatting? ~~Is formatting.~~ If it is mostly about formatting, does that mean it's ~~like,~~ illegitimate in some way, or does that mean we should really think more about the importance of formatting? ~~Um,~~ but yeah, ~~it's very.~~ As always, it's extremely difficult to pin much down if you really want to do it, ~~um,~~ with any real rigor. So ~~that, um, is maybe a good bridge toward.~~ And certainly the same is even more true about the future. So I've been interested in this space of forecasting for a long time. I actually participated in one of the original, ~~um,~~ tetlock organized super forecasting tournaments maybe 15 years ago now. ~~Uh,~~ Tyler Cowen posted, ah, an invitation to participate, and I was like, I'll try it in my hand at that. I did reasonably well. I wouldn't say, ~~um,~~ I didn't top the leaderboard, but I came out feeling like I had at least somewhat of a knack for it. And I've always found that the sort of Robin Hanseson perspective on this seems like a much better way than sor of highest paid person's opinion or whatever kind of prevails in organizations. ~~Um,~~ that's always been compelling to me, but it seems like generally speaking, we still don't see a ton of forecasting deployments in the world, I guess. What would your analysis be of kind of where we are in forecasting, where you think the most notable deployments are, and why we don't see more than we do today? **Speaker B:**  Right. I want to answer from the previous point you made around good hearting because I think this actually goes towards there and you know which model is better? Define better right? Better is incredibly content specific like even in just a small world of things I am trying to do personally within metaculous clau like 3 point five is more useful for me on question writing but not necessarily fact retrieval And it's a very narrow thing And this current version of these models seem like you know one of them has an easier knack towards one thing without interrupting without self censoring so I can move forward faster I think core forecasting also relates to this in terms how can this process actually be useful? Is one thing different from you know will it score good on these benchmarks? Like in this one specific competition will you know 4 point oh score better? Like that is a much narrower thing In a way Usefulness is almost always anecdotal and I think we are not paying enough attention to that And I think same as applicable for forecs Well there has been so many tournaments like latest know like ACX uh 2023 tournament interesting for how accurate forecasts have gotten Um but me okay how going actually be useful for an end user different question And I think approach really want focus on with metaculous upcoming sprint okay we have couple validations you know feel satisfied What those One wisdom crowd works interesting works when aggregate number people go into when aggregate number bots um trained LLMs what have seems able draw accurate picture future enough case studies Why not commonly used usefulness whole different paradigm accuracy really want focus What Toa do front example identify critical inflection points towards future states different question just forecast accurate shape world want live entities You know federal agencies prior work philanthropists corporations nation states framework forecasting especially te talking lens focused how actually useful improve accuracy move forward coming versions forecasting deployments actively pay attention decision maker take account things within space levers why context humans trying live better life extremely important Um share examples front curious where you'to go But um pretty much research agenda metaculous next chapter next um two quarters heavily focuses lot experimentation kinds questions **Speaker A:**  Yeah interesting Does look basically conditional **Speaker B:**  Markets

**Speaker A:** **Speaker A:**  ~~Um,~~ being ~~kind of~~ the first thing, I mean, that's something that Robin Henson has talked about for a long time, and I don't see much, but we've just lived through a moment in history where it seems like something like that was pretty motivating to the current president of the United States, ~~who I, uh, think was,~~ if reporting and general intuition are correct, seems like he was not sold on the idea that somebody else had a better chance than him until he saw polling data suggesting that and then was ~~kind of~~ like, well, I guess, yeah, if somebody else has that much of a better chance, maybe I should step aside. ~~Um,~~ is that the sort of. Obviously play that out a million different ways for a million different context. But is that the kind of next big paradigm? **Speaker B:**  I think that is an example that basically is, ~~uh,~~ a very simplified and somewhat was obvious to the entire population, except the decision makers themselves for longer than it should have, in my opinion, state of affairs. With that said, the real cases that I'm interested in is much more sophisticated than this, ~~right.~~ That heavily looks at public opinion and is more, I may say, like vibes based rather than data driven. And I'm interested in really pushing this edge further. Say we have $50 million to allocate towards making the world better. Pick your challenge. You reducing microplastics, climate related risks, AI related risk. How should we allocate these resources to get to a better world? Requires us to build world models. I think forecasts around what are specific outcomes we can get to if we take an intervention point is very helpful. And the simplest thing we can do is exactly what you said on you come up with conditional forecast. If we take lever x, will that bring us to a better future? If not, what will it be like? ~~Um,~~ and if we see high divergence here, that is great. Now I want to push this much further. We can already do this. ~~Um,~~ but throughuth test conditional questions are somewhat hard to answer. It's hard to think in that framework. So can we build tools, be it, ~~you know,~~ LLM driven or discourse driven, or come up with ways in which people can collaborate, that enable conditional forecasts to be more useful? This is one avenue. One of the things I want to do in, ~~uh,~~ the near future is launch a series of minitacul. This is the name we came up with. Think of it like subreddits, which is metaculous instances. This will come in context of us open sourcing metaculus, and we hope that many of these will spring in the next quarter. ~~Um,~~ each Mintaculus will be focused on a specific question, a goal oriented question such as we are trying to reduce microplastics for example or we're trying to reduce homelessness in San Francisco. This is geared towards disaster response or consequences of research avenues and context of AI. I would want every question in the minuteacul to be able to serve if we are able to answer this question it bubbles up to the parent and then we can see which of these questions have highest value information which ones actually inform us oh it looks like this intervention is going to be able to drive much further value i would want us to identify critical inflection points like is there a specific moment in which world models see diverge are we able extract schools thought context forecasting seeing oh uh this group forecasters seem be much more accordance over multiple forecasts why world modern divergent can double down finding more questions help excavate these kinds research go way beyond what metaculous aimed so far actively trying build model enclosed space metaculous spec goal find really interesting kinds love short term proxies heavily forecast both short term proxy good how short term proxy panning way landed fab uh forecasting benchmark basically guided also way um frame presidential debate through lens think civilization need think much from lens version cognitive revolution change people thinking future way enabling coordinate between world models still see forecast aggregation fairly low fidelity coordinate world models use building block primitive come much better models **Speaker A:**  So let's maybe take one step back just for those who maybe don't have so much experience with metaculous as it exists today ~~Uh~~ I'd be interested hear just starters how do you describe somebody who's never seen before ~~Um~~ would you call prediction market would you call forecasting platform how does fit because there's few these now right with people would familiar certainly online betting platforms also there's manifold polymarket see kind shared them around how would describe overall product today distinguish some other things **Speaker B:**  Mhm Metaculous aggregates forecasts It's forecasting platform aggregation engine

**Speaker B:** I would not call metaculous a prediction market. The goal of Metaulus is to bring a level of epistemic security towards how we envision the future to be. We can call it Wikipedia about the future, and it is a space in which multiple people can see how they foresee the future to play out and the critical discussions to take place there. ~~Um,~~ it works with predictions as its core block, but it does not have a monetary incentive. ~~Um,~~ it behaves quite differently than prediction markets as a result of that. And some of those differences are the reasons why, in my opinion, Metaculus has been both more accurate and also more rigorous compared to a lot of other spaces. ~~Um, uh,~~ I can shed more light into that. For example, on a prediction market, ~~the, uh,~~ participants are buying and selling contracts that are based on the future outcome of an event, right? So you place bets and the result is a zero sum question. For example, if the current forecast is at 60% and you think it is 60%, you don't have an incentive to add that information in because it only can get worse from there. While on metaculous, this is not the case. ~~Um,~~ there's no financial incentive, and instead we are comparing all the forecasters accuracy and track record through time. And, ~~um,~~ this creates a different set of incentives that I believe are actually much more productive towards something that looks like Wikipedia about the future, where people are one incentivized share what their world model is. Two, people are incentivized to participate in forecasts and not think about de risking or spreading, but instead focus on, ~~you know,~~ what is the world model that I have that I can share. So our scoring mechanisms are different with respect to prediction markets as a result of that, too, because the reward mechanism is that you reward a forecaster over time for their calibration across many predictions and for their accuracy. ~~Um,~~ we also have a metric that we call the community prediction. This is interesting because this is where you can see everyone that has predicted on this question. And we also have weighted averages depending on your past success on your track record, and the recency for sooner forecasts thand to be better for, you have more information. So using these, we actually end up in an ecosystem that is much more collaborative and much more grounded and good epistemicics. And this brings higher rigor as well. So the questions we forecast tend to be more like, ~~you know,~~ carbon emissions on this ~~d~~ , rather than very personal questions, ~~uh,~~ on you. Who am I gonna be dating with next? And I like that, too. ~~You know,~~ there's a market for that, but I like that there is a space for focusing on the rigor that is actually beneficial for the world. So that is what I find distinct and attractive about metaculous.

**Speaker A:**  Gotcha. So it seems like the big thing there is the incentives, whereas on a more market oriented platform, I am looking for things that are wrong so I can make money here. I am looking for just opportunities where I can share something with the community that hopefully brings ~~the overall,, uh,,~~ community forecast toward a more accurate.

**Speaker B:**  Right. But on top of that, I will add, there is a financial incentiment metaculous too as in if you have very good track record as a forecaster we will hire you as a pro forecaster to go engage on many specific paid client works And these range from federal agencies to large retailers to hedge funds think tanks that have much narrower questions These questions don't make their way to public forecast that we have they will be paid engagements we will also pay pro forecasters for their reasoning so they can actually explain why they see forecast to be this way Just to echo back to thing we were talking about I think one of core projects we have for metaculous going to be reasoning transparency The forecast on say I'm making up an example um say ~~we'thinking~~ about taiwanese sovereignty This was context in which this came up Um I was in Taiwan recently for conference we were talking about um will Taiwan you know electricity grid be um challenged by China as you know in process of potential invasion And um forecast jumped from 30% to 40% And there were no comments under it because it was fairly new And I was sharing this with you know one of ~~the,, uh,,~~ folks there working on from government'pers respective they were saying unless I know why this case cannot take into account And for that do pay our pro forecasters come up with better forecasts with their explanations well And um place people jobs past Um so there is way leaderard translate into uh financial incentives 

**Speaker A:**  Yeah.

**Speaker B:**  Opportunities happen on substrate question And think quite 

**Speaker A:**  Okay cool Can you say little bit more about how create community forecast out kind touch this briefly but this one big questions I've had um honestly long time because there two kind think them like canonical AI questions around AGI timelines I've come back years now think first tweeted about almost two years ago these weak AGI strong AGI unpack little bit minute

**Speaker A:** But one thing that I've always ~~kind of~~ wondered is, ~~like,~~ exactly what am I looking at when I'm looking at this? To what degree am I seeing, ~~you know,~~ is it a naive aggregation? ~~Um,~~ because you can go in there and put a whole distribution. ~~Right.~~ So I'm interested in your comments on that, too. Like, I don't have a great sense of what I'm doing when I'm, ~~like,~~ actually drawing a curve over the potential timeline of something happening. ~~Um,~~ I feel like ~~I'm a little bit like, you know, I mean,~~ I guess I'm always sort of viing with these predictions, but that brings it home to me where I'm like, boy, the precision here feels like I'm leaving something behind. That is, ~~you know,~~ it's weird, ~~right?~~ It's a way to express my uncertainty, but it's also a way to, ~~like,~~ be very specific about my uncertainty. And even that I don't feel like I really have so interested in sort of how you see that kind of curve drawing. And then how are you aggregating? All these curves into one curve. Like do people get UPW weighted if they're better? Is there a recency bias, et cetera? **Speaker B:**  So, ~~um,~~ couple different parts there. ~~Um,~~ with respect to the community prediction calculation, we basically keep the most recent prediction from each forecaster that we have. And, ~~um,~~ we wait each forecast based on how recent it is before being aggregated. And ~~um,~~ we also, for the Met tacless prediction, do pay attention, especially if there is you, a paid client that is looking for a specific outcome or higher rigor. We do do things like pay attention to the past track record of each of the forecasters and aggregate that information in as well. Um,
for binary question,
the commuter prediction is basically
a weighted mean,
um,
all of
the individual forecasters probabilities.
And if you have
a numeric question or
a date question,
it is
a weighted mixture of all
ofthe individual forecaster distributions.
Um,
there's actually
a lot
off different philosophies
off aggregation and this is one
offthe spaces that I am interested in experimenting further.
These are
the ones that we use.
And in general,
the community prediction works and seems
to be really accurate.
Um,
there may be
a couple
off folks that seemingly know consistently beat
the community prediction.
And I think,
you know,
there's
a couple posts,
um,
from like astral code,
ext ten,
et cetera,
that has focused on exploring this.
Um,
I think that I'm very interested in this.
Very soon we will open source metaculous.
I'm curious for people
to come up with,
you know,
hey,
here's
a difference scoring mechanism,
an aggregation mechanism that actually seems
to work better or seems
to be more instrumental.
um,
i really want
to encourage experimentation on
the space.
What we have so far seems
to work.
iif you just copy
the community prediction,
you will do pretty well in,
huh,
tournaments,
but then you're not really bringing in independent information,right?
sothe better question todoisfor someone todo their homework on,youknowwhat are past forecasts ,umthat mightbe similartothisand then contribute,and only afterthatyou see 
the community prediction because otherwise you start messing with 
the wisdomof 
the crowd.You said,youknow,you mightbe doing vibes based reasoning.I think alotofmore.So,youknow reasoning based forecasting endsupbeing space fora lotofpeople.Not everyoneis goingtobuildlikea mathematical vigoroous modelorbeadomain expert,butsomehow whenweput manyofthesetogether,it actually does yieldabetter outcome.Andcommunity predictionis our waytobeabletopreict **Speaker A:**  Yeah. Do you want to talk about the metaculous track record on AI forecasting in particular. ~~I think, um, that's obviously a very relevant data point. And then~~ I do want to dig into those two questions that I refer to most often a little bit more. Uh,
but maybe 
the general background would be good 
to share firstin terms 
ofjust establishingthat thereis some alphain 
the community forecast **Speaker B:**  Mhm.Uhwhat doyou mean?Ididn't understand.Umthere's some alth **Speaker A:**  Well there'sthis postonjust kindof breaking down 
the track record.Umthe meticulous track recordforAIforecasting.Umexploring meticulous'sAItrack recordandyouknow,Ibasically was hopingyouwould uh summarize thatorsharethe highlightsasyou seeit **Speaker B:**  Msorry pausing hereforMin.If there'sthis canyoufind.Let's findthespecific posifyouwanttozoominon **Speaker A:**  Areyouinthe.Um.I'll putit intothe chat.I'll puttwo thingsinthe chat.First,Ihavethe **Speaker B:**  There'sabunchofthings thataresomewhatsimilartothis **Speaker A:**  Well,you could certainly bringin anythingthatyouwant,but here'smy outline.Thisis whatI'mjust referringtoaswego.Andthen secondisthis post.But definitely feelfreetogobeyondthatorgivewhateveryouknowbest.Summer,youthink **Speaker B:**  Uh,wheredidyou,didyou pasteiton 
the endof **Speaker A:**  Oh yeah,youshould have.The UIhereis not surpr **Speaker B:**  Track recordonAIforecast.Oh yeah.Yeah.Thisisthe uh postbyPeter.Yeah,I 'm gonnaaskactuallycanwejust takeabrief nature break?UmI'll be adv **Speaker A:**  Sureasec.Yep,no problem.See youinasec.We're back **Speaker B:**  Cool.Can you hear me well ,yeah uh **Speaker A:**  Yeah,Ithinkso **Speaker B:**  I would love 
to go into like,Iwas just likelooking atmy uh notes.UmI'd love 
totalkalittle aboutlikeinteresting episodesfrom historywe would have caughtand.Right.That was

**Speaker B:** Maybe we talk about that a little and then we can shift to Aji questions slash d. ~~Um,~~ ~~the,~~ like, I just looked at the post from Peter. I can talk about that. This is very much around ~~like,~~ the scoring rules and scoring accuracy rather than ~~like~~ what are the takeaways from there? So I would address this in context of like some of the more recent things we are doing on this front, ~~like~~ ~~the um,~~ five years after, ~~uh,~~ AGI tournament. We can talk also about, ~~you know,~~ the questions that we have written on ~~the, um,~~ AGI question, like I saw on the doctor. So ~~like~~ maybe we can talk about those in a larger context altogether, rather than specifically dive into this post. ~~For.~~ I feel like the post is like a math lecture, almost like I can go into that, but I feel like it's not necessarily the interesting cy ofistry. **Speaker A:**  ~~Yeah, I mean,~~ I think my takeaway from that post was somebody had said on the Internet that the mettaculous forecast were no better than random. And it's basically a exhaustive, rigorous breakdown of why that's not in fact true. And, ~~um,~~ we can see that there is actually some amount of significant benefit to looking at ~~the,~~ the community forecast over random. But I do think that anecdotes or kind of notable examples are very much of interest as well. Please share. **Speaker B:**  So, sure. One of the things that ~~I,~~ I mean, I think it goes much more than, better than random, given that there's actually a lot of people using metaculous forecasts. Um, I would start from, for example, ~~the comparisons from~~ ~~the ah~~ 2023 ACX ~~uh uh contest is quite interesting for example to look at for comparison of know how does metaculous compare for prediction markets or super forecasters And~~ I really like Sasiti as an anchor for ~~I think they're actually doing a great job um as a reference point Um this doesn't you know I think to me~~ ,the parts of the question is like how to make ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts of~~ ~~,the parts~ forecast useful along with how to make ~~be accurate I think there is enough track record on a couple different forums like who predicted 2023 Best post from astral code Extent is quite interesting for this Um but if you've been zooming on specific moments where an entity be it a federal agency or a person was able to take action from a forecast I think those are moments where I see yes metaculous was actually useful or interesting Like for example in epidemiology metaculus has outperformed both panels of experts on Covid and also informed hospital resource allocation public health decision making Uh a lot~  forecasts were more robust and accurate than baseline models in predicting COVID vaccine uptakes. And ~~um,I do think that'quite interesting For example um and another part is on~ ~~-taculous um was able to quickly provide perspective on that front Um for example in January 2020 back when you Conventional wisdom was that Covid wouldn't be significant Metaculous instead was predicting that more than 100000 people would eventually become infected with disease And um a lot~  folks took that as ~~you know an early warning sign I remember reading a post about someone making a bunch~ investment decisions because metaculous said so.~  Like in other cases around predictions around Russia invasion of Ukraine there's a comment on metaulus that I really like where um,the metachulous user in Ukraine said just want to say that I moved from Kyivv Toiv on February 13 entirely thanks to this prediction thread and metaculous estimates Um like that to me is moment where yeah forecasts were instrumentally useful for someone making decision Like we've been you know ced in economist our world and data Bloomberg Fortune Forbes you name it~  core question is around how will these be able to turn into instrumental actions that one can take? And I'm particularly interested in this being helpful for AI sphere and making sure tools we're building AI as whole are actually serving humanity And if there is something good track record ability be able influence individual decisions we should explore why how this can be much more useful And lens which prioritizing AI important but also other cause areas Some folks say Mettachul should purely focus long term miss causes do think lot short term intervention modeling being able take successful action teaches us how forecasting can helpful longer term contexts Like questions how reduce homelessness San Francisco If have additional million should go build two more houses Is best thing Or form lobbying large crowd say make housing market understand negative externalities homelessness point have more well grounded change would minitaculous every forecast forecasts conditional intertwined each other explore different ways visualize them Like usefulness towards someone us being good repeata fashion help tackle largest questions much better **Speaker A:**  Cool Very interesting going two AI questions refer back most probably many listeners visited pages weak AGI strong AGI timeline Each one kind four different resolution criteria

**Speaker A:** And the question is basically, when will a single AI satisfy these different criteria? And you get to predict your distribution of dates. **Speaker B:**  Right. **Speaker A:**  I think this has been really interesting and quite informative for a long time, although more recently it does feel like it also highlights a real challenge of writing these questions, which is that when things are farther out, it seems like the. Or it can seem. I feel like in this case, it does seem like the detailed criteria, ~~you know,~~ seemed quite reasonable. And now as we're getting closer, I'm feeling like there's ~~sort of~~ a divergence, ~~uh, between what matters and what is actually the, you know,~~ the letter of the law in the question, particularly when it comes to in the week agei question, the use of a specific form of the Turing test where I'm ~~kind of like,~~ okay, from my standpoint, ~~in the sort of intuitive,~~ ~~like,~~ what really matters in the Turing test line of thinking, I would say we've passed it. And yet the formulation requires ~~an, uh,~~ expert interrogation and that expert not be able to tell what is the AI and what is not the AI, and we're not that close to that. But I always emphasize for people that I think the reason we're not that close to that is a design decision of the people that are making the AI's that are to be tested. **Speaker B:**  Right. **Speaker A:**  Like, if I were going to try. **Speaker B:**  To pass, uh, how confident are you about this claim? **Speaker A:**  ~~Um,~~ I would say quite in as much as if I wanted to create an AI that would be impossible for a. Or much more difficult for a interrogator, ~~um,~~ to identify as AI or not. The first thing I would do would be have it say, I don't know, a lot more often than it does, ~~right? So, like,~~ the easiest way for me to tell whether something's an AI or not is just to ask ten very long tail random questions and be like, no human is going to answer these questions all ten. Like, it's just ~~wa.~~ You know, nobody has that breadth of knowledge. Actual people would say, I don't know. So I would just train, ~~you know,~~ I would actually dramatically narrow ~~the you know~~ ,the range of responses from the AI and make it seem much more conversational, make it seem much more ignorant, make it much less useful ~~you know~~ ,for what you would actually go to chat GPT for. But I think I could make it a lot harder for the expert interrogator to figure out what is what. So anyway that's like just one example of this general problem ~~Um~~ ,I wonder wonder how you guys are thinking about that **Speaker B:**  So to me I'll start from what you just said and then go zoom back to hi question The changes you mentioned could probably be enacted by just using a couple language models that are policing each other and you could basically get to a system that actually behaves this way right now Um so I'm not very sold that know that is main threshold here Um there is a quote from Jren Lanier that I actually used at beginning my thesis was focusing on how can we augment citizen um participation in governance uh through natural language processing guess today call itms where he says um Turing test cuts both ways Um if you can have conversation with simulated person presented by an AI program can you tell how far you've let your sense personh who degrade in order make illusion work? think this quite important here ~~like~~ being able communicate on certain pattern full expectations not what am interested in think that's very very low bar In fact ~~like~~ goal my interest goes way beyond am able simulate something convincing enough closed box tournament like does not actually bring us better world from opinion actually agree with you don't really love way question operationalized but keep mind they are both from 2020 Um we will not always formulate questions so they are optimally informative years later Right And would say that in 2020 these questions said it yourself were fact quite useful point argue attackersus probably moved Overton window respect how people paying attention um impact AI And think value add that's both hard track but also intuitively resonates with me which also draws me here So think these questions somewhat serve purpose Now zooming out purpose question okay but can we have better question If we were do today these questions instead being single question should shaped something minitaculous instance talking about where all subpars questions multiple different forecasts together ensemble actually give picture Heck don't even clear definition AGI point question needs operationalize itself way another Right One uh projects I'mt pretty excited metacas come indexes basically come way aggreate bunch stock tickers come composite view would like there forecasts all really zooming slightly different aspects them allogether paying attention now

**Speaker B:** You can say, well, I want to rigorously link all of these through causal diagrams, and then you will get into a whole different hair ball. Sure, that could be helpful if you pull it off, but even a lesser fidelity version of this that is just here is 30 of forecasts that all rhyme with each other with respect to its focus point will be able to shed more light. And I think at that point, with what metaculous had, like that was possible. And these questions did serve their purpose. ~~Um~~, like, it's a challenge of forecasting the future. ~~Right.~~ We don't always know what formulation for a question will be most useful years from now. Now, ~~um~~, for example, we're doing the five years after AGI, ~~um~~, question series that just launched. ~~Like~~, I am much more interested in that, for example, because when I look at the answers there, it actually gives me a much more accurate view of what people even conceive of as AGI. Like, the way I am using those questions isn't about thinking of, okay, ~~uh~~, will these things happen when AGI hits it more so informs me, okay, these are the things that people consider as critical possibilities with an AGI or not. And just doing a throwback to some of my prior work with AI objectives institute, I often find there to be, if we are talking about AGI and AI alignment without talking about the societal context in which this has impact, I think we are narrowing this down. ~~Like~~, for example, there's a common meme that we would use in AI objectives institute to talk about what successful AGI that can enable human coordination is in the world. That is post AGI. If you don't think Jerusalem will be a united and peaceful city, maybe your AGI isn't ambitious enough. Like, maybe something that is truly AGI would be able to resolve clashes and cruxes within existing human sphere, where it's not trained to make sure it is perfectly neutral towards that, but instead it augments human agency that actually brings a meaningful shape. Because otherwise, ~~you know~~, sure, I canh up a system so it can say, I don't know, enough time so that you might find that convincing. I find that to be a lower. I think we should be more ambitious. **Speaker A:**  Yeah. So what do you ~~sort~~ do you exercise over these questions? Because it does seem like these couple of questions have sort ~~of~~ become a bit of a shelling point. And it's a delicate ~~um~~ decision probably from your perspective ~~right?~~ Do we ~~sort~~ take a proactive step to retire a shilling point because we feel like it's outlived ~~uh~~ its usefulness or do we just let the community ~~kind~~ gradually move on? **Speaker B:**  I wouldn't say that at all. I think like these questions are good. I am much more interested in pushing it further. So ~~uh~~ , I guess it's also ~~uh~~ , a call to action slash ask for help. For everyone that loves metaculus is interested in this. As we launch minitaculus, which are focused instances ~~like~~ if you have different formulations that you think are interested come tell us ~~like~~ , ~~we already get a lot of inbound questions right~~ , ~~that are around by Ky Can we write a question?~~ We heavily editorialize them for we do want to maintain a level of rigor And so far I think metaculous has been much more close than what I would like it to be I would love for there to be many more people That's right questions especially domain experts especially people who say hey I get hang on what question is resolvable and meaningful these are things we can help with But we are entering chapter metaculous as we are open sourcing get many more people write questions have instances hosting have maybe different scoring mechanisms ~~you know~~ , different levels rigor point actually proves useful them We will also host ataculous.com many instances very domain specific So just think need more questions It's not about going back changing what accomplished but more so bringing new lights Like for example quite excited about bunch new technologies could actually bring better results Like love lot or symbolic base Like able use language models order come up specification criteria use create safeguard AI systems Uh interested singular learning theory There's bunch new techniques actually when imagine versions AGI weak levels AI competency even really good ways envision features substantially different And quite quite interested exploring these And think just requires ah breadth more questions forecast also human energy AI energy able forecast questions anyone interested saying hey things want forecast formulation think better come talk us **Speaker A:**  How do you create density though? Right? I mean right? The one worry that would have if was you got million new questions now need like you know billion predictions right actually create meaningful community forecast all those million questions So how do you think balancing diversity questions versus density forecasts **Speaker B:**  Right Great question **Speaker A:**  Um this also where AI's come We'll get momentarily **Speaker B:**  Yeah nail head real currency here real limitation human attention bandwidth Right

**Speaker B:** I have 10,000 questions being launched at metaculous every day. It's not going to help anyone, at least until everyone is forecasting part time as part of their job. That's not what I'm trying to angle towards here. But this is why we need to do active research on questions like, can we build indexes that aggregate a bunch of different forecasts? Can we have AI start forecasting as part of, ~~uh, uh,~~ AI benchmark tournament? We've had an explosion of AI contributors. They seem to be doing okay. And can that create a scaffolding or jumping off point for humans to be able to get to a rigorous forecast much faster? ~~Um,~~ there is, I think, a lot we can do to increase the quality. ~~Um,~~ the wind condition isn't, we have 10,000 new forecasts every day. I think that just will drown any kind of quality from the system. And the wind condition also isn't, ~~well,~~ AI's are forecasting and humans are just watching. I think the question is more around are we able to identify what are the best questions? And that requires, I want that to happen with more people, not just you, the metaculous team. And I want the contribution of the bot to be able to gear towards shedding more light and more information and have these questions be incrementally composable, ~~um,~~ so that we can build world models of, ~~you know,~~ all of these are rhyming with respect to how we are thinking about electric vehicle proliferation, for example, ~~you know. Um,~~ and using those, then we can have much vaguer questions like, are we able to, ~~you know,~~ like forecasting specific windows of electric vehicle proliferation in China is quite specific. But if I have 30 of those questions, I can then make something aggregate that says, ~~you know,~~ will electric vehicles be better for the environment? ~~It's like, what does that even mean? But like,~~ it actually means a compost of all of these different things. This is a different frame of reference for thinking about how we can aggregate them.

**Speaker A:**  Cool. ~~Um,~~ well that's great motivation then to get into ~~kind of~~ what the state of the art is in LLM powered forecasting, and then the tournament that you're running to try to advance that state of the art a little bit further. In preparation for this, ~~uh,~~ I read through three links to papers that you had shared, and I was overall pretty impressed. You can give me more detail on kind what you think is most important or stands out, or what the kernels are that you really want to build on. But it seemed like, across the board, pretty positive results. And these are from serious, ~~um,~~ authors, including Tetlock, has been involved in some of this research. Just to summarize the three papers, the first one was approaching human level forecasting with language models. And this was from, ~~uh,~~ Jacob Steinhardt and his group. They basically created, ~~I guess,~~ what I would describe as sort of the intuitive thing that I would create if I was going to work hard on trying to make this work. And that is like a retrieval system, the ability to go on the Internet, search through the latest news process that, ~~ah, um.~~ And ultimately create forecasts. And it seemed like it was pretty good. It was like coming close to the community forecast, although not as good as the overall community forecast. ~~Um,~~ a question that I did have reading that paper, which I don't know if you would know the answer to is okay it was a little bit short of community forecast but like how does that compare? If it were an individual human you what at what percentile would um that system have performed? Uh I don't know if you do know that but's my intuition was that it would be pretty high as like um percentile individual humans.

**Speaker B:**  Right I mean let me give you a thing that I do believe in that I don't have data but I think we will soon have data for this Is that part in hands team human forecasters will just kill it Like obviously going much better Right Going back question usefulness academic rigor aspect don't get wrong testing isolation good lot designs around uh um AI benchmarking competition pays attention But already obvious let's actually look systems good They're going massive amounts content identifying parts may relevant They're taking first step um creating world model Um let's actually build systems pay attention first um build top Um particularly sch Steinhardt lab Halloween paper lot intuitions explore further paper lot folks asked compete tournament What should always point well start try different Try ensemble methods use language models Um share prior data share prior data debate third model look synthesize Um playful strategies one go So enjoy thinking framework Um encouraging um active discord by way uh tournament people discussing strategies absolutely delightful models evolved three weeks tournament kicking off um strategies people come up

**Speaker B:** And we do encourage people to update their models. ~~Um,~~ for the tournament, there shouldn't be human in the loop because we'trying to benchmark the state of affairs. But if they have a better strategy, they should update that. ~~Um,~~ another thing we do is reasoning transparency. Have the models post at least some form of text we don't grade or score this because it is a whole different level of complexity. For that, let's stay with the forecasting accuracy. But that at least gives us a way in which how the model is thinking. And a lot of earlier research on chain of thought reasoning has pointed that, ~~you know,~~ explanation is actually what gets these models to be able to stay further grounded. So, to me, these things are really good. ~~Um,~~ couple other avenues that I don't think has been explored as much lately is how can we bring in model based reasoning on top of language models that will actually yield much, much better results? Even in the first few weeks, we have, ~~what,~~ 15 questions that have resolved so far? I think, ~~um,~~ in that signal, we've had plenty of questions that have, for example, tests like scope sensitivity or, ~~uh,~~ negation. ~~Um,~~ ask the same forecast, ask the opposite. See if the answers are the opposite of each other. ~~Uh,~~ we've had examples like, ~~for example,~~ there was the measles question. Like, if you ask the bots, ~~you know,~~ what will be the number of know measles cases? Less than, ~~uh,~~ 200. It'll say 70%, 75%, 70% for more than 300. And that means, ~~you know,~~ there should be five chance that it will be between 203 hundred, and bots will say, ~~you know,~~ 65% for the window that's between 203 hundred. Like, obviously, a pro forecaster wouldn't make this mistake. But even an ensemble method falls apart on this case because it doesn't keep track of. Here is a world model that is mathematically rigorous. Now, why is this interesting to me? Humans wouldn't also be able to do a very good job at tracking this if they were much more complex. Like, obviously a pro forecaster is trained to get better at it, but if you ask this to someone that is, ~~you know,~~ not highly numerous child they would be like maybe it's same oh I didn't realize that this is wrong That means there's something intuitive about how humans reason that is distinct from mathematical rigor here How can we close gap Like if we are able incorporate model based reasoning Uh and I think this can happen with approaches like open agency architecture or even like simple squiggled integration I'm super interested in that To be able say your forecasts as you bring in more and more information from language model is building world model also has mathematical grounding which you can enforce things scope sensitivity negotion uh negation sensitivity et cetera et cetera There I think we will actually have lot more paradigm shifts And this goes along with an intuition I would like be much more explored for um building safer AI systems which can we have language models used order come up rigorous world models interpreted because mechanical And um there papers on ah front too um um I think explored different ways there's Tenenbaum lab Stanford published paper called word models world was about year ago So plenty work come top Are able build ah probabilistic uh uh programming language uh support Um so use LLM m come up world representation where representation both consistent interpretable Um use starting point come up uh uh much um Um better robust worlds um AI systems getting accurate logically consistent Um go little technical you're interested Like example auto formalizing option spaces Like finite set proposals constant positive number total budget Say trying question budget allocation option space finite functions sum all actions needs less equal budget LLM parse LLM might able get better If thinking um take natural language description decision situation produce formal description decision variables constraints language optimization framework um ton research use cvxpy bunch libraries get structured construction option spaces simple choice question matching problem M LLMs good figuring Oh uh thing seems match kind help parse That way world model inspect okay parts right parts wrong improve human continue verbal intuition rather than um need excel spreadsheet intuitive probabilities tracking instead you're able say things intuitive probabilities figure Logically consistent help forecaster Here's data Here's forecasts

**Speaker B:** Maybe these 30 forecasts have some logical inconsistencies between them. Can you do better? If we can help language models get better at this, that's composite system, I believe will yield a much more reliable, much more safer AI model as well. And if we extend that further and further, ~~um,~~ we actually might end up with AI systems that are interpretable, that have reasoning transparency, that have distinct parts of world model building, exploring option spaces, eliciting preferences and desirabilities from people that you can look at and see, ~~uh oh,~~ this is how all of them are talking. If you're just trying to get one LLM or a bunch of LLMs, not so much ~~like, I will never be able,~~ but maybe through breakthroughs on mechanistic interpretive, we might be able to get there. ~~Um,~~ so I believe these kinds of explorations will actually yield much better AI forecasting. Yeah. Cool. **Speaker A:**  So that's awesome. I want to, just for closure, for people who wanted to maybe hear those other two papers, I'll just mention them briefly, ~~uh,~~ because I think if you're going to get into this tournament, you should look at the, ~~uh,~~ Halloween and Steinhardt paper for sure. That's like you're ~~kind of~~ jumping off point. ~~Well done,~~ agent with retrieval, with fine tuning, with, ~~ah,~~ a good scaffolding to spit out good predictions. That's the one that I mentioned before, comes reasonably close, but still fall short ~~of the,~~ of the community prediction. Then there are two from Tetlock and co authors. One was pretty interesting around just giving people access to an AI assistant and seeing how that helped them as humans forecast. This is kind of ~~the big picture,~~ at least a small step toward ~~the big picture~~ vision that you're painting. Interestingly, they had a biased, they ran an experiment where they gave the best assistant that they could give to the participants and then also a deliberately biased, ~~um,~~ AI assistant, and they found that both helped, although the biased one didn't help as much. ~~Um,~~ that's an interesting finding and also an interesting argument in that paper about how this look at the future. I mean, you could think like multiple reasons for why AI forecasting could be useful. You've made the case that, you know, obviously we would like to have a better sense of what's going to happen. We would like to be able to make better decisions. They also make kind of an argument in that paper that the study of what language models can predict is also kind of a useful way to interrogate to what degree they can get out of distribution, which is a very hotly debated topic within the study of AI. Right. Some level., By definition, if you're predicting the future, you're out of distribution. So that's ~~Right., Some level.,~~ I think. And the fact that they are doing it reasonably well is definitely at least some points for team. These things can generalize ~~um~~ purely beyond their strictly defined training data. ~~Um~~ then the third one also from Tetlock and a number of the same authors is just an exercise in ensembling different language models and finding that like average language models performs better than individual so it's kind of wisdom ~~of kind~~ in fact that's title paper is wisdom silicon crowd Yes interesting me mean did expect Tetlock publication pre registered all experiments very sort rigorous about declaring exactly hypotheses going test did jump data GPT four way outperforming models wanted really simple improvement method would cut worst take uh one like few top performing just run multiple copies those **Speaker B:**  Right **Speaker A:**  Um couple interesting notes there around bias toward round numbers little bit biasd toward positive resolution Some these things noted where was some logical inconsistencies were hard Another note had paper was really shows breadth knowledge powerful way because would have looking things even know person might leader country whatever even begin uh discussion fact just jumping making uh predictions wide range things good reminder some fundamental strengths **Speaker B:**  Right? **Speaker A:**  So okay that's background hopefully breadcrumbs people want tournament **Speaker B:**  You've alluded tourn If make comment little bit think conclusions papers make intuitive sense love see rigorous tests Like example said well cut worst maybe that'll better Maybe But also want keep mind Like goal uh better forecast probably kinds things make mild leaps going things look similar questions asked variety you know prediction platforms like actually instrumental shifts academic mindset uh rigor towards like actually instrumentally helpful here do think lot shortcuts actually much around Like okay how get further helpful those things really interested getting folks explore

**Speaker B:** Ensemble methods are great. ~~Like,~~ wisdom of the crowd works. Wisdom of silicon crowd also would probably work as a result. ~~Like,~~ try different models. Try the same model. Figure out if these models are good at specific domains or if they're avoidant on specific questions. ~~Like,~~ these are all. There is so much juice there. And as we have better models, also, the conclusions will shift continuously, which is why I think a benchmark like this will actually be ~~really,~~ really helpful. **Speaker A:**  So, let's get to the contest. You've alluded to the competition, ~~uh,~~ or I guess we should maybe properly call this a forecasting tournament. ~~Um,~~ you've alluded to that a couple of times. I would maybe love to start with just ~~kind of~~ a rundown ~~of, like,~~ what the setup is, ~~what,~~ what the rules are. There's prize money available. So you just give people a sense of ~~like,~~ what they would be signing up for it and kind of ~~the, you know,~~ the specific nature of the competition. **Speaker B:**  Yes, I am pretty excited about this competition. ~~Uh, it s called AI benchmark by~~ AI forecasting benchmark series. The competition will last for an entire year, where every quarter we will have new questions that get launched. And, ~~um,~~ for this quarter we will ask about, ~~uh,~~ 250 to 400 questions to the AI systems that are forecasting. ~~Um,~~ we have about 120k prize money to be allocated across the entire competition. And, yeah, I would love for people to participate. A couple learnings that I've had just looking at the competition is, ~~um,~~ even very simple bots seem to be doing really well. And, ~~um,~~ this might be that their prompts are better, this might be that they're paying attention to better news sources. So it is definitely interesting. ~~Uh,~~ and without a lot of effort, I do think it is possible to get something that is somewhat competitive. ~~Um~~ now what is the tournament? It is in a way it's a typical metaculous forecasting tournament but um it is specifically geared towards spots um we encourage people to build bots that use multiple LLMs And um we will use this as a benchmark to compare against um pro forecasters and also community aggregation And um it's first of its kinds done at this scale Um basic rules are that you cannot have human in loop You can change your bot but you cannot make specific adjustments Bots have leave comments showcase reasoning We won't score comments but it will good us see what winning bots doing **Speaker A:**  Uh so quick clarification When said can change your bot but can't modify it means update periodically adjust specific question **Speaker B:**  Is that exactly? Exactly I'm just saying it for specific question basically defeats purpose point has human loop right mean believe human loop systems ultimately going better Just like how you know competition good collaboration good but like competitive collaborative system where teams collaborate competition better Um tournament we're not looking into We do want see AI capabilities own footing Um so um hence update if come up better strategy Uh especially winning bots interview like writers interview them ask approach We encourage share systems would like expected do Um provide description bot code um would like see works doesn't Um yeah create benchmark continuously evolving also kind cannot cheated We literally don't answers lot these questions So really fun Like evolves every day Like every day look again see bot doing missing find pretty fun personally Um created template follow fairly simple straightforward um use start off system but um top town Like lot done ensemble methods model based reasoning systems Bring news Like one things example where saw touched earlier little bit um if human forecaster forecasting trying well google look other platforms see similar questions something bots figured fast writers rather Um so uh really happy these kinds explorations Um yeah rough rules fairly easy started Oh also um both OpenAI anthropic donated fairly generous amount credits anyone get credits um because you know lot forecast think cover needs So huh process ping either discord send email You can email me daggeraculous.com or support email It's website say hey kind thing try Can get credits sure plenty support

**Speaker B:** So, yeah, I find it too, to be, um, quite exciting for that. **Speaker A:**  All the questions are binary questions they're going to resolve. Yes. No. Is that right? Can you give us a few examples of early ones that have already resolved? **Speaker B:**  Yes. I want to say all the questions are binary at this tournament. ~~Um,~~ we will have non binary questions soon, ~~um,~~ for the next round, which will be q four, the tournament will happen in every quarter. ~~Um,~~ ~~and, um,~~ you get scored on the questions you forecast. So ~~a lot of~~ folks have asked me, am I too late to participate? I missed the first few weeks, actually. Not at all. We have some people that are on high on the leaderboard that have joined fairly late. So I say join now and also try things now because we will just cover your credits. Anyway, ~~um,~~ so when Q four hits, you can go in with ~~a~~ system ~~that you have~~ rigorously tested. ~~Um,~~ some of the questions that have already resolved with respect to, ~~um,~~ like the prime minister of France, ~~um,~~ will that belong to a coalition other than the new popular front or together? A lot of election related questions on France have resolved already. ~~Ah~~ domestic box office question. We have one on Deadpool and boulverine. Will that be higher than that of deadpool resolve? Yes, it was interesting for the bots did better than humans on this one. ~~Um~~ Joe Biden. ~~Uh, you know what will happen for the democratic card?~~ We had a bunch of questions on that front. ~~Um~~ one thing we have done that I think is really interesting is in ~~the uh~~ main quarterly cup, we have questions that are continuous variables like what will be between July 17 and July 28? What will be strongest geomagnetic storm have a k in excel? For this tournament we have discretized this continuous variable question to say things like will it be greater than four or less than or equal to six or between five and six? So we have turned continuous variables into binary questions so we can compare it to you Is there logical consistency here? But also how does this compare with human forecasters looking at this? So a couple tricks we placed in there to stay with purely binary forecasting tournament next quarter we'll build on top of that with more complexity **Speaker A:**  So is the structure that people submit their bot then you guys run it daily as new questions come out? ~~Um they going to do are they going to answer each question once or are they sort of going to be repose~~ Are they going to repose daily until they resolve? And then do they provide a percentage? And then how does scoring work based on that number they give you? **Speaker B:**  Um scoring is same as any binary question we done on metaculous It will resolve yes or no and score accordingly towards that We score ensemble on top of all We only doing binary questions here but process is basically we don't host their bots they host bots And um we open questions Every question open for 24 hours So need continuously forecast on top We made process fairly easy If you're if anyone has any questions they should take look at onboarding process It would take maybe 30 minutes spin up very simple bot Um but yeah so need submit through API your forecasts question open close every day **Speaker A:**  Gotcha So people running own bots own computing infrastructure **Speaker B:**  Yeah basically we some folks actually competing bots value form private ip We don't want them just say well need give us what you Or if built something really interesting want monetize do want encourage So think very interesting everyone submit bots But also point stage where current element capabilities at rather people much more ease updating bots want see things like oh uh this bot seem bad scope sensitivity but got better curious tricks did rather bot still custody person building Does make sense **Speaker A:**  Yeah ~~Is there a way~~ are we working on honor system or possibility people could human loop submit stuff Like reason assumed had submit bot guarantee wouldn't human intervention process **Speaker B:**  In this tournament we discussed quite bit decided go honor system Um one things number questions forecast quite high actually So um somewhat disinceentivizes human forecast about you 600 questions just you're being bombarded **Speaker A:**  It's a lot of work.

**Speaker B:** **Speaker B:**  ~~Um,~~ and another reason why we want people to submit, their reasoning is that if there is human intervention, it might be much more visible through that, especially for, ~~you know,~~ the winning cases and the high volume of questions. ~~Um,~~ I do think we will scrutinize them heavily. And if we do have, ~~you know,~~ reasonable suspicion on that front, I'm sure we will have, ~~you know,~~ further investigations. But for this tournament, we decided to go forward with the honor system rather. So we do encourage people to abide by the norms because it'll be contributing to a meaningful benchmark that way. Otherwise it ~~kind of~~ pro provides a cheat. ~~Um,~~ so yeah, I guess ~~the other.~~ **Speaker A:**  Thing is that the general prior assumption is just based on ~~the,~~ all the research that we talked about a few minutes ago that ~~like,~~ you might be able to ask, add a bit, but you're not going to add. Even over the baseline AI performance, an individual is not likely to add that much. ~~So m and~~ you might even make it worse in some cases. So it's not an obvious advantage to be unlike, for example, the arc challenge, where if you had a human intervention, there would be ~~like~~ a clear reason to think that you would have a big advantage toward the prize. Here, it's like much less obvious that a human can actually improve on what their bot is doing, ~~uh,~~ on its own. **Speaker B:**  Yeah, exactly. And to be honest, ~~like,~~ this is fairly early to make any conclusive statements and ~~kind of~~ hope that this will change. But we have a couple questions where the bots did better than the aggregate of pro forecasts. And I'm like, oh, this is very interesting because they clearly are failing on things ~~like~~ you know, scope of negation, sensitivity, but ~~um~~ on questions where that's not ~~you know~~ the primary ~~um~~ mechanism ~~, it's~~ they seem to be able to do something that is powerful. ~~Um~~ so I think people should try not messing with it. And one thing is ~~um~~ every quarter we will have a different tournament that will have its own sets of rules and norms. So ~~~~I am m interested in actually exploring~~~~ you know different mechanisms here as well. So ~~~~um~~~~ we have an active discour. So people have ideas on like hey this kind of competition would be much more interesting ~~Um~~ I'd love to chat with them and hear ~~you know~~ what their ideas are ~~~~So um~~~~ we can try different things but like ~~~~the goal~~~~ of this is to be able to benchmark AI capabilities and see if this can be an early warning system that would actually substantially help um role forecasting plays in **Speaker A:**  You said a minute ago that the scoring is like standard scoring but just in case I don't know exactly what that is is that basically a My intuition is that it would be like almost in the way that like a neural network might be measured for like a classification task sort of sum of um squares type scoring Is that right **Speaker B:**  Um it'your question how we are forecast like how the scoring is for binary questions **Speaker A:**  Yeah exactly **Speaker B:**  Yeah I think with this way um we're basically comparing the forecast to a coin flip In context of uh forecaster we're using log loss versus coin flip peer score basically how your baseline score which log loss compared coin flip compares everyone else's Um so way proper scoring rule that's used based log scores The reason why designed rewards forecasters beating crowd incentivizes both Like research understand crowd report best guess rather than um say things want 10% above whatever community prediction Um Does make sense **Speaker A:**  Yeah Are penalized by overconfidence Like put one something wrong very costly scoring system **Speaker B:**  Yeah given basically So need accurate respect envision world Um s way don't you know drive towards far edges something see prediction markets financial incentives Um actually combats against That's saying market community prediction 60% believe correct should say 60% accurate um turns yes penalized but think accurate guess should not say it's 60% Um while market um trying maximize financial output market isn't meaningful bet **Speaker A:**  Yeah gotcha Uh get questions once well Would within rules system consider questions sort handle try deal sort possible inconsistencies **Speaker B:**  Can repeat said **Speaker A:**  Yeah said number questions related kind discretized continuous variable supposed consider one one give prediction kind consider family imp post checks related questions make sure uh predictions self consistent **Speaker B:**  mean hope contributors Right

**Speaker B:** I want a human forecastaster, a bot to be able to do that, which is precisely why we're asking these questions this way, because it is very hard for bots to be able to do this, ~~um,~~ unless you have come up with something that is much more robust. So I also want to see if they get better at doing this over time. ~~Um,~~ in ~~the next, um,~~ through the next year, will simpler models be better at scope sensitivity or negation sensitivity? But yeah, like a human pro forecaster will obviously say, oh, all of these questions are related, so let me come up with an answer. ~~Um,~~ it wouldn't be very difficult for an AI system to start doing this by noticing these questions are all connected. You can just have a simple LLM check that says if all of the questions are looking at similar variables, come up with one coherent answer, and then based on that answer, answer each of the individual ~~parks~~ parts specifically. ~~Um,~~ I'm curious how many contributors will do that. And I'm curious if that will actually yield numbers that will be, yeah, ~~I.~~ **Speaker A:**  Would think it would help at least a bit. **Speaker B:**  Yeah, it should. Like this is's what I'm hoping for. **Speaker A:**  Is there a leaderboard that folks can obsessively refresh instead of going to the election websites every day? **Speaker B:**  Yes, there is, and I encourage people to check it. ~~Uh,~~ what's interesting is some like newcomer bots have already went up high on the leaderboard fairly fast, which is why I tell everyone, ~~you know,~~ we have easy templates to get started. Just go and take your shot at winning the prize money. Like we do have a large ~~um,~~ pool of money. And this will also be distributed across the entire contribution over a certain level. So you don't have to get first place to get something. Like I do expect a lot of the ~~um,~~ bots will actually be compensated, ~~um,~~ in some shape or form. ~~Um, so yeah,~~ like bot performance seems high enough~, variance enough~, and we have three more quarters. So I would say like this is the time to get your bot in shape~, set up~ through the template~, start testing~, and maybe you'live win some money.~ We will cover your costs.~ So ~~um,~~ ~the catch~ will be distributed along ~the curve rather than know~ just ~the top three~ . So it's not too late at all.~ I say give it a shot.~ ~~Um,my question~~ ~to you~ is ~like~ , what would it take you to make your own bot? I think you would probably enjoy it.~ **Speaker A:**  Yeah~, I think it does look fun.~ ~I did read through~ ~the collab~, uh~, notebook that you have shared~ ~and~ ~it does look know really with that all in place~, it's like~, especially~, and also covering credits.~ But that was one other little detail question I had was is there a credit budget or any sort of budget ~~per,	uh,	per question~~ or is that's all up to you? To manage on the participant side.~ **Speaker B:**  So in this tournament~, we decided~ ~to not impose a max budget.~ ~I do think this would be interesting~, like~, say,	if we said,	you only have $200 forecast for an entire quarter,	but then,	like,	we're intentionally inhibiting measuring AI capabilities,	so that doesn't actually give us	~ ~the outcome we want.~ And that could happen in a fairer competition~, but that kind of defeats~ ~the purpose.~ ~~Um,	we have given up	to five k	to,	um,some	~ ~of		the,	uh,	competitors	and people have asked us	to say,	hey,	can we get more credits?	Um,we ask people	to describe	~ ~the strategy they will try	and,	um,incrementally give more.	Um,	so this is,	um,we decided	to do it on an ad hoc basis because if we just distributed at large,	we're kind	to can't keep track.~ But people,	um,	that actually want	to spend a lot more budget,	they can reach out	to us.~ And what it will take is a quick email exchange back	and forth where they describe	~ ~the phenomenon,and then we will keep a look at our they forecasting.If so,we will keep on giving them gotch.~ **Speaker A:**  You cool? Um,great question for me in terms of what would it take for me	to get into	the contest.I think	the biggest thing I'm probably missing right now is	a sense	of how do I improve on	the Steinhardt	a nd , uh , group paper.Reading through that,I was like,this seems quite well done.It seems like it's working quite well.And it wasn't immediately obvious	t o me how	i would make that better.So	i would need 	to.And it hasn't been that long since I've read it.So,you know,eureka moments , uh,could strike any time.Um,but i hadn't had an intuition yet around , oh , if i do this , i think i can beat them.Um,and that's sort 	of 	the moment 	of , uh,inspiration,i guess i'm sort 	of waiting for . **Speaker B:**  Right.A couple quick ideas I'd like 	to share is pay attention 	to other forecasts.Like any forecaster should start by googling . Okay , has anyone forecasted this ? Um , what's happening on other platforms ? Are there other questions at metaculus , like , we do ? Pay attention 	to make sure we don't have another question that's identical , um , for 	the tournament.But similar things will provide a lot 	of light towards having a good base rate.So 	that , for example , or hook up perplexity,pull up recent news , um , or try multiple different models 	and , um , see how they compare with each other.I do believe that,you know,fact fetching versus , um , coming up with base rates versus,you know , abiding by logic consistencies or rather than abiding by,I'say , leveraging that 	to be able 	to make better forecasts,different models will have different competencies.

**Speaker B:** I have found this is very anecdotal, and this might change even if you use different prompts. I'm just sharing, ~~you know,~~ I tried this not as a research, but literally, ~~like~~ spending prompting for a while. Anthropics seems much better with respect to negation and logic consistencies compared to OpenAI. Open is much more helpful to work with me in trying to figure out, ~~know what? I should pay attention to the question.~~ So come up with models that pay attention to multiple things, use LL models, use custom things. ~~Um,~~ you can even fine tune with prior forecast if you like. There's a lot that can be done. ~~Um,~~ and I don't think what will make the winning condition ~~is going to be like, this comes from a multiple, you know, um,~~ PhDs research team that invented something really novel. I think it will be actually much more flexible than that with respect to, ~~you know,~~ which. What ends up winning? I don't know. My bet will be that something simple will end up in the top three or top five, and we will say, wow, ~~like,~~ maybe we didn't need all of that complexity, or maybe we will find out, ~~like,~~ yeah, logic, consistency abiding by it, will yield much better forecast. So you definitely need to pay attention to that, because that was the determining factor. There's a lot of conclusions we can get, so ~~I just.~~ My goal is getting people to try out a bunch of them. **Speaker A:**  ~~It seems like the.~~ If I had to forecast on a meta level, the result of this tournament over the next year, and definitely using the research papers as point of departure, it seems like some sort of ensemble of these bots, which themselves will probably be ensembles, ~~you know,~~ internally, in many cases, it seems like we probably are headed for a world in which the AI forecasts are, in aggregate, very competitive with, and maybe even surpassing, to some extent, the community forecast. ~~And I guess maybe in closing, I'd love to hear, like, first of all, do you think that's true? And then what, you know~~ , could you give us a little bit more. You've kind of sprinkled some of this in throughout,. ~~but But~~ a little bit more about what that will mean. ~~I guess~~ I don't have a great intuition always ~~, for~~ , like how good is the community forecast? It's still obviously not like a crystal ball. ~~Um~~ , but if we could get that good ~~, how good is that? How useful does that start to be? Is it a question of just,, we need to.~ If we have this level of accuracy for everything ~~, like~~ how much does that change the world or how much does that still sort of leave us in a ~~, like,,~~ fundamentally uncertain state? ~~Um,,~~ because this seems like this could happen ~~, especially as~~ ,the tokens are getting extremely cheap ~~, Um,, you know,, we could really have,, with~ .the latest GPT four o mini'especially ~~, if you do~ ,the offline batch process ~~, 10 million tokens for a dollar,, folks.,~ **Speaker B:**  It's ~~,~ . **Speaker A:**  It's ridiculous ~~, So,, yeah,, like,, how.~ What is ~~the sort of~~ epistemic future look like to you? **Speaker B:**  I will answer from a different starting point again ~~, that hearkens back to what we started with,, which is around., Why is this?, If I was to tell you,, we will end up in a world where you will have an ensemble AI,, or~ .the bought aggregate that consistently beats the community prediction ~~, does that bring a better world on its own?, I don't think so.,~~ I think ~~the part with~ ,~ AI'that I'm pretty excited about is that it costs a couple cents to have them ~~, you know,, write an entire research paper explaining,, you know,, their reasoning., I don't know if you'll buy~ .the reasoning ~~, but it is much cheaper~ .to probe and understand ways in which their conclusions come compared to humans ~~, And~ .that ~~to me,, is~ .a paradigm shift., And this is already happening., Like,, there's multiple companies focusing on this,, ranging from,, you know,, illicits~ .to future search ~~, I am interested in seeing how that will give us better action ab,,, um,, if bots in aggregate starts~ .to forecast better than humans or human plus bot ensemble systems are doing much better ~~, Um,, I will again go back~ .to how do we make this useful? And I am excited that ~~the LLMs will be able~ .to create much,,, um,,, more interpretable world models., Um,,, hoping~ .that these world models will not be manipulative ~~, Also hoping that,, you know,, these world models will actually serve~ .the goals of those that are trying to make value out of it ~~, which is why,, you know,, some of~ .the questions are fun and throw away ~~, Other questions are actually quite proactive towards specific goals., And we will have more~ .of these to come up in ~~the upcoming,,, um,,, coming months,,, like around questions of,,, you know,,, strategies on mitigating homelessness., Like,,, um,,, there is a lot that we can do there.~ So if bots are getting much better than humans ~~, then I think~ .the question is ~~, how can we make this be maximally useful?, We already have really accurate forecasts,,, and we haven't had~ .the cambrian explosion of every single entity corporation government perpetually uses forecast because the frame of ~~the forecasts has not proven to be helpful just yet,,, which is why I am really interested in this action oriented,,, um,,, inflection point identification,,, finding short term proxies,,, finding questions around budget allocation,,, working with hypotheticals., Another side note here that I think might be worthwhile to go into., I think we should ask questions that might not resolve., Like if I say,,, if San Francisco was to allocate $70 million for improving public transportation,,,, if they did x,,,, if they did y., Now,,,, like,,,, this might not resolve,,,, this is probably not gonna happen.~

**Speaker B:** But asking this kind of question and asking, ~~you know,~~ pro forecasters to forecast on it, ~~um,~~ they might say, well, I'm not goingna ~~be get~~ a good leaderard on it because it will never resolve. But if I tell them, hey, this will be helpful for resource allocation. Doing this for questions on taiwanese sovereignty, doing this on questions on AI. ~~Um,~~ will actually let us explore hypotheticals, counterfactuals in a way that will bring a lot more strategic information. So these are spaces I would like to go to. And if bots are able to bring a level of reasoning trans currency, that is great, because that will make it much more actionable. ~~Um,~~ I hope it checks out. I hope it doesn't end up, ~~you know,~~ being the uncanny value of seems legit, but not necessarily correct, but it's too hard to scrutinize, ~~like,~~ that failure mode would be what I would be afraid of here. ~~Um,~~ and in a way, we already live in a world that encourages that, right? Like, we have legal documents that are, unless you speak legally, you won't understand it. So you need to defer. ~~Um,~~ a failure mode here is ~~like,~~ yes, there is something that all of these bots are able to converse with each other, that we see as, ~~like,~~ somehow this has higher epistemic status, ~~um,~~ than what a human can access. Like, at that point, I think we are in the failure mode of epistemic security. ~~Um,I would like to dismantle that.~~ I'd like to dismantle that possibility, which is why I'm excited for LLMs to be able to help, say someone that doesn't understand anything legal or doesn't have money for a lawyer to be able to make sense of a contract or for medical sector or insurance sector or science. So there is a world in which these tools can actually get us towards better reasoning and do it beat individual or in a collective scale where we are re aggregating multiple perspectives. I think same as well for forecasting. ~~Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecasting.Like,I think same as well for forecas

**Speaker B:** So these are all spaces that we will highly prioritize. We're entering a window of a lot of experimentation, actually, on seeing ~~like,~~ what are additional things on top of, ~~uh,~~ forecasts as they exist right now would add value. So the minitaculus that we were talking about is just one of the many examples here. ~~Um, building indices is another, um,~~ like looking into things like tech trees that, ~~uh,~~ foresight Institute is building on seeing, ~~you know, okay,~~ for us to get to this technical state, it looks like we have these in between things that need to be invented or researched. Will this be worthwhile? Okay, if we put $5 million to this versus $15 million to this, we will we be able to go through these inflection points? These are the kinds of ways of reasoning that I would like to see metaculous enable in. **Speaker A:**  Is there anything that you worry about with this paradigm? I mean, generally speaking, ~~you know,~~ the sort of ~~I mean~~ we just look through this crowdstrike disruption, right, where ~~like~~ one seemingly very local point failure ~~like~~ cascaded through society. And if I was going to take ~~the,~~ the most ~~like~~ risk oriented position on this, I might say something like ~~in a world where~~ yeah maybe we're getting most of the time even better than wisdom of the crowds forecasts from like a couple different AI models. What happens if they fail? Not ~~ne~~ in terms of an outage although maybe but more so is there a potential for sort of a correlated failure that could create weird scenarios weird tail risks? How do you think about that type of possibility? Is there any way we can get ahead of that? **Speaker B:**  I mean decentralization is key right? Like if everyone wasn't using crowdstrike probably everything wouldn't have gone down all at once. And I'm sure a lot of people have ~~you know~~ had the hindsight to say well I saw this coming I've talked to a couple folks even that ~~you know~~ said well yeah we switched out because we first said something like this coming up. I think especially when you have institutional systems that are entrenching the use of specific tools or specific flows that ends up introducing a lot of failure mod right? Like if there is a government endorsed supply chain flow that will be much easier for a foreign entity to be able to ~~um~~ infiltrate and mess with causing supply chain related risks. ~~Um~~ we plenty of those through ~~you know~~ human history. ~~I think like metaculous~~ being open source is good. ~~Like I am less interested in I mean~~ obviously I want metaculous to be the most accurate and that is the goal we are striving towards but even more than that's like the proliferation of the perspective so that there is multiple people doing multiple focuses there is many different strategies like maybe for a specific domain a different way of scoring will work much better and this will end up ~~you know~~ causing much more value for that Like for example just zooming back to something we said at the beginning ~~uh~~ of the podcast ~~um~~ decisions around political outcomes is very different than say you know like questions like should Biden step down versus questions like if we allocated an additional $50 million towards ~~um~~ synthetic biology which of these will yield an inflection point? Um now it is interesting like in the book like super forecasting there's plenty of anecdotes of you know people who are really good at forecasters can end up beating domain experts This doesn't mean we don't want domain experts this means we want forecasters to work with domain experts So I think there's many different contexts in which forecasts can play instrumental role but they don't all look ~~~~the~~~~ So I think the real win for ~~met attackos~~ metaculous is to actually bring us towards this world where many people are trying many different approaches and many different things We will always strive towards level rigor accuracy But on top of that like I would love it if you know there'a different thing that ends up building an AI ensemble method that seems to be more reliable than metaculous prediction Like at that point then question is okay like how do we integrate this towards usefulness Like that wouldn't be a failure It would in way be success for like we have shown that this possible So my answer towards failure modes through singular authority has maximal controls always Well decentralization much better And how can stward towards That's question Cool **Speaker A:**  Um I just had one other thought that was going toa ask now escaped me as was listening answer Oh uh are you also interested things like polis The sort ~~~~and~~~~ ~~~~is there~~~~ ~~~~like an angle~~~~ Uh what's ~~~~the sort~~~~ ~~~~you know~~~~ seems ~~~~like~~~~ yes Is answer is there ~~~~a sort~~~~ meticulous polis mashup or ~~~~like uh~~~~ what does it look if those two concepts have baby **Speaker B:**  Great question This goes all way back my backstory Um would say Polis probably most influential platform evolution my thinking Um right before metaculous at AI objectives institute project worked longest called talk city which LLM assisted aggregation deliberation platform take qualitative feedback And way was working thesis This was working startup cerebral also Um so have thought question many different lenses Um when raw text highest fidelity human opinion how can augment

**Speaker B:** ~~Um,~~ and through many iterations, ~~you know,~~ first without LLMs, then looking at multimodal systems with, ~~you know,~~ text data plus other data, ~~um,~~ and in the latest iteration with ~~to~~ the city, what I have come to was, okay, the current state of language models actually does a fine job in identifying what are the topics? Are there any subtopics? And another thing they are really, ~~really~~ good at is actually the retrieval of these concepts. ~~Um,~~ talk to the city still ~~actually~~ exists, and it's going pretty well. We have an excellent team at AI objectives institutes. I recommend the audience to check it out. ~~Um,~~ website is AI do objectives dot institute. And they can see on blog post a couple case studies, ~~um,~~ that we've done on, ~~uh,~~ impacts of talkk to the city. ~~Like,~~ for example, one was with Taiwan. ~~Uh,~~ we've had an extensive collaboration with Taiwan's, ~~ah,~~ Ministry of Digital affairs, ~~um,~~ where we were aggregating people's opinions with respect to both local municipal questions and also larger scale questions, ~~um, on, you know,~~ same sex marriage data. A lot of these data inputs come in from polis. Now, Polis doesn't ~~like,~~ there's some constraints there. That is a trade off, or it ultimately is a recommender system where you're knowing people that will share certain viewpoints instead of leaving the onus to that which causes you know less human bandwidth like you can only write about tweet sized things. We said okay can we have just completely unbounded input window where people can send in text they can send in videos they can share any kind of data ~~um that you you~~ would be able to then enhance and see okay what does this community talk about? What matters to them? And in a way my journey to forecasting into metaculous was me seeing okay we are actually at a place where we can aggregate public desirability ~~Um~~ I prefer the word desirability to preference because preferences can change one might not necessarily be aware of their preferences as you can have cyclical dependencies I use desirability more as a catch all term that overcomes some of these We can aggregate these we can have a snapshot Like one project that I loved for example was with the va ~~um~~ labor union with focusing on veterans health where they wanted to run a survey with respect to a specific proposition And the negotiation windows they have with government is incredibly small There's a 20 day window where they need to come up with a policy share it and it will go through um whole system is basically rigged against internal deliberation Just it's so narrow and so fast paced that people just say whoever I voted for as head of union should go forward The new president of union Mark Smith ran a survey open ended text based question to entire population Within 24 hours I think we got what like maybe 200 responses on first round Within 24 hours We could turn this open ended survey in multiple languages by way not just in English You can get bit Spanish Tagalog consolidate this say here are four viewpoints came up What your thoughts Send back entire community develop recursive loop It's so much more interesting when say wow between just yesterday when survey went out already have four clusters Maybe should respond this O uh have something add this one Next day do again This cycle much cheaper than what used be think paradigm shift like changes governance realized okay now we aggregate what need next pillar which action over actually get us towards where people want go And that's talking Gaia previous year metntaculous that's ended eventually So excited seeing forecasting help think there's lot there think need lot experimentation Um yeah like polis tools way started thinking huh hu maybe way which better **Speaker A:** Glad remember uh bonus question think does sort start look like liquid democracy sort technology mediated liquid democracy definitely super compelling mean there's just not much room We see right now going through campaign Obviously US like things actually getting talked few not particularly well chosen many cases And uh you know there's just much stuff really ought be you know want understand you know what people actually care first all or how think different things We're just even getting data first place let alone you know able map path toward actually delivering people **Speaker B:** Ye so absolutely absolutely And think you know bit signal red blue votes US do much better That's why looking municipal engagements membership based organizations looking daos making lot decisions around you know stakeholders entire thing digital substrate so much more experimentation here What said reminded something respect you know liquid democracy

**Speaker B:** I must say, like the term liquid the Mar democracy does bring some aspects of future in my mind also, and I think it's worth pointing that out. ~~Um,~~ there's this concept that I call the consensus illusion. ~~Um,~~ there is a drive towards the lowest common denominator that if we say finding consensus in a community is desirable, for that is the best policy, what you will end up is a lot of policy outcomes that are quite lukewarm, that don't actually address the issue. ~~Um,~~ there was a Europe's paper from DeepMind and, ~~uh,~~ like 2022 on find, ~~like,~~ how can we fine tune language models so that we can find agreement across humans that have diverse preferences? And one of my concerns when I see work like this, I think the paper is actually great. Like, some of the techniques they used has made its way to talk to the city. So I like that. ~~Um,~~ some of the concerns I have is finding agreement doesn't necessarily mean good policy. In fact, it quite often doesn't. ~~Like on an example I like to give is one of~~ ~~the conclusions from a civic data set. Is~~ ~~um~~ , we should build more bike lanes for the community. Everyone seems to on to our back lanes, and you say, okay, where should we build these back lanes? ~~It should it be on this street? And~~ ~~the model will say~~ , no, no , no , that's not what we agreed on . It shouldn't be on a specific street . We need more bike lanes . ~~This is~~ ~~the thing~~ . We don't want to make any specific streets narrower . And it's just like , oh , we're doing the same thing we've been doing with politics all along . Where find the most common denominator statement that , ~~um~~ , yields power . Because in the current of elective system , consensus is power . So when you have a desire towards consensus , that causes a trade off with fidelity to your viewpoint , and if you seek power over fidelity , you will have higher representation of a viewpoint that is not very meaningful . And , you know , ~~the most~~ , you know , catch all sentences will end up resonating ~~the most~~ , ~~um~~ , and it won't make meaningful policy . So I don't want consensus , really . I want to start from a shared world model . Like , can we actually come up with ways in which we have desirabilities for stakeholders , we have action possibilities that come from policymakers , and then we have outcome likelihoods from domain . And these three need to be continuously talking to each other . As you division of labor , I thinkacy focuses on the state desirability for stakeholders . But if the options you give is only roads , you can't really build a bridge . And people need to be able to say , I want to also be able to build a bridge and an AI model that hampers this by finding o , ~~uh~~ , this is the most agreeable thing is not good . Instead , I'd much rather have an AI model whose goal is come up with individual viewpoints that are clashing with each other , represent each of them with high fidelity , and identify what are the cruxes between these viewpoints . ~~Like~~ , if we can find ~~the good crux where~~ I think a is true , you think a is false , but ~~the underlying cause~~ , if I thought ~~the underlying cause change~~ , this would change my mind about a , and you would say the same thing . Like ~~, uh~~ ,, double crre process is good because that means we actually have a same shared world model ~~, um~~ ,, and we need more data . And at that point ~~, bring on further research,, bring on forecasting., Like we're in a good mode.~ The failure mode here is a risky alliance where someone says ~~, oh,,~~ I think policy a is good ~~, You say,,~ ~~,I also think~ ~a~ ~is good.,~ And I say ~a~ ~is good because it will enable b,, which will be great,,~ ~and~ you could say ~~,I don't think b~ ~is likely~ ~to happen as~ ~a result~ ~of a,, but maybe~ ~we should keep together because it seems instrumental just for this one step., And~ you end up having a lot of unlikely alliances., And ~the ultimate version~ ~of this~ ~is~ ~a completely polarized society where you for some reason know social conservative and fiscally conservative behavior is correlated with each other,, even though that doesn't necessarily manifest., Um,, there was one research that I read,, I,, um,, can't remember where,, that I just absolutely loved,, which was instead of asking people their opinions with to immigration policy,, it actually asked a statistical question on how many people are you willing to let in,, um,, before you reject someone that truly deserved to come into ~the country~ ~and~ ,, uh,, ~the previous people that you have Letin might be mistakes.~ This is very interesting,, because instead of people saying,, well,, ~I am liberal,,~ I am conservative,, you see people who say they are liberal,, San Francisco crowd that will say,, yeah,, I'm willing to let in five mistakes before we admit one person., And others will say,, what do you mean five?, We need like 300., But both of these people see themselves as having a liberal opinion., Like,, we do not yet operate on a level where we are looking at good policy., So we should not encourage these illusion of consensus so that it can serve towards better power., Instead,, we can use these techniques that we have right now to go towards better policy., And better policy means higher visibility,,, better policy means people agree on ~the world models.~ So I see ~the work we're doing at metaculous as an instrumental step in that trajectory.~ Are we able to find people whose world models are diverging?, Let's figure out why they are diverging., Are we able to see,,, okay,,, will this action that a policymaker has given us bring us to the outcome?

**Speaker B:** ~~Um,~~ I think these are really important questions around the category of you. How can we have better epist security? **Speaker A:**  It's crazy to think how far this might be able to go over the not too distant future. ~~I mean,~~ obviously, you're primarily focused right now on getting a read on what the bots can do and trying to be as accurate as you can and to be much more in depth on these ~~sort of~~ mini metaculuses. Do you have a roadmap for let's ass assum, this works? Do you have a roadmap for how this sort of rolls out and scales up to ultimately, like, big picture, most important questions in society? **Speaker B:**  ~~Right?~~ And that question I hear, ~~ah o, they are,~~ you should write a blog post about this, probably that maps this out. ~~Um,~~ quick thoughts that come to my mind, ~~um, like,~~ we know preferences can and do change based on actions and their consequences, ~~right?~~ So can we build these feedback loops as proof points in organizations that can actually take action on them where real stakes are present? ~~Um,~~ that's why I'm interested in labor unions, for example, because it's a fairly acute case of coordinated decision making with stakeholders that are outside and inside the group. So it gives us a lot of visibility. ~~I think~~ where we are at right now is, I don't expect the top down revolution of a government adopting this off the bat, but I do think there's a lot of municipal level, ~~um,~~ experimentation that already has been happening. ~~Like,~~ for example, talk to the city is collaborating with, ~~uh,~~ a couple of municipalities in Japan right now, ~~um,~~ through liquid, which is a japanese, ~~um,~~ liquid democracy focus company. ~~Um,~~ there's a bunch coming ~~in~~ in Taiwan. We have interest from folks in Singapore to be able to use metaculous forecasts. For example, we have interests in similar Taiwan community. We have groups in the US also on municipal level. Like for example, Detroit has a bunch of communities, ~~um,~~ that are focusing on well being of African Americans and previously incarcerated forks. Are we able to figure out what interventions bring a better world to them? These are all very short term, but in these processes we can actually see, ~~oh,~~ this seemed to have worked. This actually did yield an outcome where a group was able to coalesce much better. ~~I think~~ we need more visibility into that. This is ~~the very first step. I think~~ AI tooling is absolutely critical for both the failure mode and the success mode will heavily depend on how these tools are implemented and used ~~, um,,~~ how these tools are actively enhancing human aid. ##y um,, I would recommend people who are interested in more of this to check out the roadmap documents from AI Objectives Institute. That's where I have done a lot of my writing and thinking with the team there. ~~Um,,~~ and I reach out to them also. Um,, I still try to stay as involved as I can,, but it does hold a dear space in my heart for Peter Eckersy,, who was the original founder and a,, uh,, mentor and a friend of mine,, unfortunately passed away quite unexpectedly,, which is when I started leading AI objectives institute., Um,, ~~,and like~~the line of thought,, there was very much always,, like,, AI can be a transformative point for human well being,, but the default systems do not place us on that path., Um,, so ~~,I think there's a lot there,,and this is~~the question of existential hope,, right?, Like,, I see existential risk and a lot of risk related failures as let me put it this way., Existential risk is failure to coordinate at the face of a risk., If we can already foresee this path ~~,and we are failing to coordinate the systems we are in,,,the coordination capabilities we are in doesn't let us get to the heart of that., That is why we are fail., So that is~~~the angle that I wanted to keep looking at., Because we have seen incredibly successful cases ~~,of international coordination,,,or multi corporation coordination., Like~~~the ozone layer is basically recovering since we have banned CP CFcs., Like there is many different cases where we have moved mountains as society., Like microplastics related harms., Like we have bands,,, um,,, lead at this point., Like there are ways in which we are able to coordinate if we can create coherent world models., And ~~,I think~~~the thing we need to do is have shared world models that can contain ~~,the disagreements rather~~~instead ~~,of agreeable action policies.~ ~~,I think~~~the way politics happens right now,,, voting happens right now,,, is find ~~,the most agreeable action policy so you can maintain control~~~as opposed ~~,to say,,, what~~~is ~~,the good policy?, And~~~this requires ~~,the level~~~of epistemic rigor and epistemic security., ~~,I see.~ My life's work is to focus on that question and bring more and more towards that., And if there are groups that we can work with,,, hell yeah,,, let's kick it., This is where we need to start., So if there are any organizations that are focusing on our priority cause areas,,, know,,, be it on um,,, climate,,, uh,,, change,,, or AI,,, or like nuclear consequences,,, or there's any organizations that are trying to do better on resource allocation where they want ~~,the resources~~~to be able to do ~~,the maximal good~~~for this specific community,,, I would love to talk to them., I would love to understand how ~~,the things~~~we are building can be useful for them., Um,,, ~~,I think~~~we need more experimentation ~~,of this sort.~ And,,, um,,, I'd rather have these experiments be with people that benefit from them in ~~,the immediate short term.~ Cool., **Speaker A:**  Well,, that's a great,, uh,,,, call to action.

**Speaker A:** ~~Um,~~ I'm glad we stayed on the little extra to get, ~~um,~~ that final section. ~~Um,~~ I guess I'll ask again, anything else that we didn't last time? It was a fruitful question. Anything else that we didn't, ~~uh,~~ get to that you wanted to touch on? **Speaker B:**  Nope. I feel complete. ~~Um,~~ thank you so much for this opportunity. It was lovely for it also made me realize the context through which my path has evolved. Like seeing the role forecasting can play hand to hand with collective intelligence and the failure modes of, you know, the current political processes or democracy or resource allocation makes me realize, oh, I see the role at this place. Uh, so this was great for me as well. So thank you. **Speaker A:**  Cool. Thank you, Dar. ~~Uh,~~ make sure I'm saying it correctly again. ~~Dr. Tan~~ Der Tan , right? **Speaker B:**  Yes. **Speaker A:**  Der Tan , CEO of Mettaculous . Thank you for being part of the cognitive revolution . **Speaker B:**  Same here . **Speaker A:**  ~~Uh,~~ great job about you . I think , ~~uh,~~ some of your commentary , especially toward the end there , and think it'super fascinating . I'll hit stop .

